{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "from scipy import sparse\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tsv file with selected attibutes of reviews.json\n",
    "\n",
    "outfile = open(\"review_stars.tsv\", 'w')\n",
    "sfile = csv.writer(outfile, delimiter =\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "sfile.writerow(['business_id','stars', 'text'])\n",
    "with open('yelp_dataset/yelp_academic_dataset_review.json') as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        # some special char must be encoded in 'utf-8'\n",
    "        sfile.writerow([row['business_id'], row['stars'], (row['text']).encode('utf-8')])\n",
    "\n",
    "outfile.close()\n",
    "\n",
    "review_df= pd.read_csv('review_stars.tsv', delimiter =\"\\t\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tsv file with selected attibutes of business.json\n",
    "\n",
    "outfile = open(\"business.tsv\", 'w')\n",
    "sfile = csv.writer(outfile, delimiter =\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "sfile.writerow(['business_id','categories', 'stars', 'review_count'])\n",
    "with open('yelp_dataset/yelp_academic_dataset_business.json') as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        # some special char must be encoded in 'utf-8'\n",
    "        sfile.writerow([row['business_id'], row['categories'], row['stars'],row['review_count'] ])\n",
    "\n",
    "outfile.close()\n",
    "\n",
    "business_df= pd.read_csv('business.tsv', delimiter =\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group-by business id\n",
    "\n",
    "review_agg_df = review_df.groupby('business_id')['text'].sum()\n",
    "\n",
    "# for Sklearn\n",
    "\n",
    "df_ready_for_sklearn = pd.DataFrame({'business_id': review_agg_df.index, 'all_reviews': review_agg_df.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join both files and create new\n",
    "\n",
    "merge_df = pd.merge(business_df, df_ready_for_sklearn, on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization \n",
    "\n",
    "merge_df['review_count'] = zscore(merge_df['review_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IT-IDF Vectorizer\n",
    "\n",
    "vectorizer = sk_text.TfidfVectorizer(stop_words='english', min_df=5)\n",
    "matrix = vectorizer.fit_transform(merge_df['all_reviews'])\n",
    "matrix = matrix.toarray()       # Compressed Sparse Row matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X Data\n",
    "\n",
    "review_array = np.vstack(merge_df['review_count'])\n",
    "\n",
    "features_matrix = np.concatenate((matrix,review_array),axis=1)\n",
    "\n",
    "# Y Data\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "target_array = label_encoder.fit_transform(merge_df['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data into Training and Testing\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_matrix, target_array, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data stats\n",
    "\n",
    "print('X training set shape ',x_train.shape)\n",
    "print('y training set shape ',y_train.shape)\n",
    "print('X test set shape ',x_test.shape)\n",
    "print('y test set shape ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regrassion\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg_clf = LinearRegression()\n",
    "\n",
    "lin_reg_clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = lin_reg_clf.predict(x_test)\n",
    "\n",
    "# print predicted and target values\n",
    "\n",
    "for i in range(0,len(y_pred)):\n",
    "     \n",
    "    print(y_pred[i],y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Log_reg_clf = LogisticRegression()\n",
    "\n",
    "# Train the model \n",
    "Log_reg_clf.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = Log_reg_clf.predict(x_test)\n",
    "\n",
    "# print predicted and target values\n",
    "\n",
    "for i in range(0,len(y_pred)):\n",
    "     \n",
    "    print(y_pred[i],y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb_clf = MultinomialNB()\n",
    "\n",
    "mnb_clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = mnb_clf.predict(x_test)\n",
    "\n",
    "# print predicted and target values\n",
    "\n",
    "for i in range(0,len(y_pred)):\n",
    "     \n",
    "    print(y_pred[i],y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC()\n",
    "\n",
    "svm_clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "\n",
    "# print predicted and target values\n",
    "\n",
    "for i in range(0,len(y_pred)):\n",
    "     \n",
    "    print(y_pred[i],y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn_clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = knn_clf.predict(x_test)\n",
    "\n",
    "# print predicted and target values\n",
    "\n",
    "for i in range(0,len(y_pred)):\n",
    "     \n",
    "    print(y_pred[i],y_test[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
