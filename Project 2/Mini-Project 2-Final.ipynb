{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChandiniNagendra\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import io\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "import collections\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Open business.json file, create tsv file with business_id, business name, categories, and review count to be used as features \n",
    "#and stars as label\n",
    "\n",
    "outfile = open(\"business.tsv\", 'w')\n",
    "sfile = csv.writer(outfile, delimiter =\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "sfile.writerow(['business_id','categories', 'stars', 'review_count', 'postal code'])\n",
    "with open('yelp_academic_dataset_business.json', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        sfile.writerow([row['business_id'], row['categories'], row['stars'], row['review_count'], row['postal_code']])\n",
    "\n",
    "outfile.close()\n",
    "\n",
    "business_df= pd.read_csv('business.tsv', delimiter =\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Open review.json file, create tsv file with business_id,text to be used as features \n",
    "#and stars as label\n",
    "\n",
    "outfile = open(\"review_stars.tsv\", 'w')\n",
    "sfile = csv.writer(outfile, delimiter =\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "sfile.writerow(['business_id','stars', 'text'])\n",
    "with open('yelp_academic_dataset_review.json', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        # some special char must be encoded in 'utf-8'\n",
    "        sfile.writerow([row['business_id'], row['stars'], (row['text']).encode('utf-8')])\n",
    "\n",
    "outfile.close()\n",
    "\n",
    "review_df= pd.read_csv('review_stars.tsv', delimiter =\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Group all reviews by business_id\n",
    "review_agg_df = review_df.groupby('business_id')['text'].sum()\n",
    "review_df_ready_for_sklearn = pd.DataFrame({'business_id': review_agg_df.index, 'all_reviews': review_agg_df.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Merge the resulting review aggregate dataframe with business dataframe\n",
    "merge_df = pd.merge(business_df, review_df_ready_for_sklearn, on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Normalization of review count field so it becomes comparable and remove bias\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "merge_df.insert(3,'normalized_count',((merge_df['review_count'] - merge_df['review_count'].min()) / (merge_df['review_count'].max() - merge_df['review_count'].min())).astype(float))\n",
    "merge_df['review_count'] = zscore(merge_df['review_count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# removing NaN categories\n",
    "\n",
    "merge_df = merge_df[merge_df['categories'].notnull()]\n",
    "merge_df = merge_df[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Extracting categories\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "encoded_categories = MultiLabelBinarizer()\n",
    "category_matrix = encoded_categories.fit_transform(merge_df['categories'].str.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#TF-IDF calculation\n",
    "\n",
    "tfidf = sk_text.TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    " stop_words= 'english',ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fit the reviews column with TFIDFvectorizer\n",
    "matrix = tfidf.fit_transform(merge_df['all_reviews'])\n",
    "matrix = matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We are adding the normalized count to the original matrix with TFIDFvectorizer\n",
    "x_matrix_minmax = np.column_stack((matrix, merge_df['normalized_count']))\n",
    "\n",
    "# Zscore\n",
    "x_matrix_zscore = np.column_stack((matrix, merge_df['review_count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train test data for linear regression\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_matrix_minmax, merge_df['stars'] , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Training and prediction using Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# linear regression\n",
    "\n",
    "lin_reg_model = LinearRegression()\n",
    "\n",
    "lin_reg_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred_linear = lin_reg_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business id - hTF1Qo6PRFnDgg1rh9a9BQ actual stars  - 4.000000 predicted - 3.643041\n",
      "business id - bAPjkuNJ67j2F4C5HQQHhQ actual stars  - 4.000000 predicted - 3.900257\n",
      "business id - dFcs3q8ynbFEaAnbyGSLjQ actual stars  - 4.000000 predicted - 4.197429\n",
      "business id - jrhc4s5XMR8S8kpGdU08og actual stars  - 4.500000 predicted - 4.797609\n",
      "business id - e7207sqC-pSn6GIf31ikhQ actual stars  - 4.000000 predicted - 3.765016\n",
      "business id - CF9TxeEdP5QxihYFAl4sUg actual stars  - 4.000000 predicted - 4.057981\n",
      "business id - zZPCAFK85NtitSNVP_wfYg actual stars  - 3.500000 predicted - 3.503671\n",
      "business id - 42U4Vlzr7nmQa1Bk8J4flw actual stars  - 5.000000 predicted - 4.855848\n",
      "business id - TTrYd662CZFRPaiwl-sUqA actual stars  - 2.000000 predicted - 1.747432\n",
      "business id - -lBIxCbHxuN3YO_sUkWeUQ actual stars  - 2.500000 predicted - 2.484346\n"
     ]
    }
   ],
   "source": [
    "# list  the business with the stars and prediction\n",
    "\n",
    "for i in range(0,10):\n",
    "    idx=y_test.index[i]\n",
    "    print(\"business id - %s actual stars  - %f predicted - %f\" \n",
    "          %(merge_df['business_id'][idx], y_test[idx], y_pred_linear[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 0.56\n",
      "Variance score: 0.70\n"
     ]
    }
   ],
   "source": [
    "# RMS value\n",
    "\n",
    "score_lin_classic = np.sqrt(mean_squared_error(y_test, y_pred_linear))\n",
    "print(\"Root Mean Squared Error: %.2f\" % score_lin_classic)\n",
    "print('R2 score: %.2f' % r2_score(y_test, y_pred_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# label encoding data for logistic regression\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "merge_df['encoded_stars'] = label_encoder.fit_transform(merge_df['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train test data afor other models\n",
    "\n",
    "x_train_lr, x_test_lr, y_train_lr, y_test_lr = train_test_split(x_matrix_minmax, merge_df['encoded_stars'] , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# logistic Regression\n",
    "\n",
    "Log_reg_model = LogisticRegression()\n",
    "\n",
    "Log_reg_model.fit(x_train_lr, y_train_lr)\n",
    "\n",
    "y_pred_logistic = Log_reg_model.predict(x_test_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 1.38\n",
      "Variance score: 0.54\n"
     ]
    }
   ],
   "source": [
    "# RMs for logistic\n",
    "\n",
    "score_log_classic = np.sqrt(mean_squared_error(y_test_lr, y_pred_logistic))\n",
    "print(\"Root Mean Squared Error: %.2f\" % score_log_classic)\n",
    "print('R2 score: %.2f' % r2_score(y_test_lr, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Tensorflow Model for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "** Training without early stopping and Model Checkpoint and RELU **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Tensor flow works well with 32 bit\n",
    "y_stars_regression = merge_df['stars'].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train test data\n",
    "x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x_matrix_minmax, y_stars_regression , test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow model for Regression with RELU\n",
    "\n",
    "model_reg_relu = Sequential()\n",
    "\n",
    "model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "model_reg_relu.add(Dense(1)) # Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 2.3512\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3952\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2887\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2576\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.2426\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.2266\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.1978\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1676\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1418\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.1168\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0960\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0802\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0677\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0578\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0479\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0415\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0363\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0314\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0275\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0246\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0222\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0206\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0201\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0195\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.0184\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.0169\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0169\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0160\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.0154\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0147\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0137\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0138\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0137\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.0133\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.0129\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0118\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0115\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0117\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0119\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0117\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0111\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0102\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0098\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0099\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0098\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0098\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0099\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0101\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0097\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.0090\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.0088\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.0086\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0086\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0088\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0096\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0092\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0081\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0071\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0071\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0069\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0074\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0078\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0085\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0079\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0077\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0069\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0066\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0067\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0064\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0065\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0064\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0065\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0066\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0062\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0061\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0062\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.0063\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.0067\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0064\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0059\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.0061\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.0066\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0061\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0057\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0055\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0053\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0050\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0055\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0054\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0055\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0057\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0057\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0057\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0051\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0047\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0047\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0047\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0049\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0050\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15e16817a20>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model training with Optimizer = adam\n",
    "\n",
    "model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_reg_relu.fit(x_train_reg,y_train_reg,verbose=2,epochs=100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_simple = model_reg_relu.predict(x_test_reg)\n",
    "print(\"Shape: {}\".format(pred_reg_simple.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 4.0, predicted Stars: [2.8022065]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 2.5, predicted Stars: [1.9806347]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 2.5, predicted Stars: [1.8916467]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 3.5, predicted Stars: [3.1011438]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 3.0, predicted Stars: [2.7952552]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 2.5, predicted Stars: [2.213677]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [1.9444847]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 3.0, predicted Stars: [3.5327148]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [3.4062147]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 2.5, predicted Stars: [2.4765658]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_simple[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5732024908065796\n",
      "R2 score: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_reg_relu = np.sqrt(mean_squared_error(y_test_reg,pred_reg_simple))\n",
    "print(\"Final score (RMSE): {}\".format(score_reg_relu))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "** Training with early stopping and Model Checkpoint ReLU **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 1.9429 - val_loss: 0.4807\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.48067, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.3239 - val_loss: 0.3785\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.48067 to 0.37852, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2114 - val_loss: 0.3623\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37852 to 0.36232, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.1640 - val_loss: 0.3665\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36232\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1349 - val_loss: 0.3770\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36232\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1122 - val_loss: 0.3892\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36232\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.0924 - val_loss: 0.3905\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36232\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0724 - val_loss: 0.3866\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36232\n",
      "Epoch 00008: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 2.4294 - val_loss: 0.5279\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36232\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.3611 - val_loss: 0.3874\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36232\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2321 - val_loss: 0.3690\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36232\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1823 - val_loss: 0.3759\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36232\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1507 - val_loss: 0.3725\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36232\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1273 - val_loss: 0.3747\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36232\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1077 - val_loss: 0.3914\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36232\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0907 - val_loss: 0.4077\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36232\n",
      "Epoch 00008: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 1.9530 - val_loss: 0.4637\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36232\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3129 - val_loss: 0.3759\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36232\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2103 - val_loss: 0.3635\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36232\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.1637 - val_loss: 0.3581\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.36232 to 0.35812, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.1323 - val_loss: 0.3703\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35812\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.1078 - val_loss: 0.3751\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35812\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0875 - val_loss: 0.3946\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35812\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0714 - val_loss: 0.3859\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35812\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0582 - val_loss: 0.3837\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35812\n",
      "Epoch 00009: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 1.6968 - val_loss: 0.4779\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35812\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3224 - val_loss: 0.3835\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35812\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2123 - val_loss: 0.3726\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35812\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1672 - val_loss: 0.3819\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35812\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1379 - val_loss: 0.3912\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35812\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1104 - val_loss: 0.3806\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35812\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0908 - val_loss: 0.3899\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35812\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0725 - val_loss: 0.3855\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35812\n",
      "Epoch 00008: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.8032 - val_loss: 0.4613\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35812\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3164 - val_loss: 0.3816\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35812\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2128 - val_loss: 0.3670\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35812\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1690 - val_loss: 0.3665\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35812\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1360 - val_loss: 0.3746\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35812\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1131 - val_loss: 0.3835\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35812\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0923 - val_loss: 0.3797\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35812\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0729 - val_loss: 0.3858\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35812\n",
      "Epoch 00008: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.9035 - val_loss: 0.4718\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35812\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3176 - val_loss: 0.3821\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35812\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2139 - val_loss: 0.3682\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35812\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1683 - val_loss: 0.3725\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35812\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1410 - val_loss: 0.3743\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35812\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1155 - val_loss: 0.3834\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35812\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0922 - val_loss: 0.3856\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35812\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0758 - val_loss: 0.3888\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35812\n",
      "Epoch 00008: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 1.9735 - val_loss: 0.4679\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35812\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3223 - val_loss: 0.3694\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35812\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2169 - val_loss: 0.3589\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35812\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1727 - val_loss: 0.3675\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35812\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1425 - val_loss: 0.3711\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35812\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1188 - val_loss: 0.3688\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35812\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0974 - val_loss: 0.3768\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35812\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0800 - val_loss: 0.3893\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35812\n",
      "Epoch 00008: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 2.0104 - val_loss: 0.4623\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35812\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3112 - val_loss: 0.3764\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35812\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2046 - val_loss: 0.3669\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35812\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1595 - val_loss: 0.3725\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35812\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1275 - val_loss: 0.3646\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35812\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.0998 - val_loss: 0.3751\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35812\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0791 - val_loss: 0.3878\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35812\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0635 - val_loss: 0.3960\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35812\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0518 - val_loss: 0.3933\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35812\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0420 - val_loss: 0.3901\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.35812\n",
      "Epoch 00010: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.8361 - val_loss: 0.4704\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35812\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3148 - val_loss: 0.3770\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35812\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2137 - val_loss: 0.3775\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35812\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1727 - val_loss: 0.3720\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35812\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 3s - loss: 0.1484 - val_loss: 0.3774\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35812\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1294 - val_loss: 0.3851\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35812\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1089 - val_loss: 0.3818\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35812\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0942 - val_loss: 0.3866\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35812\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0790 - val_loss: 0.3872\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35812\n",
      "Epoch 00009: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.9894 - val_loss: 0.4869\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35812\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3349 - val_loss: 0.3825\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35812\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2182 - val_loss: 0.3780\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35812\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1666 - val_loss: 0.3758\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35812\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1318 - val_loss: 0.3714\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35812\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1064 - val_loss: 0.3838\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35812\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0850 - val_loss: 0.3912\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35812\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0693 - val_loss: 0.3916\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35812\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0582 - val_loss: 0.3941\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35812\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.0483 - val_loss: 0.4009\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.35812\n",
      "Epoch 00010: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100)\n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_stopping = model_reg_relu.predict(x_test_reg)\n",
    "print(\"Shape: {}\".format(pred_reg_stopping.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 2.0, predicted Stars: [1.9188011]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 5.0, predicted Stars: [3.5073977]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [2.555329]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 3.5, predicted Stars: [3.6105719]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 2.0, predicted Stars: [2.5487258]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 4.5, predicted Stars: [5.296804]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 3.5, predicted Stars: [4.684453]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 3.5, predicted Stars: [3.2609322]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [4.428051]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.5, predicted Stars: [3.6865396]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_stopping[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5984302163124084\n",
      "R2 score: 0.66\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_reg_relu_stopping = np.sqrt(mean_squared_error(y_test_reg,pred_reg_stopping))\n",
    "print(\"Final score (RMSE): {}\".format(score_reg_relu_stopping))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_stopping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu with Postal Code and Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot cooding of postal codes \n",
    "\n",
    "postal_hotcoded_df = pd.get_dummies(merge_df['postal code'], sparse = 'true')\n",
    "\n",
    "x_matrix_postal = np.column_stack((x_matrix_minmax, postal_hotcoded_df))\n",
    "x_matrix_final = np.column_stack((x_matrix_postal, category_matrix))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_stars_regression.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test data\n",
    "x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x_matrix_final, y_stars_regression , test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_postal.hdf5\", verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.8029 - val_loss: 0.4539\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45386, saving model to ./best_weights_sigmoid_postal.hdf5\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3086 - val_loss: 0.4007\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45386 to 0.40070, saving model to ./best_weights_sigmoid_postal.hdf5\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2069 - val_loss: 0.3674\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.40070 to 0.36736, saving model to ./best_weights_sigmoid_postal.hdf5\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1602 - val_loss: 0.3862\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36736\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1327 - val_loss: 0.3684\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36736\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1090 - val_loss: 0.3869\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36736\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0896 - val_loss: 0.3900\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36736\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0733 - val_loss: 0.3955\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36736\n",
      "Epoch 00008: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.6822 - val_loss: 0.4554\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36736\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3153 - val_loss: 0.3847\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36736\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2109 - val_loss: 0.3773\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36736\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1665 - val_loss: 0.3772\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36736\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1350 - val_loss: 0.3832\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36736\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1103 - val_loss: 0.3890\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36736\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0897 - val_loss: 0.4073\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36736\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0711 - val_loss: 0.4092\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36736\n",
      "Epoch 00008: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.6747 - val_loss: 0.4896\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36736\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3223 - val_loss: 0.4183\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36736\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2111 - val_loss: 0.3773\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36736\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1661 - val_loss: 0.3710\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36736\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1337 - val_loss: 0.3904\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36736\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1093 - val_loss: 0.3879\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36736\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0910 - val_loss: 0.3888\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36736\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0744 - val_loss: 0.4037\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36736\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0613 - val_loss: 0.4156\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.36736\n",
      "Epoch 00009: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.8349 - val_loss: 0.4997\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36736\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3344 - val_loss: 0.4052\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36736\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2245 - val_loss: 0.3817\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36736\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1798 - val_loss: 0.3853\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36736\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1527 - val_loss: 0.3995\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36736\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1303 - val_loss: 0.3920\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36736\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1138 - val_loss: 0.3959\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36736\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1000 - val_loss: 0.3984\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36736\n",
      "Epoch 00008: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.5673 - val_loss: 0.4511\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36736\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3047 - val_loss: 0.3783\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36736\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2075 - val_loss: 0.3699\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36736\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1651 - val_loss: 0.3805\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36736\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1424 - val_loss: 0.3894\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36736\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1202 - val_loss: 0.3885\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36736\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1016 - val_loss: 0.3961\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36736\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0833 - val_loss: 0.3963\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36736\n",
      "Epoch 00008: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 2.3171 - val_loss: 0.4801\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36736\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3160 - val_loss: 0.3882\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36736\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2125 - val_loss: 0.3652\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36736 to 0.36518, saving model to ./best_weights_sigmoid_postal.hdf5\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1630 - val_loss: 0.3684\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36518\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1278 - val_loss: 0.3770\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36518\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.0994 - val_loss: 0.3765\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36518\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0757 - val_loss: 0.3942\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36518\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0573 - val_loss: 0.3810\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36518\n",
      "Epoch 00008: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.8009 - val_loss: 0.4739\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36518\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3153 - val_loss: 0.3791\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36518\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2097 - val_loss: 0.3955\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36518\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1640 - val_loss: 0.3788\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36518\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1353 - val_loss: 0.3818\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36518\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1143 - val_loss: 0.3939\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36518\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0964 - val_loss: 0.4025\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36518\n",
      "Epoch 00007: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.9109 - val_loss: 0.4578\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36518\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3118 - val_loss: 0.3816\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36518\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2115 - val_loss: 0.3733\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36518\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1640 - val_loss: 0.3754\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36518\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1354 - val_loss: 0.3869\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36518\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1118 - val_loss: 0.3981\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36518\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0922 - val_loss: 0.4087\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36518\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0739 - val_loss: 0.4002\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36518\n",
      "Epoch 00008: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.8523 - val_loss: 0.4835\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36518\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3163 - val_loss: 0.3827\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36518\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2057 - val_loss: 0.3646\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36518 to 0.36457, saving model to ./best_weights_sigmoid_postal.hdf5\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1534 - val_loss: 0.3788\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36457\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1217 - val_loss: 0.3928\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36457\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.0973 - val_loss: 0.3908\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36457\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 3s - loss: 0.0784 - val_loss: 0.4044\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36457\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0652 - val_loss: 0.4105\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36457\n",
      "Epoch 00008: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.8085 - val_loss: 0.4856\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36457\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3166 - val_loss: 0.3809\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36457\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2116 - val_loss: 0.3856\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36457\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1661 - val_loss: 0.3712\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36457\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1371 - val_loss: 0.3851\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36457\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1129 - val_loss: 0.3854\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36457\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0889 - val_loss: 0.3953\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36457\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0699 - val_loss: 0.3927\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36457\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0569 - val_loss: 0.4127\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.36457\n",
      "Epoch 00009: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n",
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 4.3546 - val_loss: 1.1106\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36457\n",
      "Epoch 2/100\n",
      " - 3s - loss: 1.0318 - val_loss: 1.0156\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36457\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.9730 - val_loss: 0.9412\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36457\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.7775 - val_loss: 0.6796\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36457\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.4995 - val_loss: 0.4723\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36457\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.3391 - val_loss: 0.3702\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36457\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.2577 - val_loss: 0.3243\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.36457 to 0.32431, saving model to ./best_weights_sigmoid_postal.hdf5\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.2134 - val_loss: 0.3038\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.32431 to 0.30382, saving model to ./best_weights_sigmoid_postal.hdf5\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.1861 - val_loss: 0.2935\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.30382 to 0.29346, saving model to ./best_weights_sigmoid_postal.hdf5\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.1671 - val_loss: 0.2896\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.29346 to 0.28959, saving model to ./best_weights_sigmoid_postal.hdf5\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.1528 - val_loss: 0.2898\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28959\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1411 - val_loss: 0.2905\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.28959\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.1311 - val_loss: 0.2954\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.28959\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.1228 - val_loss: 0.3028\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.28959\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.1155 - val_loss: 0.3015\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.28959\n",
      "Epoch 00015: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 2.5463 - val_loss: 1.0141\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28959\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.9367 - val_loss: 0.8597\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28959\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.6733 - val_loss: 0.5775\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28959\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.4134 - val_loss: 0.4062\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28959\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.2820 - val_loss: 0.3325\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28959\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.2206 - val_loss: 0.3065\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28959\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1892 - val_loss: 0.2978\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28959\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1687 - val_loss: 0.2940\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28959\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1553 - val_loss: 0.2974\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28959\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.1433 - val_loss: 0.2981\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28959\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.1333 - val_loss: 0.3007\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28959\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1258 - val_loss: 0.3021\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.28959\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.1199 - val_loss: 0.3097\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.28959\n",
      "Epoch 00013: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 2.4904 - val_loss: 1.0075\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28959\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.9251 - val_loss: 0.8570\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28959\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.6668 - val_loss: 0.5657\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28959\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.4118 - val_loss: 0.3990\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28959\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.2800 - val_loss: 0.3282\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28959\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.2191 - val_loss: 0.3019\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28959\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1876 - val_loss: 0.2948\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28959\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1672 - val_loss: 0.2916\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28959\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1529 - val_loss: 0.2960\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28959\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.1416 - val_loss: 0.2949\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28959\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.1327 - val_loss: 0.3004\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28959\n",
      "Epoch 12/100\n",
      " - 4s - loss: 0.1244 - val_loss: 0.3029\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.28959\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.1175 - val_loss: 0.3066\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.28959\n",
      "Epoch 00013: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 2.6105 - val_loss: 1.0236\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28959\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.9511 - val_loss: 0.8935\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28959\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.7208 - val_loss: 0.6242\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28959\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.4656 - val_loss: 0.4399\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28959\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.3189 - val_loss: 0.3579\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28959\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.2444 - val_loss: 0.3180\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28959\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.2038 - val_loss: 0.2987\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28959\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1790 - val_loss: 0.2938\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28959\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.1616 - val_loss: 0.2918\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28959\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.1495 - val_loss: 0.2943\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28959\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.1378 - val_loss: 0.2951\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28959\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1297 - val_loss: 0.2996\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.28959\n",
      "Epoch 13/100\n",
      " - 4s - loss: 0.1222 - val_loss: 0.3051\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.28959\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.1157 - val_loss: 0.3066\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.28959\n",
      "Epoch 00014: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.3526 - val_loss: 0.8770\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28959\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.6952 - val_loss: 0.5596\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28959\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.3822 - val_loss: 0.3571\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28959\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2521 - val_loss: 0.3098\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28959\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.2058 - val_loss: 0.2960\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28959\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1808 - val_loss: 0.2932\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28959\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 3s - loss: 0.1641 - val_loss: 0.2984\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28959\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.1513 - val_loss: 0.2979\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28959\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1419 - val_loss: 0.2990\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28959\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.1321 - val_loss: 0.3127\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28959\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.1253 - val_loss: 0.3083\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28959\n",
      "Epoch 00011: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 3.8595 - val_loss: 1.0628\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28959\n",
      "Epoch 2/100\n",
      " - 3s - loss: 1.0087 - val_loss: 0.9858\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28959\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.8965 - val_loss: 0.8220\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28959\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.6384 - val_loss: 0.5663\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28959\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.4140 - val_loss: 0.4177\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28959\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.2976 - val_loss: 0.3479\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28959\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.2352 - val_loss: 0.3143\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28959\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1997 - val_loss: 0.2992\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28959\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.1764 - val_loss: 0.2952\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28959\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.1601 - val_loss: 0.2920\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28959\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.1472 - val_loss: 0.2953\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28959\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1363 - val_loss: 0.2929\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.28959\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.1280 - val_loss: 0.2965\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.28959\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.1212 - val_loss: 0.2982\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.28959\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.1141 - val_loss: 0.3040\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.28959\n",
      "Epoch 00015: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 2.7623 - val_loss: 0.9972\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28959\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.9095 - val_loss: 0.8281\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28959\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.6639 - val_loss: 0.5792\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28959\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.4361 - val_loss: 0.4191\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28959\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.3029 - val_loss: 0.3445\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28959\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.2343 - val_loss: 0.3097\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28959\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1969 - val_loss: 0.2965\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28959\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.1744 - val_loss: 0.2939\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28959\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1587 - val_loss: 0.2925\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28959\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.1462 - val_loss: 0.2959\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28959\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.1362 - val_loss: 0.3024\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28959\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1277 - val_loss: 0.3013\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.28959\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.1209 - val_loss: 0.3017\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.28959\n",
      "Epoch 14/100\n",
      " - 4s - loss: 0.1153 - val_loss: 0.3083\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.28959\n",
      "Epoch 00014: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 2.4803 - val_loss: 1.0141\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28959\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.9230 - val_loss: 0.8463\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28959\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.6754 - val_loss: 0.5889\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28959\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.4356 - val_loss: 0.4276\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28959\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.3022 - val_loss: 0.3446\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28959\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.2343 - val_loss: 0.3113\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28959\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1970 - val_loss: 0.2993\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28959\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1738 - val_loss: 0.2997\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28959\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.1575 - val_loss: 0.2965\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28959\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.1455 - val_loss: 0.3037\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28959\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.1353 - val_loss: 0.3064\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28959\n",
      "Epoch 12/100\n",
      " - 4s - loss: 0.1266 - val_loss: 0.3068\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.28959\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.1197 - val_loss: 0.3055\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.28959\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.1138 - val_loss: 0.3116\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.28959\n",
      "Epoch 00014: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.7007 - val_loss: 0.8931\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28959\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.7223 - val_loss: 0.5984\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28959\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.4374 - val_loss: 0.4016\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28959\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2882 - val_loss: 0.3300\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28959\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.2248 - val_loss: 0.3073\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28959\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1928 - val_loss: 0.2998\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28959\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1721 - val_loss: 0.2965\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28959\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.1578 - val_loss: 0.2983\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28959\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1468 - val_loss: 0.2997\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28959\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.1369 - val_loss: 0.3044\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28959\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.1299 - val_loss: 0.3085\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28959\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1234 - val_loss: 0.3137\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.28959\n",
      "Epoch 00012: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.7724 - val_loss: 0.9255\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28959\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.7758 - val_loss: 0.6578\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28959\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.4956 - val_loss: 0.4371\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28959\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.3153 - val_loss: 0.3385\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28959\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.2357 - val_loss: 0.3050\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28959\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1991 - val_loss: 0.2938\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28959\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1764 - val_loss: 0.2951\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28959\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1611 - val_loss: 0.2901\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28959\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1478 - val_loss: 0.2941\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28959\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.1374 - val_loss: 0.3087\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28959\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.1294 - val_loss: 0.3085\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28959\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1232 - val_loss: 0.3187\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.28959\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.1157 - val_loss: 0.3152\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.28959\n",
      "Epoch 00013: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ReLU\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_postal.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars relu\n",
    "pred_reg_relu_stopping = model_reg_relu.predict(x_test_reg)\n",
    "print(\"Shape: {}\".format(pred_reg_relu_stopping.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [1.9188011]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.5073977]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [2.555329]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 5.0, predicted Stars: [3.6105719]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 2.5, predicted Stars: [2.5487258]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [5.296804]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [4.684453]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [3.2609322]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 4.0, predicted Stars: [4.428051]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.5, predicted Stars: [3.6865396]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_relu_stopping[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE) ReLU: 0.2876877188682556\n",
      "R2 score Relu: 0.92\n",
      "Final score (RMSE) ReLU: 0.2876877188682556\n",
      "R2 score Relu: 0.92\n"
     ]
    }
   ],
   "source": [
    "score_relu_postal = np.sqrt(mean_squared_error(y_test_reg,pred_reg_relu_stopping))\n",
    "print(\"Final score (RMSE) Sigmoid: {}\".format(score_relu_postal))\n",
    "print('R2 score Sigmoid: %.2f' % r2_score(y_test_reg, pred_reg_relu_stopping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Best from classic, best from tensor flow and additional features comparison\n",
    "\n",
    "score_list_reg=[score_reg_sig,score_reg_sig_stopping, score_relu_postal]\n",
    "names =['Sigmoid','Sigmoid Stopping','ReLU Postal']\n",
    "tick_marks = np.arange(len(names))\n",
    "plt.bar(range(len(score_list_reg)), score_list_reg)\n",
    "plt.xticks(tick_marks, names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with different optimizers for ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** SGD **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_sgd.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.2416 - val_loss: 0.7421\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.74209, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.5746 - val_loss: 0.4747\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.74209 to 0.47469, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.3808 - val_loss: 0.3859\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.47469 to 0.38587, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.3110 - val_loss: 0.3493\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.38587 to 0.34927, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.2799 - val_loss: 0.3404\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.34927 to 0.34043, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.2583 - val_loss: 0.3336\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.34043 to 0.33358, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.2428 - val_loss: 0.3491\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.33358\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.2291 - val_loss: 0.3333\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.33358 to 0.33329, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.2190 - val_loss: 0.3271\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33329 to 0.32712, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.2104 - val_loss: 0.3342\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.32712\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.2019 - val_loss: 0.3275\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.32712\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1932 - val_loss: 0.3354\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.32712\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.1867 - val_loss: 0.3255\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.32712 to 0.32546, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.1800 - val_loss: 0.3263\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.32546\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.1740 - val_loss: 0.3273\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.32546\n",
      "Epoch 16/100\n",
      " - 3s - loss: 0.1683 - val_loss: 0.3358\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.32546\n",
      "Epoch 17/100\n",
      " - 2s - loss: 0.1623 - val_loss: 0.3548\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.32546\n",
      "Epoch 18/100\n",
      " - 2s - loss: 0.1578 - val_loss: 0.3330\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.32546\n",
      "Epoch 00018: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.3487 - val_loss: 0.7571\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32546\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.6047 - val_loss: 0.5078\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32546\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.3993 - val_loss: 0.4039\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32546\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.3180 - val_loss: 0.3553\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32546\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.2846 - val_loss: 0.3484\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32546\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.2610 - val_loss: 0.3348\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32546\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.2431 - val_loss: 0.3294\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32546\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.2297 - val_loss: 0.3263\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32546\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.2176 - val_loss: 0.3323\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.32546\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.2083 - val_loss: 0.3392\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.32546\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.1991 - val_loss: 0.3238\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.32546 to 0.32384, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.1895 - val_loss: 0.3288\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.32384\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.1851 - val_loss: 0.3384\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.32384\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.1762 - val_loss: 0.3437\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.32384\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.1722 - val_loss: 0.3250\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.32384\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.1655 - val_loss: 0.3257\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.32384\n",
      "Epoch 00016: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.3758 - val_loss: 0.8248\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32384\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.6521 - val_loss: 0.5479\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32384\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.4235 - val_loss: 0.4011\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32384\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.3282 - val_loss: 0.3706\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32384\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.2880 - val_loss: 0.3380\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32384\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.2648 - val_loss: 0.3292\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32384\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.2456 - val_loss: 0.3238\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.32384 to 0.32380, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.2326 - val_loss: 0.3275\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32380\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.2202 - val_loss: 0.3221\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.32380 to 0.32209, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.2097 - val_loss: 0.3202\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.32209 to 0.32024, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.1995 - val_loss: 0.3254\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.32024\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1928 - val_loss: 0.3246\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.32024\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.1859 - val_loss: 0.3199\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.32024 to 0.31992, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.1790 - val_loss: 0.3230\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.31992\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.1737 - val_loss: 0.3308\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.31992\n",
      "Epoch 00015: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.5349 - val_loss: 0.8252\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31992\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.6823 - val_loss: 0.5799\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31992\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.4464 - val_loss: 0.4261\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31992\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.3367 - val_loss: 0.3584\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31992\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.2940 - val_loss: 0.3439\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31992\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.2686 - val_loss: 0.3343\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31992\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.2515 - val_loss: 0.3398\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31992\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.2354 - val_loss: 0.3266\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31992\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.2243 - val_loss: 0.3274\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31992\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.2146 - val_loss: 0.3234\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31992\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.2051 - val_loss: 0.3347\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31992\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.1966 - val_loss: 0.3238\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31992\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.1893 - val_loss: 0.3317\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31992\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.1815 - val_loss: 0.3324\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.31992\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.1749 - val_loss: 0.3252\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.31992\n",
      "Epoch 00015: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.3864 - val_loss: 0.7962\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31992\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.6387 - val_loss: 0.5539\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31992\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.4213 - val_loss: 0.4026\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31992\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.3294 - val_loss: 0.3813\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31992\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.2908 - val_loss: 0.3452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31992\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.2676 - val_loss: 0.3385\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31992\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.2491 - val_loss: 0.3319\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31992\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.2336 - val_loss: 0.3306\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31992\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.2229 - val_loss: 0.3271\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31992\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.2118 - val_loss: 0.3341\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31992\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.2025 - val_loss: 0.3257\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31992\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1949 - val_loss: 0.3389\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31992\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.1859 - val_loss: 0.3291\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31992\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.1806 - val_loss: 0.3237\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.31992\n",
      "Epoch 15/100\n",
      " - 2s - loss: 0.1756 - val_loss: 0.3264\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.31992\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.1691 - val_loss: 0.3261\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.31992\n",
      "Epoch 17/100\n",
      " - 2s - loss: 0.1623 - val_loss: 0.3280\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.31992\n",
      "Epoch 18/100\n",
      " - 2s - loss: 0.1570 - val_loss: 0.3313\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.31992\n",
      "Epoch 19/100\n",
      " - 2s - loss: 0.1522 - val_loss: 0.3307\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.31992\n",
      "Epoch 00019: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.3249 - val_loss: 0.7592\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31992\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.5984 - val_loss: 0.5029\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31992\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.3922 - val_loss: 0.3978\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31992\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.3169 - val_loss: 0.3605\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31992\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.2824 - val_loss: 0.3402\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31992\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.2596 - val_loss: 0.3475\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31992\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.2456 - val_loss: 0.3309\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31992\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.2305 - val_loss: 0.3244\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31992\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.2185 - val_loss: 0.3207\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31992\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.2105 - val_loss: 0.3270\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31992\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.2024 - val_loss: 0.3364\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31992\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.1918 - val_loss: 0.3207\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31992\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.1856 - val_loss: 0.3239\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31992\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.1784 - val_loss: 0.3613\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.31992\n",
      "Epoch 00014: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.4070 - val_loss: 0.8037\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31992\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.6510 - val_loss: 0.5553\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31992\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.4280 - val_loss: 0.4039\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31992\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.3305 - val_loss: 0.3710\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31992\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.2909 - val_loss: 0.3509\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31992\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.2683 - val_loss: 0.3468\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31992\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.2491 - val_loss: 0.3263\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31992\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.2370 - val_loss: 0.3262\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31992\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.2244 - val_loss: 0.3233\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31992\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.2151 - val_loss: 0.3211\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31992\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.2052 - val_loss: 0.3241\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31992\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.1972 - val_loss: 0.3223\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31992\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.1900 - val_loss: 0.3197\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.31992 to 0.31975, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.1825 - val_loss: 0.3218\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.31975\n",
      "Epoch 15/100\n",
      " - 2s - loss: 0.1762 - val_loss: 0.3212\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.31975\n",
      "Epoch 16/100\n",
      " - 3s - loss: 0.1703 - val_loss: 0.3231\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.31975\n",
      "Epoch 17/100\n",
      " - 2s - loss: 0.1665 - val_loss: 0.3248\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.31975\n",
      "Epoch 18/100\n",
      " - 2s - loss: 0.1604 - val_loss: 0.3226\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.31975\n",
      "Epoch 00018: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 1.3955 - val_loss: 0.7913\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31975\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.6320 - val_loss: 0.5326\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31975\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.4132 - val_loss: 0.4219\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31975\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.3216 - val_loss: 0.3550\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31975\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.2846 - val_loss: 0.3394\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31975\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.2611 - val_loss: 0.3321\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31975\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.2432 - val_loss: 0.3268\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31975\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.2278 - val_loss: 0.3224\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31975\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.2181 - val_loss: 0.3294\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31975\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.2079 - val_loss: 0.3211\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31975\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.1986 - val_loss: 0.3241\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31975\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.1898 - val_loss: 0.3186\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.31975 to 0.31856, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.1847 - val_loss: 0.3251\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31856\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.1771 - val_loss: 0.3219\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.31856\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.1695 - val_loss: 0.3241\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.31856\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.1668 - val_loss: 0.3221\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.31856\n",
      "Epoch 17/100\n",
      " - 2s - loss: 0.1588 - val_loss: 0.3270\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.31856\n",
      "Epoch 00017: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.5372 - val_loss: 0.8409\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31856\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.7041 - val_loss: 0.5884\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31856\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.4562 - val_loss: 0.4169\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31856\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.3362 - val_loss: 0.3613\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31856\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.2914 - val_loss: 0.3471\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31856\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.2656 - val_loss: 0.3365\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31856\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.2451 - val_loss: 0.3359\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31856\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.2326 - val_loss: 0.3206\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31856\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.2183 - val_loss: 0.3253\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31856\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.2074 - val_loss: 0.3519\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31856\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.1982 - val_loss: 0.3201\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31856\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 0.1896 - val_loss: 0.3180\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.31856 to 0.31801, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.1819 - val_loss: 0.3196\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31801\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.1748 - val_loss: 0.3181\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.31801\n",
      "Epoch 15/100\n",
      " - 2s - loss: 0.1673 - val_loss: 0.3213\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.31801\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.1621 - val_loss: 0.3158\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.31801 to 0.31576, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 17/100\n",
      " - 2s - loss: 0.1553 - val_loss: 0.3227\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.31576\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.1506 - val_loss: 0.3285\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.31576\n",
      "Epoch 19/100\n",
      " - 3s - loss: 0.1454 - val_loss: 0.3212\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.31576\n",
      "Epoch 20/100\n",
      " - 2s - loss: 0.1404 - val_loss: 0.3196\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.31576\n",
      "Epoch 21/100\n",
      " - 2s - loss: 0.1332 - val_loss: 0.3243\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.31576\n",
      "Epoch 00021: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.3185 - val_loss: 0.7814\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31576\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.6205 - val_loss: 0.5233\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31576\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.4060 - val_loss: 0.3931\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31576\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.3220 - val_loss: 0.3643\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31576\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.2870 - val_loss: 0.3543\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31576\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.2631 - val_loss: 0.3354\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31576\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.2466 - val_loss: 0.3416\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31576\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.2319 - val_loss: 0.3320\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31576\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.2208 - val_loss: 0.3283\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31576\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.2109 - val_loss: 0.3308\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31576\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.2023 - val_loss: 0.3271\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31576\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.1954 - val_loss: 0.3307\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31576\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.1876 - val_loss: 0.3295\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31576\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.1833 - val_loss: 0.3324\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.31576\n",
      "Epoch 15/100\n",
      " - 2s - loss: 0.1742 - val_loss: 0.3344\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.31576\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.1681 - val_loss: 0.3424\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.31576\n",
      "Epoch 00016: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model training with Stochastic gradient descent optimizer(SGD).\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_sgd.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_sgd = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [5.1745205]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.7011952]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [3.7546391]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 5.0, predicted Stars: [3.8918414]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 2.5, predicted Stars: [2.5711584]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.4422555]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [4.1195154]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.2732162]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 4.0, predicted Stars: [3.8707886]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.5, predicted Stars: [4.8203497]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_sgd[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5619208812713623\n",
      "R2 score: 0.69\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_sgd = np.sqrt(mean_squared_error(y_test_reg,pred_reg_sgd))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_sgd))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** RMSProp **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_rmsprop.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.3005 - val_loss: 0.3905\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39054, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2986 - val_loss: 0.3437\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.39054 to 0.34370, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2378 - val_loss: 0.3331\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.34370 to 0.33305, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2080 - val_loss: 0.3729\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.33305\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1817 - val_loss: 0.3449\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.33305\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1603 - val_loss: 0.3332\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.33305\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1369 - val_loss: 0.3289\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.33305 to 0.32887, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1175 - val_loss: 0.3665\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32887\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0968 - val_loss: 0.3296\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.32887\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0826 - val_loss: 0.3452\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.32887\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0704 - val_loss: 0.3522\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.32887\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.0600 - val_loss: 0.3394\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.32887\n",
      "Epoch 00012: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.8768 - val_loss: 0.4170\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32887\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3124 - val_loss: 0.3516\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32887\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2425 - val_loss: 0.3275\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32887 to 0.32746, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2090 - val_loss: 0.3240\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.32746 to 0.32395, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1824 - val_loss: 0.3256\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32395\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1540 - val_loss: 0.3232\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.32395 to 0.32317, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1290 - val_loss: 0.3249\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32317\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1047 - val_loss: 0.3200\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.32317 to 0.31996, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0871 - val_loss: 0.3264\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31996\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0693 - val_loss: 0.3226\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31996\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0571 - val_loss: 0.3360\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31996\n",
      "Epoch 12/100\n",
      " - 4s - loss: 0.0495 - val_loss: 0.3387\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31996\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.0440 - val_loss: 0.3310\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31996\n",
      "Epoch 00013: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.1687 - val_loss: 0.3912\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31996\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2860 - val_loss: 0.3368\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31996\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2313 - val_loss: 0.3360\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31996\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1932 - val_loss: 0.3419\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31996\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1579 - val_loss: 0.3660\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31996\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1246 - val_loss: 0.3248\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31996\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0999 - val_loss: 0.3237\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31996\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0810 - val_loss: 0.3193\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.31996 to 0.31929, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0662 - val_loss: 0.3310\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31929\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0569 - val_loss: 0.3311\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31929\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0480 - val_loss: 0.3386\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31929\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.0423 - val_loss: 0.3243\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31929\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.0382 - val_loss: 0.3334\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31929\n",
      "Epoch 00013: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.4585 - val_loss: 0.3904\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31929\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3012 - val_loss: 0.3426\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31929\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2419 - val_loss: 0.3285\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31929\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2104 - val_loss: 0.3332\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31929\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1822 - val_loss: 0.4195\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31929\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1558 - val_loss: 0.3219\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31929\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1294 - val_loss: 0.3277\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31929\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1085 - val_loss: 0.3162\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.31929 to 0.31623, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0889 - val_loss: 0.3164\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31623\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0738 - val_loss: 0.3276\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31623\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0633 - val_loss: 0.3247\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31623\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.0552 - val_loss: 0.3395\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31623\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.0474 - val_loss: 0.3325\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31623\n",
      "Epoch 00013: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.1916 - val_loss: 0.3883\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31623\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2904 - val_loss: 0.3571\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31623\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2305 - val_loss: 0.3450\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31623\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1958 - val_loss: 0.3284\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31623\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1619 - val_loss: 0.3312\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31623\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1306 - val_loss: 0.3151\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.31623 to 0.31510, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1022 - val_loss: 0.3232\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31510\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0827 - val_loss: 0.3244\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31510\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0669 - val_loss: 0.3360\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31510\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0558 - val_loss: 0.3213\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31510\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0482 - val_loss: 0.3533\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31510\n",
      "Epoch 00011: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.4607 - val_loss: 0.4040\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31510\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3027 - val_loss: 0.3745\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31510\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2401 - val_loss: 0.3255\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31510\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2071 - val_loss: 0.3281\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31510\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1773 - val_loss: 0.3220\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31510\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1501 - val_loss: 0.3410\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31510\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1239 - val_loss: 0.3206\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31510\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 3s - loss: 0.1035 - val_loss: 0.3361\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31510\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0847 - val_loss: 0.3201\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31510\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0705 - val_loss: 0.3243\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31510\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0601 - val_loss: 0.3535\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31510\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.0509 - val_loss: 0.3357\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31510\n",
      "Epoch 00012: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.2305 - val_loss: 0.3863\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31510\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2967 - val_loss: 0.3532\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31510\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2400 - val_loss: 0.3319\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31510\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2073 - val_loss: 0.3367\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31510\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1813 - val_loss: 0.3435\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31510\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1535 - val_loss: 0.3404\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31510\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1268 - val_loss: 0.3214\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31510\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1055 - val_loss: 0.3245\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31510\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0868 - val_loss: 0.3461\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31510\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0725 - val_loss: 0.3189\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31510\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0621 - val_loss: 0.3292\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31510\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.0542 - val_loss: 0.3331\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31510\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.0461 - val_loss: 0.3289\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31510\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.0419 - val_loss: 0.3463\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.31510\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.0382 - val_loss: 0.3296\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.31510\n",
      "Epoch 00015: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.1034 - val_loss: 0.3839\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31510\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2881 - val_loss: 0.3686\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31510\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2310 - val_loss: 0.3508\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31510\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1929 - val_loss: 0.3645\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31510\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1624 - val_loss: 0.3329\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31510\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1328 - val_loss: 0.3308\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31510\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1090 - val_loss: 0.3246\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31510\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0865 - val_loss: 0.3229\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31510\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0704 - val_loss: 0.3347\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31510\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0592 - val_loss: 0.3593\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31510\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0510 - val_loss: 0.3343\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31510\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.0438 - val_loss: 0.3262\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31510\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.0409 - val_loss: 0.3501\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31510\n",
      "Epoch 00013: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.1385 - val_loss: 0.3948\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31510\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2946 - val_loss: 0.3629\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31510\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2372 - val_loss: 0.3393\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31510\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2025 - val_loss: 0.3431\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31510\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1729 - val_loss: 0.3327\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31510\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1452 - val_loss: 0.3302\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31510\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1180 - val_loss: 0.3197\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31510\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0954 - val_loss: 0.3453\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31510\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0786 - val_loss: 0.3208\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31510\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0649 - val_loss: 0.3433\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31510\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0553 - val_loss: 0.3239\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31510\n",
      "Epoch 12/100\n",
      " - 4s - loss: 0.0480 - val_loss: 0.3308\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31510\n",
      "Epoch 00012: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 1.0753 - val_loss: 0.3943\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31510\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2917 - val_loss: 0.3439\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31510\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2357 - val_loss: 0.3364\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31510\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1981 - val_loss: 0.3282\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31510\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1610 - val_loss: 0.3237\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31510\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1318 - val_loss: 0.3263\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31510\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1074 - val_loss: 0.3193\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31510\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0873 - val_loss: 0.3167\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31510\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0709 - val_loss: 0.3295\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31510\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0578 - val_loss: 0.3417\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31510\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0517 - val_loss: 0.3252\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31510\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.0451 - val_loss: 0.3150\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.31510 to 0.31503, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.0385 - val_loss: 0.3173\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31503\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.0352 - val_loss: 0.3185\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.31503\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.0327 - val_loss: 0.3124\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.31503 to 0.31238, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 16/100\n",
      " - 3s - loss: 0.0305 - val_loss: 0.3228\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.31238\n",
      "Epoch 17/100\n",
      " - 3s - loss: 0.0277 - val_loss: 0.3203\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.31238\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.0265 - val_loss: 0.3247\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.31238\n",
      "Epoch 19/100\n",
      " - 3s - loss: 0.0248 - val_loss: 0.3096\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.31238 to 0.30956, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 20/100\n",
      " - 3s - loss: 0.0242 - val_loss: 0.3190\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.30956\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.0228 - val_loss: 0.3134\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.30956\n",
      "Epoch 22/100\n",
      " - 3s - loss: 0.0216 - val_loss: 0.3381\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.30956\n",
      "Epoch 23/100\n",
      " - 3s - loss: 0.0207 - val_loss: 0.3185\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.30956\n",
      "Epoch 24/100\n",
      " - 3s - loss: 0.0206 - val_loss: 0.3152\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.30956\n",
      "Epoch 00024: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model training with RMSProp optimizer.\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_rmsprop.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_rmsprop = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [4.869574]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.5951164]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [3.4641051]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 5.0, predicted Stars: [4.3006268]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 2.5, predicted Stars: [2.5696065]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [4.589199]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [3.747323]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.2644005]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 4.0, predicted Stars: [4.4606256]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.5, predicted Stars: [4.549286]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_rmsprop[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5563821196556091\n",
      "R2 score: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_rmsprop = np.sqrt(mean_squared_error(y_test_reg,pred_reg_rmsprop))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_rmsprop))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_rmsprop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Adagrad **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_adagrad.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.7942 - val_loss: 0.4038\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.40379, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2672 - val_loss: 0.3663\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.40379 to 0.36630, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2009 - val_loss: 0.3595\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36630 to 0.35953, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1650 - val_loss: 0.3488\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35953 to 0.34880, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1379 - val_loss: 0.3518\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34880\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1154 - val_loss: 0.3522\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34880\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0954 - val_loss: 0.3556\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34880\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0784 - val_loss: 0.3537\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34880\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0642 - val_loss: 0.3574\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34880\n",
      "Epoch 00009: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.7881 - val_loss: 0.4075\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34880\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2611 - val_loss: 0.3809\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34880\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.1939 - val_loss: 0.3629\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34880\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1585 - val_loss: 0.3523\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34880\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1331 - val_loss: 0.3508\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34880\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1133 - val_loss: 0.3512\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34880\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0953 - val_loss: 0.3548\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34880\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0798 - val_loss: 0.3594\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34880\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0655 - val_loss: 0.3575\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34880\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0536 - val_loss: 0.3613\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34880\n",
      "Epoch 00010: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 0.7948 - val_loss: 0.4029\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34880\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2622 - val_loss: 0.3669\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34880\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.1956 - val_loss: 0.3568\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34880\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1597 - val_loss: 0.3557\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34880\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1337 - val_loss: 0.3566\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34880\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1131 - val_loss: 0.3559\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34880\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0945 - val_loss: 0.3555\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34880\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0778 - val_loss: 0.3632\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34880\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0635 - val_loss: 0.3621\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34880\n",
      "Epoch 00009: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.7134 - val_loss: 0.3924\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34880\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2490 - val_loss: 0.3507\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34880\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.1837 - val_loss: 0.3449\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.34880 to 0.34494, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1494 - val_loss: 0.3409\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.34494 to 0.34092, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1246 - val_loss: 0.3443\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34092\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1051 - val_loss: 0.3420\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34092\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0882 - val_loss: 0.3479\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34092\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0732 - val_loss: 0.3487\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34092\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0604 - val_loss: 0.3488\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34092\n",
      "Epoch 00009: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.7557 - val_loss: 0.4030\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34092\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2614 - val_loss: 0.3662\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34092\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.1930 - val_loss: 0.3557\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34092\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1592 - val_loss: 0.3547\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34092\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1361 - val_loss: 0.3516\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34092\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1182 - val_loss: 0.3592\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34092\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1037 - val_loss: 0.3588\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34092\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0913 - val_loss: 0.3604\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34092\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0804 - val_loss: 0.3644\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34092\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0703 - val_loss: 0.3684\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34092\n",
      "Epoch 00010: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.6992 - val_loss: 0.4057\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34092\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2575 - val_loss: 0.3653\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34092\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.1940 - val_loss: 0.3618\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34092\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1627 - val_loss: 0.3578\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34092\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1408 - val_loss: 0.3571\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34092\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1248 - val_loss: 0.3606\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34092\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1098 - val_loss: 0.3624\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34092\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0970 - val_loss: 0.3735\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34092\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0840 - val_loss: 0.3806\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34092\n",
      "Epoch 00009: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.8783 - val_loss: 0.4150\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34092\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2792 - val_loss: 0.3689\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34092\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2102 - val_loss: 0.3588\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34092\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1731 - val_loss: 0.3514\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34092\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1481 - val_loss: 0.3528\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34092\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1298 - val_loss: 0.3482\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34092\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1143 - val_loss: 0.3554\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34092\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.1005 - val_loss: 0.3513\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34092\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0871 - val_loss: 0.3529\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34092\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0745 - val_loss: 0.3645\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34092\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0632 - val_loss: 0.3590\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.34092\n",
      "Epoch 00011: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.7882 - val_loss: 0.4178\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34092\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2711 - val_loss: 0.3757\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34092\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2046 - val_loss: 0.3625\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34092\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 3s - loss: 0.1681 - val_loss: 0.3542\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34092\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1422 - val_loss: 0.3594\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34092\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1209 - val_loss: 0.3565\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34092\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1028 - val_loss: 0.3591\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34092\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0870 - val_loss: 0.3575\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34092\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0725 - val_loss: 0.3589\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34092\n",
      "Epoch 00009: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.8217 - val_loss: 0.4295\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34092\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2672 - val_loss: 0.3649\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34092\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.1977 - val_loss: 0.3559\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34092\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1616 - val_loss: 0.3487\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34092\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1369 - val_loss: 0.3474\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34092\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1174 - val_loss: 0.3514\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34092\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1011 - val_loss: 0.3517\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34092\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0867 - val_loss: 0.3539\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34092\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0735 - val_loss: 0.3594\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34092\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.0618 - val_loss: 0.3612\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34092\n",
      "Epoch 00010: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.7686 - val_loss: 0.4006\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34092\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2607 - val_loss: 0.3636\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34092\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.1932 - val_loss: 0.3541\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34092\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1555 - val_loss: 0.3484\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34092\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1301 - val_loss: 0.3537\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34092\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1099 - val_loss: 0.3522\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34092\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.0928 - val_loss: 0.3549\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34092\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0779 - val_loss: 0.3601\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34092\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0648 - val_loss: 0.3599\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34092\n",
      "Epoch 00009: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model training with Adagrad.\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adagrad')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_adagrad.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_adagrad = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [5.160581]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.2411199]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [3.7054992]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 5.0, predicted Stars: [3.724305]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 2.5, predicted Stars: [2.3649683]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.6233296]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [4.0357356]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.4179277]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 4.0, predicted Stars: [4.2212996]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.5, predicted Stars: [4.939703]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_adagrad[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5838866233825684\n",
      "R2 score: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_adagrad = np.sqrt(mean_squared_error(y_test_reg,pred_reg_adagrad))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_adagrad))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_adagrad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Adadelta **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_adadelta.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 0.9989 - val_loss: 0.3713\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37126, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2822 - val_loss: 0.3283\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37126 to 0.32831, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2366 - val_loss: 0.3231\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32831 to 0.32309, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2054 - val_loss: 0.3182\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.32309 to 0.31824, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1818 - val_loss: 0.3219\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31824\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1564 - val_loss: 0.3382\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31824\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1297 - val_loss: 0.3245\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31824\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.1090 - val_loss: 0.3330\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31824\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.0878 - val_loss: 0.3284\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31824\n",
      "Epoch 00009: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.1212 - val_loss: 0.3618\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31824\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2832 - val_loss: 0.3599\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31824\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2297 - val_loss: 0.3202\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31824\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2028 - val_loss: 0.3217\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31824\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1747 - val_loss: 0.3180\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.31824 to 0.31804, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1455 - val_loss: 0.3309\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31804\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1171 - val_loss: 0.3190\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31804\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0953 - val_loss: 0.3190\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31804\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0760 - val_loss: 0.3173\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.31804 to 0.31729, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.0609 - val_loss: 0.3300\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31729\n",
      "Epoch 00010: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.0694 - val_loss: 0.3987\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31729\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2817 - val_loss: 0.3414\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31729\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2341 - val_loss: 0.3240\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31729\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2036 - val_loss: 0.3419\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31729\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1769 - val_loss: 0.3350\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31729\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1459 - val_loss: 0.3752\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31729\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1180 - val_loss: 0.3288\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31729\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0973 - val_loss: 0.3249\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31729\n",
      "Epoch 00008: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 1.2157 - val_loss: 0.3791\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31729\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2811 - val_loss: 0.3679\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31729\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2325 - val_loss: 0.3271\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31729\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2026 - val_loss: 0.3192\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31729\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1760 - val_loss: 0.3605\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31729\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1500 - val_loss: 0.3188\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31729\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1207 - val_loss: 0.3485\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31729\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0991 - val_loss: 0.3335\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31729\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0765 - val_loss: 0.3253\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31729\n",
      "Epoch 00009: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.1531 - val_loss: 0.3677\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31729\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2796 - val_loss: 0.3361\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31729\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2301 - val_loss: 0.3304\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31729\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2034 - val_loss: 0.3233\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31729\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1775 - val_loss: 0.3206\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31729\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1512 - val_loss: 0.3148\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.31729 to 0.31479, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1237 - val_loss: 0.3181\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31479\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.0993 - val_loss: 0.3361\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31479\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0834 - val_loss: 0.3251\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31479\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.0679 - val_loss: 0.3237\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31479\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.0557 - val_loss: 0.3340\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31479\n",
      "Epoch 00011: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.0845 - val_loss: 0.3784\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31479\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2739 - val_loss: 0.3278\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31479\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2275 - val_loss: 0.3270\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31479\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2028 - val_loss: 0.3712\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31479\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1780 - val_loss: 0.3385\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31479\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1537 - val_loss: 0.3279\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31479\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1274 - val_loss: 0.3652\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31479\n",
      "Epoch 00007: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.1632 - val_loss: 0.3518\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31479\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2762 - val_loss: 0.3387\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31479\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2320 - val_loss: 0.3183\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31479\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2039 - val_loss: 0.3365\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31479\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1824 - val_loss: 0.3277\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31479\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1546 - val_loss: 0.3600\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31479\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1256 - val_loss: 0.3104\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.31479 to 0.31039, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.1061 - val_loss: 0.3089\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.31039 to 0.30893, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0816 - val_loss: 0.3238\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.30893\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.0686 - val_loss: 0.3333\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.30893\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.0566 - val_loss: 0.3290\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.30893\n",
      "Epoch 12/100\n",
      " - 4s - loss: 0.0486 - val_loss: 0.3205\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.30893\n",
      "Epoch 13/100\n",
      " - 4s - loss: 0.0431 - val_loss: 0.3423\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.30893\n",
      "Epoch 00013: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.2422 - val_loss: 0.3806\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30893\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2826 - val_loss: 0.3766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30893\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2344 - val_loss: 0.3235\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30893\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2047 - val_loss: 0.3213\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30893\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1813 - val_loss: 0.3268\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30893\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1540 - val_loss: 0.3499\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30893\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1278 - val_loss: 0.3217\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.30893\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.1016 - val_loss: 0.3235\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.30893\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0824 - val_loss: 0.3323\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.30893\n",
      "Epoch 00009: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.1903 - val_loss: 0.3556\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30893\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2789 - val_loss: 0.3130\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30893\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2299 - val_loss: 0.3127\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30893\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1990 - val_loss: 0.3196\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30893\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1694 - val_loss: 0.3260\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30893\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1410 - val_loss: 0.3670\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30893\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1131 - val_loss: 0.3468\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.30893\n",
      "Epoch 00007: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.1206 - val_loss: 0.3694\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30893\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2836 - val_loss: 0.3341\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30893\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2353 - val_loss: 0.3204\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30893\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1985 - val_loss: 0.3245\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30893\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1760 - val_loss: 0.3208\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30893\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1501 - val_loss: 0.3253\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30893\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1256 - val_loss: 0.3219\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.30893\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.1003 - val_loss: 0.3278\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.30893\n",
      "Epoch 00008: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model training with ADadelta.\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adadelta')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_adadelta.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_adadelta = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [4.974571]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.7325032]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [3.4754226]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 5.0, predicted Stars: [4.126101]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 2.5, predicted Stars: [2.6592624]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [4.0764556]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [3.7106316]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.1212463]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 4.0, predicted Stars: [4.017893]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.5, predicted Stars: [5.124168]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_adadelta[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5558121800422668\n",
      "R2 score: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_adadelta = np.sqrt(mean_squared_error(y_test_reg,pred_reg_adadelta))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_adadelta))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_adadelta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Adamax **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_adamax.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.9869 - val_loss: 0.5466\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.54659, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3767 - val_loss: 0.3788\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.54659 to 0.37875, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2703 - val_loss: 0.3358\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37875 to 0.33576, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2252 - val_loss: 0.3219\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.33576 to 0.32185, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1985 - val_loss: 0.3211\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.32185 to 0.32111, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1783 - val_loss: 0.3258\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32111\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1631 - val_loss: 0.3297\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32111\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1462 - val_loss: 0.3348\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32111\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.1323 - val_loss: 0.3392\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.32111\n",
      "Epoch 00009: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.7342 - val_loss: 0.5168\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32111\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3623 - val_loss: 0.3757\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32111\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2637 - val_loss: 0.3314\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32111\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2221 - val_loss: 0.3295\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32111\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1958 - val_loss: 0.3238\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32111\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1789 - val_loss: 0.3247\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32111\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1647 - val_loss: 0.3318\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32111\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.1503 - val_loss: 0.3352\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32111\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1380 - val_loss: 0.3515\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.32111\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.1265 - val_loss: 0.3472\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.32111\n",
      "Epoch 00010: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.8945 - val_loss: 0.5549\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32111\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3776 - val_loss: 0.3812\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32111\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2726 - val_loss: 0.3391\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32111\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2285 - val_loss: 0.3279\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32111\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.2015 - val_loss: 0.3226\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32111\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1828 - val_loss: 0.3264\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32111\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1672 - val_loss: 0.3306\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32111\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1545 - val_loss: 0.3319\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32111\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1403 - val_loss: 0.3424\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.32111\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.1309 - val_loss: 0.3489\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.32111\n",
      "Epoch 00010: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.9922 - val_loss: 0.5676\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32111\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3914 - val_loss: 0.3803\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32111\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2763 - val_loss: 0.3396\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32111\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2279 - val_loss: 0.3256\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32111\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.2002 - val_loss: 0.3254\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32111\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1808 - val_loss: 0.3240\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32111\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1639 - val_loss: 0.3312\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32111\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.1486 - val_loss: 0.3296\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32111\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1351 - val_loss: 0.3427\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.32111\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.1217 - val_loss: 0.3416\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.32111\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.1078 - val_loss: 0.3580\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.32111\n",
      "Epoch 00011: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.5845 - val_loss: 0.4557\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32111\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3307 - val_loss: 0.3448\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32111\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2439 - val_loss: 0.3233\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32111\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2075 - val_loss: 0.3204\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.32111 to 0.32036, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1841 - val_loss: 0.3281\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32036\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1648 - val_loss: 0.3400\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32036\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1482 - val_loss: 0.3375\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32036\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1302 - val_loss: 0.3446\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32036\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1149 - val_loss: 0.3507\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.32036\n",
      "Epoch 00009: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.6980 - val_loss: 0.5002\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32036\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3506 - val_loss: 0.3593\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32036\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2530 - val_loss: 0.3271\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32036\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2111 - val_loss: 0.3280\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32036\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1855 - val_loss: 0.3316\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32036\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1664 - val_loss: 0.3373\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32036\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1479 - val_loss: 0.3421\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32036\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1339 - val_loss: 0.3460\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32036\n",
      "Epoch 00008: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 1.8154 - val_loss: 0.5057\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32036\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3557 - val_loss: 0.3613\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32036\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2583 - val_loss: 0.3358\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32036\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2190 - val_loss: 0.3189\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.32036 to 0.31894, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1928 - val_loss: 0.3224\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31894\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1734 - val_loss: 0.3267\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31894\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1564 - val_loss: 0.3339\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31894\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1409 - val_loss: 0.3372\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31894\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1261 - val_loss: 0.3449\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31894\n",
      "Epoch 00009: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.6266 - val_loss: 0.5286\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31894\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.3634 - val_loss: 0.3772\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31894\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2643 - val_loss: 0.3371\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31894\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2228 - val_loss: 0.3298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31894\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1978 - val_loss: 0.3265\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31894\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1805 - val_loss: 0.3545\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31894\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1676 - val_loss: 0.3366\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31894\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1531 - val_loss: 0.3362\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31894\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.1406 - val_loss: 0.3454\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31894\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.1304 - val_loss: 0.3498\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31894\n",
      "Epoch 00010: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.5268 - val_loss: 0.4584\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31894\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3270 - val_loss: 0.3523\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31894\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2445 - val_loss: 0.3231\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31894\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2074 - val_loss: 0.3230\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31894\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.1842 - val_loss: 0.3231\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31894\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1670 - val_loss: 0.3319\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31894\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1496 - val_loss: 0.3353\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31894\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1348 - val_loss: 0.3434\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31894\n",
      "Epoch 00008: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 2.5552 - val_loss: 0.6482\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31894\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.4169 - val_loss: 0.3911\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31894\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2846 - val_loss: 0.3400\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31894\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.2315 - val_loss: 0.3237\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31894\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.2008 - val_loss: 0.3258\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31894\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.1779 - val_loss: 0.3204\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31894\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1569 - val_loss: 0.3235\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31894\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.1388 - val_loss: 0.3248\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31894\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.1207 - val_loss: 0.3278\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.31894\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.1033 - val_loss: 0.3302\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31894\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.0865 - val_loss: 0.3294\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31894\n",
      "Epoch 00011: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model training with Adamax.\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adamax')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100)\n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_adamax.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_adamax = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [5.135452]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.3520615]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [3.5837724]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 5.0, predicted Stars: [3.8185892]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 2.5, predicted Stars: [2.4812694]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.5921934]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [4.378864]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.225172]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 4.0, predicted Stars: [4.2369123]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.5, predicted Stars: [5.0254517]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_adamax[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5647493004798889\n",
      "R2 score: 0.69\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_adamax = np.sqrt(mean_squared_error(y_test_reg,pred_reg_adamax))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_adamax))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_adamax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Nadam **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_nadam.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 1.0294 - val_loss: 0.4501\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45008, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2728 - val_loss: 0.3973\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45008 to 0.39729, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.1900 - val_loss: 0.3872\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.39729 to 0.38720, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1520 - val_loss: 0.3910\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38720\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1151 - val_loss: 0.3846\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.38720 to 0.38461, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0930 - val_loss: 0.3962\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38461\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0761 - val_loss: 0.3958\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38461\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0592 - val_loss: 0.3981\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38461\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.0494 - val_loss: 0.3997\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38461\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.0439 - val_loss: 0.3951\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38461\n",
      "Epoch 00010: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.2491 - val_loss: 0.4364\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38461\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2741 - val_loss: 0.4339\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38461\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1934 - val_loss: 0.3822\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38461 to 0.38224, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1546 - val_loss: 0.4082\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38224\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1282 - val_loss: 0.3894\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38224\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1050 - val_loss: 0.4046\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38224\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0880 - val_loss: 0.4072\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38224\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0704 - val_loss: 0.4000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38224\n",
      "Epoch 00008: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.2132 - val_loss: 0.4245\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38224\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2762 - val_loss: 0.3951\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38224\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2002 - val_loss: 0.3854\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38224\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1605 - val_loss: 0.3931\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38224\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1327 - val_loss: 0.3943\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38224\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1077 - val_loss: 0.3868\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38224\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0878 - val_loss: 0.3956\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38224\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0728 - val_loss: 0.4014\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38224\n",
      "Epoch 00008: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.2026 - val_loss: 0.4390\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38224\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2824 - val_loss: 0.3864\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38224\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1984 - val_loss: 0.3840\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38224\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1563 - val_loss: 0.4031\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38224\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1265 - val_loss: 0.3902\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38224\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.0957 - val_loss: 0.3887\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38224\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0773 - val_loss: 0.4019\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38224\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0607 - val_loss: 0.4001\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38224\n",
      "Epoch 00008: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.1671 - val_loss: 0.4357\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38224\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2761 - val_loss: 0.3862\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38224\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.1977 - val_loss: 0.4111\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38224\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1585 - val_loss: 0.3808\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.38224 to 0.38075, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1228 - val_loss: 0.3940\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38075\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0974 - val_loss: 0.3935\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.38075\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0769 - val_loss: 0.4026\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38075\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0608 - val_loss: 0.4008\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38075\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0512 - val_loss: 0.4038\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38075\n",
      "Epoch 00009: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.3621 - val_loss: 0.4653\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.38075\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2748 - val_loss: 0.3800\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.38075 to 0.37995, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.1907 - val_loss: 0.3982\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.37995\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1492 - val_loss: 0.3800\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.37995\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1125 - val_loss: 0.4195\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.37995\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.0866 - val_loss: 0.3963\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.37995\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0663 - val_loss: 0.3926\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.37995\n",
      "Epoch 00007: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.1191 - val_loss: 0.4149\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.37995\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2712 - val_loss: 0.3652\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37995 to 0.36516, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.1905 - val_loss: 0.3708\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36516\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1523 - val_loss: 0.3746\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36516\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1233 - val_loss: 0.3818\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36516\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.0973 - val_loss: 0.3806\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36516\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0772 - val_loss: 0.3731\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36516\n",
      "Epoch 00007: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.3710 - val_loss: 0.4687\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36516\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2682 - val_loss: 0.3678\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36516\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1842 - val_loss: 0.4467\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36516\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1419 - val_loss: 0.3708\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36516\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1087 - val_loss: 0.3703\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36516\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.0799 - val_loss: 0.3608\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.36516 to 0.36079, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0619 - val_loss: 0.3661\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36079\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0479 - val_loss: 0.3685\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36079\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0391 - val_loss: 0.3584\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.36079 to 0.35840, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.0317 - val_loss: 0.3617\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.35840\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.0273 - val_loss: 0.3631\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.35840\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 4s - loss: 0.0244 - val_loss: 0.3530\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.35840 to 0.35298, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 13/100\n",
      " - 4s - loss: 0.0232 - val_loss: 0.3622\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.35298\n",
      "Epoch 14/100\n",
      " - 4s - loss: 0.0214 - val_loss: 0.3544\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.35298\n",
      "Epoch 15/100\n",
      " - 4s - loss: 0.0213 - val_loss: 0.3520\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.35298 to 0.35197, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 16/100\n",
      " - 5s - loss: 0.0204 - val_loss: 0.3559\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.35197\n",
      "Epoch 17/100\n",
      " - 4s - loss: 0.0202 - val_loss: 0.3540\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.35197\n",
      "Epoch 18/100\n",
      " - 4s - loss: 0.0189 - val_loss: 0.3572\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.35197\n",
      "Epoch 19/100\n",
      " - 4s - loss: 0.0184 - val_loss: 0.3472\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.35197 to 0.34724, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 20/100\n",
      " - 4s - loss: 0.0160 - val_loss: 0.3458\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.34724 to 0.34580, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 21/100\n",
      " - 4s - loss: 0.0161 - val_loss: 0.3463\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.34580\n",
      "Epoch 22/100\n",
      " - 4s - loss: 0.0164 - val_loss: 0.3458\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.34580\n",
      "Epoch 23/100\n",
      " - 4s - loss: 0.0154 - val_loss: 0.3430\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.34580 to 0.34302, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 24/100\n",
      " - 4s - loss: 0.0132 - val_loss: 0.3403\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.34302 to 0.34034, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 25/100\n",
      " - 4s - loss: 0.0126 - val_loss: 0.3460\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34034\n",
      "Epoch 26/100\n",
      " - 4s - loss: 0.0124 - val_loss: 0.3440\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34034\n",
      "Epoch 27/100\n",
      " - 4s - loss: 0.0133 - val_loss: 0.3401\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.34034 to 0.34014, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 28/100\n",
      " - 4s - loss: 0.0134 - val_loss: 0.3448\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.34014\n",
      "Epoch 29/100\n",
      " - 4s - loss: 0.0128 - val_loss: 0.3401\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.34014 to 0.34010, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 00029: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.0449 - val_loss: 0.4259\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34010\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2720 - val_loss: 0.3799\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34010\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.1965 - val_loss: 0.3773\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34010\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1545 - val_loss: 0.3799\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34010\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1235 - val_loss: 0.4101\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34010\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.0997 - val_loss: 0.3877\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34010\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0776 - val_loss: 0.3834\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34010\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0629 - val_loss: 0.3814\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34010\n",
      "Epoch 00008: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.1359 - val_loss: 0.4324\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34010\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2691 - val_loss: 0.4080\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34010\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.1930 - val_loss: 0.3848\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34010\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1532 - val_loss: 0.3811\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34010\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1183 - val_loss: 0.3902\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34010\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.0931 - val_loss: 0.3792\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34010\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0716 - val_loss: 0.3776\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34010\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0560 - val_loss: 0.3907\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34010\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0460 - val_loss: 0.3791\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34010\n",
      "Epoch 10/100\n",
      " - 5s - loss: 0.0380 - val_loss: 0.3805\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34010\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.0326 - val_loss: 0.3838\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.34010\n",
      "Epoch 12/100\n",
      " - 6s - loss: 0.0304 - val_loss: 0.3791\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.34010\n",
      "Epoch 00012: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model training with Nadam.\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='nadam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_nadam.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_nadam = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [4.8099]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.1851962]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [3.6482627]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 5.0, predicted Stars: [3.824267]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 2.5, predicted Stars: [2.6786616]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [4.060901]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [3.7193618]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [3.8800077]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 4.0, predicted Stars: [4.365294]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.5, predicted Stars: [4.80472]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_nadam[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5831780433654785\n",
      "R2 score: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_nadam = np.sqrt(mean_squared_error(y_test_reg,pred_reg_nadam))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_nadam))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_nadam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot to show the best optimizer\n",
    "\n",
    "score_list_reg_opt=[score_reg_relu_stopping,score_relu_sgd,score_relu_rmsprop, score_relu_adagrad,score_relu_adadelta,score_relu_adamax,score_relu_nadam]\n",
    "names =['adam','SGD','RMSprop','Adagrad', 'Adadelta','Adamax','Nadam']\n",
    "tick_marks = np.arange(len(names))\n",
    "plt.bar(range(len(score_list_reg_opt)), score_list_reg_opt)\n",
    "plt.xticks(tick_marks, names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with Hidden nodes selection in hidden layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2hidden Layers with adam optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_2l.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 2.1888 - val_loss: 0.4819\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.48191, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3219 - val_loss: 0.3737\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.48191 to 0.37369, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2126 - val_loss: 0.3666\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37369 to 0.36657, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1606 - val_loss: 0.3748\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36657\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1287 - val_loss: 0.3757\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36657\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1010 - val_loss: 0.3960\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36657\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0813 - val_loss: 0.3934\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36657\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0672 - val_loss: 0.3998\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36657\n",
      "Epoch 00008: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 1.9449 - val_loss: 0.4618\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36657\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3090 - val_loss: 0.4140\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36657\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2040 - val_loss: 0.3847\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36657\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1594 - val_loss: 0.3725\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36657\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1317 - val_loss: 0.3855\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36657\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1092 - val_loss: 0.3909\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36657\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0896 - val_loss: 0.3956\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36657\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0724 - val_loss: 0.4106\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36657\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0606 - val_loss: 0.4279\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.36657\n",
      "Epoch 00009: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 2.5994 - val_loss: 0.5160\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36657\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3316 - val_loss: 0.3902\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36657\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2173 - val_loss: 0.3737\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36657\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1649 - val_loss: 0.3773\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36657\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1287 - val_loss: 0.3759\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36657\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1044 - val_loss: 0.3881\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36657\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0833 - val_loss: 0.3904\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36657\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0675 - val_loss: 0.3946\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36657\n",
      "Epoch 00008: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 1.6346 - val_loss: 0.4979\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36657\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3315 - val_loss: 0.3920\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36657\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2224 - val_loss: 0.3827\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36657\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1772 - val_loss: 0.3810\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36657\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1507 - val_loss: 0.3813\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36657\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1298 - val_loss: 0.3825\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36657\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1135 - val_loss: 0.3934\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36657\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0969 - val_loss: 0.4036\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36657\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.0821 - val_loss: 0.3982\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.36657\n",
      "Epoch 00009: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 2.0674 - val_loss: 0.4924\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36657\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3274 - val_loss: 0.3808\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36657\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2144 - val_loss: 0.3722\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36657\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1680 - val_loss: 0.3724\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36657\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1394 - val_loss: 0.3835\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36657\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1196 - val_loss: 0.3901\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36657\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1021 - val_loss: 0.3937\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36657\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0848 - val_loss: 0.3938\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36657\n",
      "Epoch 00008: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 2.0000 - val_loss: 0.5337\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36657\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3501 - val_loss: 0.3997\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36657\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2334 - val_loss: 0.3662\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36657 to 0.36625, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1833 - val_loss: 0.3867\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36625\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1543 - val_loss: 0.3738\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36625\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1339 - val_loss: 0.3874\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36625\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1145 - val_loss: 0.3917\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36625\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0969 - val_loss: 0.3943\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36625\n",
      "Epoch 00008: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.9034 - val_loss: 0.5094\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36625\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3327 - val_loss: 0.3888\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36625\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2142 - val_loss: 0.3683\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36625\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1669 - val_loss: 0.3734\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36625\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1380 - val_loss: 0.3798\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36625\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1160 - val_loss: 0.3828\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36625\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0951 - val_loss: 0.3877\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36625\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0808 - val_loss: 0.3907\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36625\n",
      "Epoch 00008: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 1.9670 - val_loss: 0.4796\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36625\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3197 - val_loss: 0.4066\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36625\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.2151 - val_loss: 0.3773\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36625\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1718 - val_loss: 0.3727\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36625\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1442 - val_loss: 0.3941\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36625\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1263 - val_loss: 0.4001\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36625\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.1088 - val_loss: 0.4040\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36625\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0938 - val_loss: 0.4223\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36625\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.0815 - val_loss: 0.4099\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.36625\n",
      "Epoch 00009: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 2.4632 - val_loss: 0.5864\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36625\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3723 - val_loss: 0.4029\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36625\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.2369 - val_loss: 0.3808\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36625\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1809 - val_loss: 0.3724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36625\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1465 - val_loss: 0.3677\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36625\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1195 - val_loss: 0.3819\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36625\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0969 - val_loss: 0.3968\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36625\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0788 - val_loss: 0.4097\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36625\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.0644 - val_loss: 0.4053\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.36625\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.0516 - val_loss: 0.4105\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.36625\n",
      "Epoch 00010: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 2.4323 - val_loss: 0.5123\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36625\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3400 - val_loss: 0.3877\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36625\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2177 - val_loss: 0.3661\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36625 to 0.36615, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1631 - val_loss: 0.3657\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.36615 to 0.36571, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1277 - val_loss: 0.3742\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36571\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1014 - val_loss: 0.3825\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36571\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0785 - val_loss: 0.3905\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36571\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0617 - val_loss: 0.3930\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36571\n",
      "Epoch 00008: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu'))  \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_2l.hdf5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_hl = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [5.1049814]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.080085]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [3.9044344]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 5.0, predicted Stars: [3.6088371]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 2.5, predicted Stars: [2.4052281]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.6562648]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [3.7468283]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.2008286]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 4.0, predicted Stars: [3.9779196]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.5, predicted Stars: [5.1368737]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_hl[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.6047360897064209\n",
      "R2 score: 0.65\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_2l = np.sqrt(mean_squared_error(y_test_reg,pred_reg_hl))\n",
    "print(\"Final score (RMSE): {}\".format(score_2l))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_hl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3Hidden Layers with adam optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_3l.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 1.9458 - val_loss: 0.4450\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44500, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2989 - val_loss: 0.3853\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44500 to 0.38528, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2016 - val_loss: 0.3664\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38528 to 0.36638, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1599 - val_loss: 0.3820\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36638\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1339 - val_loss: 0.3856\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36638\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1102 - val_loss: 0.3864\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36638\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0907 - val_loss: 0.3856\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36638\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0712 - val_loss: 0.3929\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36638\n",
      "Epoch 00008: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 1.8747 - val_loss: 0.4245\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36638\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2891 - val_loss: 0.3591\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.36638 to 0.35905, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.1966 - val_loss: 0.3647\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35905\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1545 - val_loss: 0.3661\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35905\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1228 - val_loss: 0.3694\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35905\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.0982 - val_loss: 0.3877\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35905\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0777 - val_loss: 0.3886\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35905\n",
      "Epoch 00007: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.6919 - val_loss: 0.4606\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35905\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2990 - val_loss: 0.3760\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35905\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2015 - val_loss: 0.3736\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35905\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1545 - val_loss: 0.3796\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35905\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1199 - val_loss: 0.3724\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35905\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.0910 - val_loss: 0.3750\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35905\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0700 - val_loss: 0.3792\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35905\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0535 - val_loss: 0.3850\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35905\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0429 - val_loss: 0.3924\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35905\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.0372 - val_loss: 0.3867\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.35905\n",
      "Epoch 00010: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 2.7716 - val_loss: 0.4928\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35905\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3301 - val_loss: 0.3727\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35905\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2189 - val_loss: 0.3570\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.35905 to 0.35702, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1765 - val_loss: 0.3643\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35702\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1480 - val_loss: 0.3667\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35702\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1255 - val_loss: 0.3698\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35702\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1021 - val_loss: 0.3710\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35702\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0835 - val_loss: 0.3800\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35702\n",
      "Epoch 00008: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.9294 - val_loss: 0.4843\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35702\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3142 - val_loss: 0.3810\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35702\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2112 - val_loss: 0.3699\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35702\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1642 - val_loss: 0.3655\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35702\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1312 - val_loss: 0.3749\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35702\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1063 - val_loss: 0.3780\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35702\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0813 - val_loss: 0.3802\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35702\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0649 - val_loss: 0.3855\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35702\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0506 - val_loss: 0.3850\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35702\n",
      "Epoch 00009: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 1.7242 - val_loss: 0.4570\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35702\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3116 - val_loss: 0.3931\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35702\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2076 - val_loss: 0.3829\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35702\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1646 - val_loss: 0.3885\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35702\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1361 - val_loss: 0.3800\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35702\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1181 - val_loss: 0.3866\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35702\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0977 - val_loss: 0.3988\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35702\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0832 - val_loss: 0.4132\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35702\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.0671 - val_loss: 0.4114\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35702\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.0551 - val_loss: 0.4099\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.35702\n",
      "Epoch 00010: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 3.2916 - val_loss: 0.5494\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35702\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3550 - val_loss: 0.3764\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35702\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.2157 - val_loss: 0.3576\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35702\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1611 - val_loss: 0.3709\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35702\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1241 - val_loss: 0.3633\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35702\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0950 - val_loss: 0.3914\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35702\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0704 - val_loss: 0.3735\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35702\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0520 - val_loss: 0.3909\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35702\n",
      "Epoch 00008: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 2.3313 - val_loss: 0.5065\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35702\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3313 - val_loss: 0.3996\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35702\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.2174 - val_loss: 0.3608\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35702\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.1724 - val_loss: 0.3899\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35702\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1455 - val_loss: 0.3721\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35702\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1250 - val_loss: 0.3741\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35702\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.1020 - val_loss: 0.3761\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35702\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0835 - val_loss: 0.3820\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35702\n",
      "Epoch 00008: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 2.2487 - val_loss: 0.4727\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35702\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3206 - val_loss: 0.3766\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35702\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 4s - loss: 0.2095 - val_loss: 0.3693\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35702\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1662 - val_loss: 0.3702\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35702\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1406 - val_loss: 0.3859\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35702\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1196 - val_loss: 0.3882\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35702\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1006 - val_loss: 0.4071\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35702\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0833 - val_loss: 0.4040\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35702\n",
      "Epoch 00008: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.9426 - val_loss: 0.4705\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35702\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3055 - val_loss: 0.3833\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35702\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.2020 - val_loss: 0.3668\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35702\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1492 - val_loss: 0.3668\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35702\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1124 - val_loss: 0.3960\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35702\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0851 - val_loss: 0.3910\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35702\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0659 - val_loss: 0.3856\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35702\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0521 - val_loss: 0.3772\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35702\n",
      "Epoch 00008: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu'))  \n",
    "    model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(10, activation='relu')) # Hidden 3\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_3l.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_hl_3 = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [5.2718616]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.1741922]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [3.6310928]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 5.0, predicted Stars: [3.4487543]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 2.5, predicted Stars: [2.2593913]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.4350264]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [4.284658]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.292638]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 4.0, predicted Stars: [3.9689474]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.5, predicted Stars: [4.7773023]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_hl_3[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.59750896692276\n",
      "R2 score: 0.65\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_3l = np.sqrt(mean_squared_error(y_test_reg,pred_reg_hl_3))\n",
    "print(\"Final score (RMSE): {}\".format(score_3l))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_hl_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4 Hidden Layers with adam optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_4l.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.9063 - val_loss: 0.4375\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43747, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.2913 - val_loss: 0.3691\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.43747 to 0.36909, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1988 - val_loss: 0.3569\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36909 to 0.35688, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.1492 - val_loss: 0.3763\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35688\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1203 - val_loss: 0.3795\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35688\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0914 - val_loss: 0.3872\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35688\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0709 - val_loss: 0.3906\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35688\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0547 - val_loss: 0.4079\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35688\n",
      "Epoch 00008: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.9469 - val_loss: 0.4268\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35688\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2884 - val_loss: 0.3785\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35688\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1937 - val_loss: 0.3592\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35688\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.1438 - val_loss: 0.3711\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35688\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1108 - val_loss: 0.3698\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35688\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0824 - val_loss: 0.3819\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35688\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0620 - val_loss: 0.3826\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35688\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0498 - val_loss: 0.3875\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35688\n",
      "Epoch 00008: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.7044 - val_loss: 0.4190\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35688\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2815 - val_loss: 0.3738\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35688\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1898 - val_loss: 0.3695\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35688\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.1458 - val_loss: 0.3703\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35688\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1103 - val_loss: 0.3700\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35688\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.0895 - val_loss: 0.3809\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35688\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0687 - val_loss: 0.3833\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35688\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.0512 - val_loss: 0.3778\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35688\n",
      "Epoch 00008: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 2.3972 - val_loss: 0.4534\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35688\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3049 - val_loss: 0.3778\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35688\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.2039 - val_loss: 0.3684\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35688\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1572 - val_loss: 0.3671\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35688\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1210 - val_loss: 0.3681\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35688\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.0904 - val_loss: 0.3851\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35688\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0681 - val_loss: 0.3743\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35688\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.0514 - val_loss: 0.3718\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35688\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.0392 - val_loss: 0.3808\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35688\n",
      "Epoch 00009: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.6597 - val_loss: 0.4157\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35688\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.2819 - val_loss: 0.3843\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35688\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1903 - val_loss: 0.3555\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.35688 to 0.35547, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.1453 - val_loss: 0.3721\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35547\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.1141 - val_loss: 0.3716\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35547\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0881 - val_loss: 0.3699\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35547\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0665 - val_loss: 0.3909\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35547\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.0517 - val_loss: 0.3946\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35547\n",
      "Epoch 00008: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.8557 - val_loss: 0.4164\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35547\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2828 - val_loss: 0.3696\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35547\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1871 - val_loss: 0.3670\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35547\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1378 - val_loss: 0.3803\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35547\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0990 - val_loss: 0.3711\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35547\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0690 - val_loss: 0.3686\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35547\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0537 - val_loss: 0.3712\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35547\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0417 - val_loss: 0.3718\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35547\n",
      "Epoch 00008: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 2.0136 - val_loss: 0.4701\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35547\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2996 - val_loss: 0.3684\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35547\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1961 - val_loss: 0.3827\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35547\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1487 - val_loss: 0.3693\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35547\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1186 - val_loss: 0.3743\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35547\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0932 - val_loss: 0.3902\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35547\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0741 - val_loss: 0.4020\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35547\n",
      "Epoch 00007: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 1.7519 - val_loss: 0.4234\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35547\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2876 - val_loss: 0.3791\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35547\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1943 - val_loss: 0.3704\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35547\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.1536 - val_loss: 0.3721\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35547\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1213 - val_loss: 0.3786\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35547\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0950 - val_loss: 0.3757\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35547\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0773 - val_loss: 0.3816\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35547\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.0636 - val_loss: 0.3890\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35547\n",
      "Epoch 00008: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 2.1514 - val_loss: 0.4855\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35547\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.3089 - val_loss: 0.3785\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35547\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.2029 - val_loss: 0.3640\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35547\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1551 - val_loss: 0.3774\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35547\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1177 - val_loss: 0.3739\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35547\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.0924 - val_loss: 0.3832\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35547\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0709 - val_loss: 0.3785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35547\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0563 - val_loss: 0.3970\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35547\n",
      "Epoch 00008: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 2.5644 - val_loss: 0.4593\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35547\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3021 - val_loss: 0.3750\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35547\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.2018 - val_loss: 0.3776\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35547\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1547 - val_loss: 0.3827\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35547\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1254 - val_loss: 0.3695\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35547\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0986 - val_loss: 0.3783\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35547\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0778 - val_loss: 0.3943\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35547\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0611 - val_loss: 0.3940\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35547\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.0489 - val_loss: 0.3936\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35547\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.0390 - val_loss: 0.3984\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.35547\n",
      "Epoch 00010: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(80, input_dim=x_train_reg.shape[1], activation='relu'))  \n",
    "    model_reg_relu.add(Dense(60, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(20, activation='relu')) # Hidden 3\n",
    "    model_reg_relu.add(Dense(10, activation='relu')) # Hidden 4\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_4l.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_hl_4 = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [5.252351]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.4988868]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [3.5443144]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 5.0, predicted Stars: [3.8369918]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 2.5, predicted Stars: [2.366735]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [4.0126057]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [3.7982235]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.000417]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 4.0, predicted Stars: [4.149415]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.5, predicted Stars: [5.051223]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_hl_4[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5962139368057251\n",
      "R2 score: 0.66\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_4l = np.sqrt(mean_squared_error(y_test_reg,pred_reg_hl_4))\n",
    "print(\"Final score (RMSE): {}\".format(score_4l))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_hl_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5 Hidden Layers with adam optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_5l.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.9864 - val_loss: 0.4081\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.40809, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2877 - val_loss: 0.3979\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.40809 to 0.39790, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1908 - val_loss: 0.3631\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.39790 to 0.36306, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.1459 - val_loss: 0.3667\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36306\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.1131 - val_loss: 0.3980\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36306\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0855 - val_loss: 0.3769\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36306\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0664 - val_loss: 0.3992\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36306\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0514 - val_loss: 0.3862\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36306\n",
      "Epoch 00008: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 2.3626 - val_loss: 0.4315\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36306\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2948 - val_loss: 0.3899\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.36306\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1971 - val_loss: 0.3704\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36306\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.1452 - val_loss: 0.3695\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36306\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1115 - val_loss: 0.4029\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36306\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0829 - val_loss: 0.3831\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36306\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0613 - val_loss: 0.3928\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36306\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0492 - val_loss: 0.3928\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36306\n",
      "Epoch 00008: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 1.3800 - val_loss: 0.3927\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.36306\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.2592 - val_loss: 0.3614\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.36306 to 0.36141, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.1742 - val_loss: 0.3703\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.36141\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.1254 - val_loss: 0.3718\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36141\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0865 - val_loss: 0.3677\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36141\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0601 - val_loss: 0.3588\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.36141 to 0.35884, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0470 - val_loss: 0.3612\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35884\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0380 - val_loss: 0.3590\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35884\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.0301 - val_loss: 0.3581\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35884 to 0.35811, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 10/100\n",
      " - 5s - loss: 0.0239 - val_loss: 0.3587\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.35811\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.0210 - val_loss: 0.3591\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.35811\n",
      "Epoch 00011: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 1.9203 - val_loss: 0.4170\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35811\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2819 - val_loss: 0.3668\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35811\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1946 - val_loss: 0.3692\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35811\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1529 - val_loss: 0.3698\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35811\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1201 - val_loss: 0.3765\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35811\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0911 - val_loss: 0.3722\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35811\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0665 - val_loss: 0.3832\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35811\n",
      "Epoch 00007: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 1.6605 - val_loss: 0.4044\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35811\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2682 - val_loss: 0.3769\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35811\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1874 - val_loss: 0.3753\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35811\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1452 - val_loss: 0.3639\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35811\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1124 - val_loss: 0.3698\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35811\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0829 - val_loss: 0.3755\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35811\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0594 - val_loss: 0.3740\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35811\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0456 - val_loss: 0.3735\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35811\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.0358 - val_loss: 0.3685\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35811\n",
      "Epoch 00009: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 1.8785 - val_loss: 0.4353\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35811\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2798 - val_loss: 0.3739\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35811\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1911 - val_loss: 0.3688\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35811\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1476 - val_loss: 0.3714\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35811\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1121 - val_loss: 0.3781\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35811\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0907 - val_loss: 0.3848\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35811\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0722 - val_loss: 0.3820\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35811\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0562 - val_loss: 0.4076\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35811\n",
      "Epoch 00008: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 1.5255 - val_loss: 0.4097\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35811\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2697 - val_loss: 0.3610\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35811\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1842 - val_loss: 0.3653\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35811\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1369 - val_loss: 0.3710\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35811\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1002 - val_loss: 0.3799\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35811\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0732 - val_loss: 0.3710\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35811\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0513 - val_loss: 0.3717\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35811\n",
      "Epoch 00007: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 1.7885 - val_loss: 0.4342\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35811\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2760 - val_loss: 0.3969\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35811\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1818 - val_loss: 0.3560\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.35811 to 0.35599, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1335 - val_loss: 0.3634\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35599\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0956 - val_loss: 0.3730\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35599\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0695 - val_loss: 0.3687\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35599\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0563 - val_loss: 0.3693\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35599\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0432 - val_loss: 0.3875\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35599\n",
      "Epoch 00008: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 2.1005 - val_loss: 0.4167\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35599\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2862 - val_loss: 0.3552\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.35599 to 0.35516, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1964 - val_loss: 0.3678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35516\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1541 - val_loss: 0.3702\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35516\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1203 - val_loss: 0.3674\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35516\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0892 - val_loss: 0.3859\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35516\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0659 - val_loss: 0.3748\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35516\n",
      "Epoch 00007: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.5811 - val_loss: 0.4095\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.35516\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2784 - val_loss: 0.3820\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.35516\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.1906 - val_loss: 0.3691\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35516\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.1447 - val_loss: 0.3800\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35516\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1118 - val_loss: 0.3706\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35516\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0844 - val_loss: 0.3870\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.35516\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0677 - val_loss: 0.3866\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35516\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0513 - val_loss: 0.3812\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35516\n",
      "Epoch 00008: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_relu = Sequential()\n",
    "\n",
    "    model_reg_relu.add(Dense(80, input_dim=x_train_reg.shape[1], activation='relu'))  \n",
    "    model_reg_relu.add(Dense(60, activation='relu')) # Hidden 2\n",
    "    model_reg_relu.add(Dense(40, activation='relu')) # Hidden 3\n",
    "    model_reg_relu.add(Dense(20, activation='relu')) # Hidden 4\n",
    "    model_reg_relu.add(Dense(10, activation='relu')) # Hidden 5\n",
    "    model_reg_relu.add(Dense(1)) # Output\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_relu.load_weights('./best_weights_relu_5l.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_hl_5 = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [5.252351]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.4988868]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [3.5443144]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 5.0, predicted Stars: [3.8369918]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 2.5, predicted Stars: [2.366735]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [4.0126057]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [3.7982235]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.000417]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 4.0, predicted Stars: [4.149415]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.5, predicted Stars: [5.051223]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_hl_4[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5959509611129761\n",
      "R2 score: 0.66\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_5l = np.sqrt(mean_squared_error(y_test_reg,pred_reg_hl_5))\n",
    "print(\"Final score (RMSE): {}\".format(score_5l))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_hl_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot to show the best optimizer\n",
    "\n",
    "score_list_reg_layers=[score_2l,score_3l, score_4l,score_5l]\n",
    "names =['2 Layers','3 Layers','4 Layers', '5 Layers']\n",
    "tick_marks = np.arange(len(names))\n",
    "plt.bar(range(len(score_list_reg_layers)), score_list_reg_layers)\n",
    "plt.xticks(tick_marks, names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training without early stopping and Model Checkpoint and Sigmoid **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow model for Regression with sigmoid\n",
    "model_reg_sig = Sequential()\n",
    "\n",
    "model_reg_sig.add(Dense(25, input_dim=x_train_reg.shape[1], activation='sigmoid'))  \n",
    "model_reg_sig.add(Dense(10, activation='sigmoid')) # Hidden 2\n",
    "model_reg_sig.add(Dense(1)) # Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 4.8183\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.2602\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.0508\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.0352\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1.0107\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.8989\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.6185\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.4155\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.3205\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.2761\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.2525\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.2386\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.2292\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.2220\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.2168\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.2119\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.2075\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.2031\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.1997\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.1963\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.1936\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.1913\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.1882\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.1856\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.1840\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.1818\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.1800\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.1784\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.1768\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.1756\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.1742\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.1730\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.1710\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.1702\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.1688\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.1677\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.1665\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.1652\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.1644\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.1629\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.1622\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.1611\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.1599\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.1595\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.1580\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.1575\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.1565\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.1555\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.1545\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.1536\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.1528\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.1522\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.1514\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.1505\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.1503\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.1490\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.1483\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.1479\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.1469\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.1464\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.1453\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.1446\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.1437\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.1435\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.1431\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.1420\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.1413\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.1408\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.1402\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.1397\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.1391\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.1381\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.1378\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.1375\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.1363\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.1367\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.1355\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.1350\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.1344\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.1339\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.1334\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.1328\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.1323\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.1319\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.1314\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.1307\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.1299\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.1295\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.1290\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.1285\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.1280\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.1271\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.1269\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.1264\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.1260\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.1252\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.1248\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.1238\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.1236\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.1230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15e3e5f2358>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training with sigmoid \n",
    "model_reg_sig.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_reg_sig.fit(x_train_reg,y_train_reg,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_sig_simple = model_reg_sig.predict(x_test_reg)\n",
    "print(\"Shape: {}\".format(pred_reg_sig_simple.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 4.0, predicted Stars: [3.5908337]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 2.5, predicted Stars: [2.1344585]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 2.5, predicted Stars: [1.700152]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 3.5, predicted Stars: [3.765379]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 3.0, predicted Stars: [2.5106606]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 2.5, predicted Stars: [2.2755718]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [2.3116946]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 3.0, predicted Stars: [3.4402456]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [4.262379]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 2.5, predicted Stars: [3.265274]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_sig_simple[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5019386410713196\n",
      "R2 score: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_reg_sig = np.sqrt(mean_squared_error(y_test_reg,pred_reg_sig_simple))\n",
    "print(\"Final score (RMSE): {}\".format(score_reg_sig))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_sig_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training with early stopping and Model Checkpoint and Sigmoid **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_sigmoid = ModelCheckpoint(filepath=\"./best_weights_sigmoid.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 2.3689 - val_loss: 1.1717\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.17171, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 2/100\n",
      " - 7s - loss: 1.0608 - val_loss: 1.0470\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.17171 to 1.04695, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 3/100\n",
      " - 7s - loss: 1.0416 - val_loss: 1.0422\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.04695 to 1.04219, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 4/100\n",
      " - 6s - loss: 1.0412 - val_loss: 1.0391\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.04219 to 1.03914, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 5/100\n",
      " - 7s - loss: 1.0413 - val_loss: 1.0421\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.03914\n",
      "Epoch 6/100\n",
      " - 7s - loss: 1.0411 - val_loss: 1.0428\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.03914\n",
      "Epoch 7/100\n",
      " - 6s - loss: 1.0406 - val_loss: 1.0366\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.03914 to 1.03656, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 8/100\n",
      " - 6s - loss: 1.0295 - val_loss: 0.9722\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.03656 to 0.97224, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.4510 - val_loss: 0.3334\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.97224 to 0.33345, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 10/100\n",
      " - 7s - loss: 0.2327 - val_loss: 0.2978\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.33345 to 0.29784, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 11/100\n",
      " - 6s - loss: 0.1816 - val_loss: 0.2909\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.29784 to 0.29091, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 12/100\n",
      " - 6s - loss: 0.1479 - val_loss: 0.3005\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.29091\n",
      "Epoch 13/100\n",
      " - 6s - loss: 0.1255 - val_loss: 0.2853\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.29091 to 0.28530, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 14/100\n",
      " - 7s - loss: 0.1105 - val_loss: 0.2887\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.28530\n",
      "Epoch 15/100\n",
      " - 6s - loss: 0.0975 - val_loss: 0.2968\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.28530\n",
      "Epoch 16/100\n",
      " - 7s - loss: 0.0893 - val_loss: 0.2976\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.28530\n",
      "Epoch 00016: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 5.5942 - val_loss: 2.9004\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28530\n",
      "Epoch 2/100\n",
      " - 7s - loss: 1.7884 - val_loss: 1.3422\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28530\n",
      "Epoch 3/100\n",
      " - 6s - loss: 1.1249 - val_loss: 1.0777\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28530\n",
      "Epoch 4/100\n",
      " - 6s - loss: 1.0462 - val_loss: 1.0446\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28530\n",
      "Epoch 5/100\n",
      " - 6s - loss: 1.0415 - val_loss: 1.0402\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28530\n",
      "Epoch 6/100\n",
      " - 7s - loss: 1.0413 - val_loss: 1.0430\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28530\n",
      "Epoch 7/100\n",
      " - 6s - loss: 1.0413 - val_loss: 1.0395\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28530\n",
      "Epoch 8/100\n",
      " - 6s - loss: 1.0415 - val_loss: 1.0406\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28530\n",
      "Epoch 00008: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 2.7218 - val_loss: 1.3717\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28530\n",
      "Epoch 2/100\n",
      " - 6s - loss: 1.1172 - val_loss: 1.0602\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28530\n",
      "Epoch 3/100\n",
      " - 7s - loss: 1.0429 - val_loss: 1.0408\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28530\n",
      "Epoch 4/100\n",
      " - 6s - loss: 1.0414 - val_loss: 1.0408\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28530\n",
      "Epoch 5/100\n",
      " - 7s - loss: 1.0414 - val_loss: 1.0391\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28530\n",
      "Epoch 6/100\n",
      " - 7s - loss: 1.0415 - val_loss: 1.0385\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28530\n",
      "Epoch 7/100\n",
      " - 6s - loss: 1.0415 - val_loss: 1.0388\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28530\n",
      "Epoch 8/100\n",
      " - 6s - loss: 1.0408 - val_loss: 1.0360\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28530\n",
      "Epoch 9/100\n",
      " - 7s - loss: 1.0411 - val_loss: 1.0382\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28530\n",
      "Epoch 10/100\n",
      " - 7s - loss: 1.0404 - val_loss: 1.0382\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28530\n",
      "Epoch 11/100\n",
      " - 6s - loss: 0.8621 - val_loss: 0.4509\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28530\n",
      "Epoch 12/100\n",
      " - 7s - loss: 0.2992 - val_loss: 0.3454\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.28530\n",
      "Epoch 13/100\n",
      " - 6s - loss: 0.2016 - val_loss: 0.2834\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.28530 to 0.28336, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 14/100\n",
      " - 6s - loss: 0.1580 - val_loss: 0.2849\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.28336\n",
      "Epoch 15/100\n",
      " - 6s - loss: 0.1304 - val_loss: 0.2986\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.28336\n",
      "Epoch 16/100\n",
      " - 7s - loss: 0.1118 - val_loss: 0.2841\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.28336\n",
      "Epoch 00016: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 3.0900 - val_loss: 1.4433\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28336\n",
      "Epoch 2/100\n",
      " - 9s - loss: 1.1389 - val_loss: 1.0698\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28336\n",
      "Epoch 3/100\n",
      " - 8s - loss: 1.0441 - val_loss: 1.0427\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28336\n",
      "Epoch 4/100\n",
      " - 7s - loss: 1.0416 - val_loss: 1.0410\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28336\n",
      "Epoch 5/100\n",
      " - 9s - loss: 1.0413 - val_loss: 1.0400\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28336\n",
      "Epoch 6/100\n",
      " - 8s - loss: 1.0413 - val_loss: 1.0425\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28336\n",
      "Epoch 7/100\n",
      " - 6s - loss: 1.0413 - val_loss: 1.0399\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28336\n",
      "Epoch 8/100\n",
      " - 6s - loss: 1.0414 - val_loss: 1.0429\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28336\n",
      "Epoch 00008: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 3.6383 - val_loss: 1.5523\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28336\n",
      "Epoch 2/100\n",
      " - 6s - loss: 1.1646 - val_loss: 1.0707\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28336\n",
      "Epoch 3/100\n",
      " - 6s - loss: 1.0443 - val_loss: 1.0432\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28336\n",
      "Epoch 4/100\n",
      " - 6s - loss: 1.0414 - val_loss: 1.0389\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28336\n",
      "Epoch 5/100\n",
      " - 6s - loss: 1.0415 - val_loss: 1.0413\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28336\n",
      "Epoch 6/100\n",
      " - 6s - loss: 1.0414 - val_loss: 1.0396\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28336\n",
      "Epoch 7/100\n",
      " - 6s - loss: 1.0415 - val_loss: 1.0412\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28336\n",
      "Epoch 00007: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 3.3359 - val_loss: 1.3620\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28336\n",
      "Epoch 2/100\n",
      " - 7s - loss: 1.1037 - val_loss: 1.0521\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28336\n",
      "Epoch 3/100\n",
      " - 6s - loss: 1.0413 - val_loss: 1.0384\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28336\n",
      "Epoch 4/100\n",
      " - 7s - loss: 1.0415 - val_loss: 1.0398\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28336\n",
      "Epoch 5/100\n",
      " - 6s - loss: 1.0413 - val_loss: 1.0426\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28336\n",
      "Epoch 6/100\n",
      " - 6s - loss: 1.0413 - val_loss: 1.0421\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28336\n",
      "Epoch 00006: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 4.4417 - val_loss: 1.9978\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28336\n",
      "Epoch 2/100\n",
      " - 6s - loss: 1.3280 - val_loss: 1.1231\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28336\n",
      "Epoch 3/100\n",
      " - 6s - loss: 1.0533 - val_loss: 1.0458\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28336\n",
      "Epoch 4/100\n",
      " - 6s - loss: 1.0415 - val_loss: 1.0424\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28336\n",
      "Epoch 5/100\n",
      " - 7s - loss: 1.0414 - val_loss: 1.0403\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28336\n",
      "Epoch 6/100\n",
      " - 6s - loss: 1.0414 - val_loss: 1.0395\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28336\n",
      "Epoch 7/100\n",
      " - 6s - loss: 1.0413 - val_loss: 1.0446\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28336\n",
      "Epoch 8/100\n",
      " - 6s - loss: 1.0414 - val_loss: 1.0383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28336\n",
      "Epoch 9/100\n",
      " - 7s - loss: 1.0407 - val_loss: 1.0498\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28336\n",
      "Epoch 10/100\n",
      " - 6s - loss: 1.0417 - val_loss: 1.0386\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28336\n",
      "Epoch 11/100\n",
      " - 7s - loss: 1.0411 - val_loss: 1.0480\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28336\n",
      "Epoch 00011: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 1.3308 - val_loss: 1.0326\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28336\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.9944 - val_loss: 0.8292\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28336\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.4161 - val_loss: 0.3283\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28336\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.2408 - val_loss: 0.2948\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28336\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.1948 - val_loss: 0.2896\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28336\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.1669 - val_loss: 0.2953\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28336\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.1455 - val_loss: 0.2934\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28336\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.1294 - val_loss: 0.2947\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28336\n",
      "Epoch 00008: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 9.1361 - val_loss: 5.7993\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28336\n",
      "Epoch 2/100\n",
      " - 7s - loss: 3.9598 - val_loss: 3.0148\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28336\n",
      "Epoch 3/100\n",
      " - 6s - loss: 2.1280 - val_loss: 1.7555\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28336\n",
      "Epoch 4/100\n",
      " - 6s - loss: 1.3750 - val_loss: 1.2633\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28336\n",
      "Epoch 5/100\n",
      " - 7s - loss: 1.1219 - val_loss: 1.1006\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28336\n",
      "Epoch 6/100\n",
      " - 6s - loss: 1.0560 - val_loss: 1.0569\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28336\n",
      "Epoch 7/100\n",
      " - 6s - loss: 1.0434 - val_loss: 1.0445\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28336\n",
      "Epoch 8/100\n",
      " - 6s - loss: 1.0415 - val_loss: 1.0424\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28336\n",
      "Epoch 9/100\n",
      " - 7s - loss: 1.0413 - val_loss: 1.0408\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28336\n",
      "Epoch 10/100\n",
      " - 7s - loss: 1.0412 - val_loss: 1.0396\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28336\n",
      "Epoch 11/100\n",
      " - 7s - loss: 1.0414 - val_loss: 1.0391\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.28336\n",
      "Epoch 12/100\n",
      " - 7s - loss: 1.0414 - val_loss: 1.0419\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.28336\n",
      "Epoch 13/100\n",
      " - 7s - loss: 1.0413 - val_loss: 1.0389\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.28336\n",
      "Epoch 00013: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 3.6141 - val_loss: 2.0690\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.28336\n",
      "Epoch 2/100\n",
      " - 7s - loss: 1.4251 - val_loss: 1.2020\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28336\n",
      "Epoch 3/100\n",
      " - 7s - loss: 1.0787 - val_loss: 1.0608\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28336\n",
      "Epoch 4/100\n",
      " - 7s - loss: 1.0435 - val_loss: 1.0428\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28336\n",
      "Epoch 5/100\n",
      " - 7s - loss: 1.0414 - val_loss: 1.0398\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28336\n",
      "Epoch 6/100\n",
      " - 7s - loss: 1.0414 - val_loss: 1.0403\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28336\n",
      "Epoch 7/100\n",
      " - 7s - loss: 1.0413 - val_loss: 1.0416\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28336\n",
      "Epoch 8/100\n",
      " - 7s - loss: 1.0415 - val_loss: 1.0400\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28336\n",
      "Epoch 00008: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_sig = Sequential()\n",
    "\n",
    "    model_reg_sig.add(Dense(120, input_dim=x_train_reg.shape[1], activation='sigmoid'))  \n",
    "    model_reg_sig.add(Dense(80, activation='sigmoid')) # Hidden 2\n",
    "    model_reg_sig.add(Dense(60, activation='sigmoid')) # Hidden 3\n",
    "    model_reg_sig.add(Dense(10, activation='sigmoid')) # Hidden 4\n",
    "    model_reg_sig.add(Dense(1)) # Output\n",
    "    model_reg_sig.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3, verbose=1, mode='auto')\n",
    "    model_reg_sig.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_sigmoid],verbose=2,epochs=100)\n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_sig.load_weights('./best_weights_sigmoid.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_sig_stopping = model_reg_sig.predict(x_test_reg)\n",
    "print(\"Shape: {}\".format(pred_reg_sig_stopping.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [4.678062]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.4644246]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [3.7925215]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 5.0, predicted Stars: [4.6447577]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 2.5, predicted Stars: [2.710929]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.2405157]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [3.7411523]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.4633565]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 4.0, predicted Stars: [3.851685]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.5, predicted Stars: [4.5967903]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_sig_stopping[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5323189496994019\n",
      "R2 score: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_reg_sig_stopping = np.sqrt(mean_squared_error(y_test_reg,pred_reg_sig_stopping))\n",
    "print(\"Final score (RMSE): {}\".format(score_reg_sig_stopping))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_sig_stopping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training without early stopping and Model Checkpoint and Tanh **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test data\n",
    "x_train_reg_tanh, x_test_reg_tanh, y_train_reg_tanh, y_test_reg_tanh = train_test_split(x_matrix_zscore, y_stars_regression , test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow model for Regression with tanh\n",
    "model_reg_tanh = Sequential()\n",
    "\n",
    "model_reg_tanh.add(Dense(25, input_dim=x_train_reg_tanh.shape[1], activation='tanh'))  \n",
    "model_reg_tanh.add(Dense(10, activation='tanh')) # Hidden 2\n",
    "model_reg_tanh.add(Dense(1)) # Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 10s - loss: 2.2030\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.5618\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2565\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.2242\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.2096\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.2014\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.1950\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.1904\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1848\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.1799\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.1755\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.1713\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.1677\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.1639\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.1597\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.1569\n",
      "Epoch 17/100\n",
      " - 3s - loss: 0.1545\n",
      "Epoch 18/100\n",
      " - 2s - loss: 0.1515\n",
      "Epoch 19/100\n",
      " - 2s - loss: 0.1490\n",
      "Epoch 20/100\n",
      " - 3s - loss: 0.1462\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.1446\n",
      "Epoch 22/100\n",
      " - 2s - loss: 0.1418\n",
      "Epoch 23/100\n",
      " - 3s - loss: 0.1403\n",
      "Epoch 24/100\n",
      " - 3s - loss: 0.1378\n",
      "Epoch 25/100\n",
      " - 3s - loss: 0.1352\n",
      "Epoch 26/100\n",
      " - 3s - loss: 0.1334\n",
      "Epoch 27/100\n",
      " - 2s - loss: 0.1308\n",
      "Epoch 28/100\n",
      " - 2s - loss: 0.1278\n",
      "Epoch 29/100\n",
      " - 2s - loss: 0.1256\n",
      "Epoch 30/100\n",
      " - 3s - loss: 0.1230\n",
      "Epoch 31/100\n",
      " - 4s - loss: 0.1199\n",
      "Epoch 32/100\n",
      " - 3s - loss: 0.1181\n",
      "Epoch 33/100\n",
      " - 3s - loss: 0.1153\n",
      "Epoch 34/100\n",
      " - 3s - loss: 0.1127\n",
      "Epoch 35/100\n",
      " - 3s - loss: 0.1102\n",
      "Epoch 36/100\n",
      " - 2s - loss: 0.1078\n",
      "Epoch 37/100\n",
      " - 3s - loss: 0.1062\n",
      "Epoch 38/100\n",
      " - 3s - loss: 0.1043\n",
      "Epoch 39/100\n",
      " - 3s - loss: 0.1018\n",
      "Epoch 40/100\n",
      " - 2s - loss: 0.0999\n",
      "Epoch 41/100\n",
      " - 3s - loss: 0.0976\n",
      "Epoch 42/100\n",
      " - 3s - loss: 0.0961\n",
      "Epoch 43/100\n",
      " - 3s - loss: 0.0935\n",
      "Epoch 44/100\n",
      " - 3s - loss: 0.0919\n",
      "Epoch 45/100\n",
      " - 3s - loss: 0.0904\n",
      "Epoch 46/100\n",
      " - 2s - loss: 0.0886\n",
      "Epoch 47/100\n",
      " - 3s - loss: 0.0868\n",
      "Epoch 48/100\n",
      " - 3s - loss: 0.0848\n",
      "Epoch 49/100\n",
      " - 3s - loss: 0.0835\n",
      "Epoch 50/100\n",
      " - 3s - loss: 0.0819\n",
      "Epoch 51/100\n",
      " - 3s - loss: 0.0802\n",
      "Epoch 52/100\n",
      " - 3s - loss: 0.0787\n",
      "Epoch 53/100\n",
      " - 3s - loss: 0.0766\n",
      "Epoch 54/100\n",
      " - 3s - loss: 0.0751\n",
      "Epoch 55/100\n",
      " - 2s - loss: 0.0744\n",
      "Epoch 56/100\n",
      " - 2s - loss: 0.0726\n",
      "Epoch 57/100\n",
      " - 2s - loss: 0.0714\n",
      "Epoch 58/100\n",
      " - 2s - loss: 0.0699\n",
      "Epoch 59/100\n",
      " - 2s - loss: 0.0685\n",
      "Epoch 60/100\n",
      " - 3s - loss: 0.0671\n",
      "Epoch 61/100\n",
      " - 3s - loss: 0.0658\n",
      "Epoch 62/100\n",
      " - 2s - loss: 0.0647\n",
      "Epoch 63/100\n",
      " - 3s - loss: 0.0632\n",
      "Epoch 64/100\n",
      " - 3s - loss: 0.0621\n",
      "Epoch 65/100\n",
      " - 4s - loss: 0.0611\n",
      "Epoch 66/100\n",
      " - 3s - loss: 0.0594\n",
      "Epoch 67/100\n",
      " - 4s - loss: 0.0585\n",
      "Epoch 68/100\n",
      " - 4s - loss: 0.0576\n",
      "Epoch 69/100\n",
      " - 4s - loss: 0.0563\n",
      "Epoch 70/100\n",
      " - 4s - loss: 0.0550\n",
      "Epoch 71/100\n",
      " - 4s - loss: 0.0541\n",
      "Epoch 72/100\n",
      " - 2s - loss: 0.0533\n",
      "Epoch 73/100\n",
      " - 2s - loss: 0.0517\n",
      "Epoch 74/100\n",
      " - 2s - loss: 0.0513\n",
      "Epoch 75/100\n",
      " - 3s - loss: 0.0504\n",
      "Epoch 76/100\n",
      " - 2s - loss: 0.0491\n",
      "Epoch 77/100\n",
      " - 2s - loss: 0.0483\n",
      "Epoch 78/100\n",
      " - 3s - loss: 0.0471\n",
      "Epoch 79/100\n",
      " - 3s - loss: 0.0457\n",
      "Epoch 80/100\n",
      " - 3s - loss: 0.0454\n",
      "Epoch 81/100\n",
      " - 3s - loss: 0.0448\n",
      "Epoch 82/100\n",
      " - 3s - loss: 0.0433\n",
      "Epoch 83/100\n",
      " - 3s - loss: 0.0427\n",
      "Epoch 84/100\n",
      " - 4s - loss: 0.0413\n",
      "Epoch 85/100\n",
      " - 4s - loss: 0.0407\n",
      "Epoch 86/100\n",
      " - 3s - loss: 0.0399\n",
      "Epoch 87/100\n",
      " - 3s - loss: 0.0394\n",
      "Epoch 88/100\n",
      " - 2s - loss: 0.0387\n",
      "Epoch 89/100\n",
      " - 3s - loss: 0.0378\n",
      "Epoch 90/100\n",
      " - 3s - loss: 0.0367\n",
      "Epoch 91/100\n",
      " - 3s - loss: 0.0363\n",
      "Epoch 92/100\n",
      " - 3s - loss: 0.0356\n",
      "Epoch 93/100\n",
      " - 3s - loss: 0.0348\n",
      "Epoch 94/100\n",
      " - 3s - loss: 0.0347\n",
      "Epoch 95/100\n",
      " - 2s - loss: 0.0339\n",
      "Epoch 96/100\n",
      " - 2s - loss: 0.0334\n",
      "Epoch 97/100\n",
      " - 2s - loss: 0.0326\n",
      "Epoch 98/100\n",
      " - 2s - loss: 0.0320\n",
      "Epoch 99/100\n",
      " - 3s - loss: 0.0317\n",
      "Epoch 100/100\n",
      " - 2s - loss: 0.0311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15fb8986390>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training with sigmoid \n",
    "model_reg_tanh.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_reg_tanh.fit(x_train_reg_tanh,y_train_reg_tanh,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_tanh_simple = model_reg_tanh.predict(x_test_reg_tanh)\n",
    "print(\"Shape: {}\".format(pred_reg_tanh_simple.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 1.0, predicted Stars: [-2.400431]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.5, predicted Stars: [3.9455674]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 4.0, predicted Stars: [4.473979]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.0, predicted Stars: [3.137375]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 4.0, predicted Stars: [3.995518]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 4.0, predicted Stars: [3.9258718]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 1.5, predicted Stars: [2.004966]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 5.0, predicted Stars: [4.9783335]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 3.5, predicted Stars: [2.1402419]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 3.0, predicted Stars: [2.7069018]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg_tanh[i],pred_reg_tanh_simple[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.7059175372123718\n",
      "R2 score: 0.53\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_reg_tanh = np.sqrt(mean_squared_error(y_test_reg_tanh,pred_reg_tanh_simple))\n",
    "print(\"Final score (RMSE): {}\".format(score_reg_tanh))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg_tanh, pred_reg_tanh_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training with early stopping and Model Checkpoint and Tanh **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_tanh = ModelCheckpoint(filepath=\"./best_weights_tanh.hdf5\", verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 0.7349 - val_loss: 0.2445\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24450, saving model to ./best_weights_tanh.hdf5\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.2329 - val_loss: 0.2387\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24450 to 0.23867, saving model to ./best_weights_tanh.hdf5\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.2105 - val_loss: 0.2417\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23867\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1946 - val_loss: 0.2413\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23867\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1818 - val_loss: 0.2399\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23867\n",
      "Epoch 00005: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.9725 - val_loss: 0.3077\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23867\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2352 - val_loss: 0.2378\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23867 to 0.23785, saving model to ./best_weights_tanh.hdf5\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2111 - val_loss: 0.2564\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23785\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1961 - val_loss: 0.2376\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23785 to 0.23755, saving model to ./best_weights_tanh.hdf5\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1810 - val_loss: 0.2375\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23755 to 0.23751, saving model to ./best_weights_tanh.hdf5\n",
      "Epoch 00005: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.0693 - val_loss: 0.2688\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23751\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2390 - val_loss: 0.2368\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23751 to 0.23684, saving model to ./best_weights_tanh.hdf5\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2105 - val_loss: 0.2411\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23684\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1973 - val_loss: 0.2384\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23684\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1842 - val_loss: 0.2507\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23684\n",
      "Epoch 00005: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 0.9261 - val_loss: 0.2547\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23684\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2313 - val_loss: 0.2450\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23684\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2096 - val_loss: 0.2374\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23684\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1923 - val_loss: 0.2380\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23684\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1832 - val_loss: 0.2395\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23684\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1733 - val_loss: 0.2500\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23684\n",
      "Epoch 00006: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.3054 - val_loss: 0.3359\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23684\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2606 - val_loss: 0.2545\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23684\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2107 - val_loss: 0.2445\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23684\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1930 - val_loss: 0.2431\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23684\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1798 - val_loss: 0.2432\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23684\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1708 - val_loss: 0.2409\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23684\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.1611 - val_loss: 0.2607\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.23684\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.1575 - val_loss: 0.2657\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.23684\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.1521 - val_loss: 0.2712\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.23684\n",
      "Epoch 00009: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 0.9216 - val_loss: 0.2501\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23684\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2344 - val_loss: 0.2526\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23684\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2098 - val_loss: 0.2464\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23684\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.1937 - val_loss: 0.2441\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23684\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1834 - val_loss: 0.2503\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23684\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1723 - val_loss: 0.2489\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23684\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.1649 - val_loss: 0.2445\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.23684\n",
      "Epoch 00007: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.0365 - val_loss: 0.2658\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23684\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2414 - val_loss: 0.2438\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23684\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2072 - val_loss: 0.2386\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23684\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1913 - val_loss: 0.2653\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23684\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1787 - val_loss: 0.2503\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23684\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1690 - val_loss: 0.2486\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23684\n",
      "Epoch 00006: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 1.0811 - val_loss: 0.2632\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23684\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2398 - val_loss: 0.2373\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23684\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2092 - val_loss: 0.2390\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23684\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1926 - val_loss: 0.2366\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23684 to 0.23662, saving model to ./best_weights_tanh.hdf5\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1837 - val_loss: 0.2580\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23662\n",
      "Epoch 00005: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.0727 - val_loss: 0.2793\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23662\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2398 - val_loss: 0.2449\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23662\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2086 - val_loss: 0.2432\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23662\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1936 - val_loss: 0.2448\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23662\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1829 - val_loss: 0.2427\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23662\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.1697 - val_loss: 0.2441\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23662\n",
      "Epoch 00006: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 0.8019 - val_loss: 0.2594\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.23662\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.2339 - val_loss: 0.2384\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.23662\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2082 - val_loss: 0.2501\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.23662\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.1928 - val_loss: 0.2476\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.23662\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.1809 - val_loss: 0.2476\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.23662\n",
      "Epoch 00005: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_reg_tanh = Sequential()\n",
    "\n",
    "    model_reg_tanh.add(Dense(120, input_dim=x_train_reg_tanh.shape[1], activation='tanh'))  \n",
    "    model_reg_tanh.add(Dense(80, activation='tanh')) # Hidden 2\n",
    "    model_reg_tanh.add(Dense(40, activation='tanh')) # Hidden 3\n",
    "    model_reg_tanh.add(Dense(20, activation='tanh')) # Hidden 3\n",
    "    model_reg_tanh.add(Dense(1)) # Output\n",
    "    model_reg_tanh.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3, verbose=1, mode='auto')\n",
    "    model_reg_tanh.fit(x_train_reg_tanh,y_train_reg_tanh,validation_data=(x_test_reg_tanh,y_test_reg_tanh),callbacks=[monitor,checkpointer_tanh],verbose=2,epochs=100) \n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_reg_tanh.load_weights('./best_weights_tanh.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_tanh_stopping = model_reg_tanh.predict(x_test_reg_tanh)\n",
    "print(\"Shape: {}\".format(pred_reg_tanh_stopping.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 1.0, predicted Stars: [0.8637372]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.5, predicted Stars: [4.230286]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 4.0, predicted Stars: [3.9415882]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.0, predicted Stars: [3.356799]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 4.0, predicted Stars: [3.9985633]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 4.0, predicted Stars: [3.7484093]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 1.5, predicted Stars: [1.5690304]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 5.0, predicted Stars: [4.9458656]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 3.5, predicted Stars: [3.3346255]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 3.0, predicted Stars: [2.941024]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg_tanh[i],pred_reg_tanh_stopping[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.4864327609539032\n",
      "R2 score: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_reg_tanh_stopping = np.sqrt(mean_squared_error(y_test_reg_tanh,pred_reg_tanh_stopping))\n",
    "print(\"Final score (RMSE): {}\".format(score_reg_tanh_stopping))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg_tanh, pred_reg_tanh_stopping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting RMSE score for all regression models\n",
    "\n",
    "score_list_reg=[score_lin_classic,score_log_classic,score_reg_relu,score_reg_relu_stopping,score_reg_sig,score_reg_sig_stopping,score_reg_tanh,score_reg_tanh_stopping]\n",
    "names =['Linear Regression','Logistic Regression','Relu','Relu Stopping','Sigmoid','Sigmoid Stopping','Tanh','Tanh Stopping']\n",
    "tick_marks = np.arange(len(names))\n",
    "plt.bar(range(len(score_list_reg)), score_list_reg)\n",
    "plt.xticks(tick_marks, names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting RMSE score for all regression models\n",
    "\n",
    "score_list_reg=[score_lin_classic,score_reg_sig,score_reg_sig_stopping]\n",
    "names =['Linear Regression','Sigmoid','Sigmoid Stopping']\n",
    "tick_marks = np.arange(len(names))\n",
    "plt.bar(range(len(score_list_reg)), score_list_reg)\n",
    "plt.xticks(tick_marks, names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Prediction for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train test data for linear regression\n",
    "\n",
    "x_train_lr, x_test_lr, y_train_lr, y_test_lr = train_test_split(x_matrix_minmax, merge_df['encoded_stars'] , test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** KNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implementing Nearest Neighbor\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(x_train_lr, y_train_lr) \n",
    "\n",
    "y_pred_knn = knn.predict(x_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business id - hTF1Qo6PRFnDgg1rh9a9BQ actual stars label - 6 predicted - 8\n",
      "business id - bAPjkuNJ67j2F4C5HQQHhQ actual stars label - 6 predicted - 4\n",
      "business id - dFcs3q8ynbFEaAnbyGSLjQ actual stars label - 6 predicted - 6\n",
      "business id - jrhc4s5XMR8S8kpGdU08og actual stars label - 7 predicted - 6\n",
      "business id - e7207sqC-pSn6GIf31ikhQ actual stars label - 6 predicted - 6\n",
      "business id - CF9TxeEdP5QxihYFAl4sUg actual stars label - 6 predicted - 6\n",
      "business id - zZPCAFK85NtitSNVP_wfYg actual stars label - 5 predicted - 7\n",
      "business id - 42U4Vlzr7nmQa1Bk8J4flw actual stars label - 8 predicted - 7\n",
      "business id - TTrYd662CZFRPaiwl-sUqA actual stars label - 2 predicted - 4\n",
      "business id - -lBIxCbHxuN3YO_sUkWeUQ actual stars label - 3 predicted - 6\n"
     ]
    }
   ],
   "source": [
    "# list  the business with the stars and prediction\n",
    "\n",
    "for i in range(0,10):\n",
    "    idx=y_test_lr.index[i]\n",
    "    print(\"business id - %s actual stars label - %d predicted - %d\" \n",
    "          %(merge_df['business_id'][idx], y_test_lr[idx], y_pred_knn[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.295\n",
      "Precision score: 0.2960480875614052\n",
      "Recall score: 0.295\n",
      "F1 score: 0.2918900582503685\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "score_knn_acc = metrics.accuracy_score(y_test_lr, y_pred_knn)\n",
    "print(\"Accuracy score: {}\".format(score_knn_acc))\n",
    "\n",
    "score_knn_precision = metrics.precision_score(y_test_lr, y_pred_knn, average= \"weighted\")\n",
    "print(\"Precision score: {}\".format(score_knn_precision))\n",
    "\n",
    "score_knn_recall = metrics.recall_score(y_test_lr, y_pred_knn, average= \"weighted\")\n",
    "print(\"Recall score: {}\".format(score_knn_recall))\n",
    "\n",
    "score_knn_f1 = metrics.f1_score(y_test_lr, y_pred_knn, average= \"weighted\")\n",
    "print(\"F1 score: {}\".format(score_knn_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** SVM **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "\n",
    "svm_model.fit(x_train_lr, y_train_lr)\n",
    "\n",
    "y_pred_svm = svm_model.predict(x_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business id - hTF1Qo6PRFnDgg1rh9a9BQ actual stars label - 6 predicted - 6\n",
      "business id - bAPjkuNJ67j2F4C5HQQHhQ actual stars label - 6 predicted - 6\n",
      "business id - dFcs3q8ynbFEaAnbyGSLjQ actual stars label - 6 predicted - 6\n",
      "business id - jrhc4s5XMR8S8kpGdU08og actual stars label - 7 predicted - 7\n",
      "business id - e7207sqC-pSn6GIf31ikhQ actual stars label - 6 predicted - 6\n",
      "business id - CF9TxeEdP5QxihYFAl4sUg actual stars label - 6 predicted - 6\n",
      "business id - zZPCAFK85NtitSNVP_wfYg actual stars label - 5 predicted - 5\n",
      "business id - 42U4Vlzr7nmQa1Bk8J4flw actual stars label - 8 predicted - 8\n",
      "business id - TTrYd662CZFRPaiwl-sUqA actual stars label - 2 predicted - 3\n",
      "business id - -lBIxCbHxuN3YO_sUkWeUQ actual stars label - 3 predicted - 3\n"
     ]
    }
   ],
   "source": [
    "# list  the business with the stars and prediction\n",
    "\n",
    "for i in range(0,10):\n",
    "    idx=y_test_lr.index[i]\n",
    "    print(\"business id - %s actual stars label - %d predicted - %d\" \n",
    "          %(merge_df['business_id'][idx], y_test_lr[idx], y_pred_svm[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.4365\n",
      "Precision score: 0.43072237226007926\n",
      "Recall score: 0.4365\n",
      "F1 score: 0.4278230138666609\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "\n",
    "score_svm_acc = metrics.accuracy_score(y_test_lr, y_pred_svm)\n",
    "print(\"Accuracy score: {}\".format(score_svm_acc))\n",
    "\n",
    "score_svm_precision = metrics.precision_score(y_test_lr, y_pred_svm, average= \"weighted\")\n",
    "print(\"Precision score: {}\".format(score_svm_precision))\n",
    "\n",
    "score_svm_recall = metrics.recall_score(y_test_lr, y_pred_svm, average= \"weighted\")\n",
    "print(\"Recall score: {}\".format(score_svm_recall))\n",
    "\n",
    "score_svm_f1 = metrics.f1_score(y_test_lr, y_pred_svm, average= \"weighted\")\n",
    "print(\"F1 score: {}\".format(score_svm_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** MNB **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb_model = MultinomialNB()\n",
    "\n",
    "mnb_model.fit(x_train_lr, y_train_lr)\n",
    "\n",
    "y_pred_mnb = mnb_model.predict(x_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business id - hTF1Qo6PRFnDgg1rh9a9BQ actual stars label - 6 predicted - 8\n",
      "business id - bAPjkuNJ67j2F4C5HQQHhQ actual stars label - 6 predicted - 6\n",
      "business id - dFcs3q8ynbFEaAnbyGSLjQ actual stars label - 6 predicted - 6\n",
      "business id - jrhc4s5XMR8S8kpGdU08og actual stars label - 7 predicted - 7\n",
      "business id - e7207sqC-pSn6GIf31ikhQ actual stars label - 6 predicted - 6\n",
      "business id - CF9TxeEdP5QxihYFAl4sUg actual stars label - 6 predicted - 8\n",
      "business id - zZPCAFK85NtitSNVP_wfYg actual stars label - 5 predicted - 8\n",
      "business id - 42U4Vlzr7nmQa1Bk8J4flw actual stars label - 8 predicted - 8\n",
      "business id - TTrYd662CZFRPaiwl-sUqA actual stars label - 2 predicted - 3\n",
      "business id - -lBIxCbHxuN3YO_sUkWeUQ actual stars label - 3 predicted - 0\n"
     ]
    }
   ],
   "source": [
    "# list  the business with the stars and prediction\n",
    "\n",
    "for i in range(0,10):\n",
    "    idx=y_test_lr.index[i]\n",
    "    print(\"business id - %s actual stars label - %d predicted - %d\" \n",
    "          %(merge_df['business_id'][idx], y_test_lr[idx], y_pred_mnb[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.3325\n",
      "Precision score: 0.29977451126707483\n",
      "Recall score: 0.3325\n",
      "F1 score: 0.2831433707336793\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "\n",
    "score_mnb_acc = metrics.accuracy_score(y_test_lr, y_pred_mnb)\n",
    "print(\"Accuracy score: {}\".format(score_mnb_acc))\n",
    "\n",
    "score_mnb_precision = metrics.precision_score(y_test_lr, y_pred_mnb, average= \"weighted\")\n",
    "print(\"Precision score: {}\".format(score_mnb_precision))\n",
    "\n",
    "score_mnb_recall = metrics.recall_score(y_test_lr, y_pred_mnb, average= \"weighted\")\n",
    "print(\"Recall score: {}\".format(score_mnb_recall))\n",
    "\n",
    "score_mnb_f1 = metrics.f1_score(y_test_lr, y_pred_mnb, average= \"weighted\")\n",
    "print(\"F1 score: {}\".format(score_mnb_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**  Activation ReLU, Optimizer adam with stopping and checkpoint **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding stars \n",
    "\n",
    "hotcoded_stars_df = pd.get_dummies(merge_df['encoded_stars'], sparse = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_stars_encoded = hotcoded_stars_df.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train test data for classification\n",
    "\n",
    "x_train_lr, x_test_lr, y_train_lr, y_test_lr = train_test_split(x_matrix_minmax, y_stars_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_classification = ModelCheckpoint(filepath=\"./best_weights_softmax.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 1.7818 - val_loss: 1.4341\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.43414, saving model to ./best_weights_softmax.hdf5\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.3224 - val_loss: 1.2933\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.43414 to 1.29335, saving model to ./best_weights_softmax.hdf5\n",
      "Epoch 3/100\n",
      " - 4s - loss: 1.1864 - val_loss: 1.2489\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.29335 to 1.24887, saving model to ./best_weights_softmax.hdf5\n",
      "Epoch 4/100\n",
      " - 4s - loss: 1.1173 - val_loss: 1.2429\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.24887 to 1.24291, saving model to ./best_weights_softmax.hdf5\n",
      "Epoch 5/100\n",
      " - 4s - loss: 1.0682 - val_loss: 1.2430\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24291\n",
      "Epoch 6/100\n",
      " - 4s - loss: 1.0262 - val_loss: 1.2564\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24291\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.9942 - val_loss: 1.2622\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24291\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.9593 - val_loss: 1.2874\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24291\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.9275 - val_loss: 1.2924\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.24291\n",
      "Epoch 00009: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.8437 - val_loss: 1.5121\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24291\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.3632 - val_loss: 1.3090\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24291\n",
      "Epoch 3/100\n",
      " - 4s - loss: 1.2048 - val_loss: 1.2614\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24291\n",
      "Epoch 4/100\n",
      " - 4s - loss: 1.1173 - val_loss: 1.2389\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.24291 to 1.23889, saving model to ./best_weights_softmax.hdf5\n",
      "Epoch 5/100\n",
      " - 4s - loss: 1.0575 - val_loss: 1.2605\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23889\n",
      "Epoch 6/100\n",
      " - 5s - loss: 1.0111 - val_loss: 1.2567\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23889\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.9693 - val_loss: 1.2751\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23889\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.9273 - val_loss: 1.2962\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23889\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.8896 - val_loss: 1.3092\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23889\n",
      "Epoch 00009: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 1.7912 - val_loss: 1.4991\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23889\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.3398 - val_loss: 1.2885\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23889\n",
      "Epoch 3/100\n",
      " - 4s - loss: 1.1854 - val_loss: 1.2459\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23889\n",
      "Epoch 4/100\n",
      " - 4s - loss: 1.1024 - val_loss: 1.2371\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.23889 to 1.23707, saving model to ./best_weights_softmax.hdf5\n",
      "Epoch 5/100\n",
      " - 4s - loss: 1.0425 - val_loss: 1.2405\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23707\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.9974 - val_loss: 1.2632\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23707\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.9507 - val_loss: 1.2755\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23707\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.9075 - val_loss: 1.3218\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23707\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.8710 - val_loss: 1.3427\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23707\n",
      "Epoch 00009: early stopping\n",
      "3\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 1.7766 - val_loss: 1.4641\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23707\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.3231 - val_loss: 1.2872\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23707\n",
      "Epoch 3/100\n",
      " - 4s - loss: 1.1755 - val_loss: 1.2437\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23707\n",
      "Epoch 4/100\n",
      " - 4s - loss: 1.0993 - val_loss: 1.2422\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23707\n",
      "Epoch 5/100\n",
      " - 4s - loss: 1.0460 - val_loss: 1.2451\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23707\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.9986 - val_loss: 1.2560\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23707\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.9539 - val_loss: 1.3054\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23707\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.9096 - val_loss: 1.3057\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23707\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.8733 - val_loss: 1.3348\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23707\n",
      "Epoch 00009: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.8203 - val_loss: 1.5124\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23707\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.3375 - val_loss: 1.2941\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23707\n",
      "Epoch 3/100\n",
      " - 4s - loss: 1.1739 - val_loss: 1.2334\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.23707 to 1.23340, saving model to ./best_weights_softmax.hdf5\n",
      "Epoch 4/100\n",
      " - 4s - loss: 1.1002 - val_loss: 1.2439\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23340\n",
      "Epoch 5/100\n",
      " - 4s - loss: 1.0480 - val_loss: 1.2353\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23340\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.9995 - val_loss: 1.2579\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23340\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.9631 - val_loss: 1.2729\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23340\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.9282 - val_loss: 1.3000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23340\n",
      "Epoch 00008: early stopping\n",
      "5\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 1.7622 - val_loss: 1.4374\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23340\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.3082 - val_loss: 1.2821\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23340\n",
      "Epoch 3/100\n",
      " - 4s - loss: 1.1808 - val_loss: 1.2491\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23340\n",
      "Epoch 4/100\n",
      " - 4s - loss: 1.1114 - val_loss: 1.2411\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23340\n",
      "Epoch 5/100\n",
      " - 4s - loss: 1.0611 - val_loss: 1.2532\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23340\n",
      "Epoch 6/100\n",
      " - 4s - loss: 1.0203 - val_loss: 1.2600\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23340\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.9829 - val_loss: 1.2813\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23340\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.9456 - val_loss: 1.3083\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23340\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.9135 - val_loss: 1.3173\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23340\n",
      "Epoch 00009: early stopping\n",
      "6\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 1.7686 - val_loss: 1.4302\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23340\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.3094 - val_loss: 1.2751\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23340\n",
      "Epoch 3/100\n",
      " - 4s - loss: 1.1829 - val_loss: 1.2518\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23340\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.1151 - val_loss: 1.2390\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23340\n",
      "Epoch 5/100\n",
      " - 4s - loss: 1.0600 - val_loss: 1.2458\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23340\n",
      "Epoch 6/100\n",
      " - 4s - loss: 1.0153 - val_loss: 1.2534\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23340\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.9703 - val_loss: 1.2678\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23340\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.9273 - val_loss: 1.2763\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23340\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.8889 - val_loss: 1.2999\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23340\n",
      "Epoch 00009: early stopping\n",
      "7\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 1.8451 - val_loss: 1.4658\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23340\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.3243 - val_loss: 1.2721\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23340\n",
      "Epoch 3/100\n",
      " - 4s - loss: 1.1831 - val_loss: 1.2395\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23340\n",
      "Epoch 4/100\n",
      " - 4s - loss: 1.1147 - val_loss: 1.2313\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.23340 to 1.23126, saving model to ./best_weights_softmax.hdf5\n",
      "Epoch 5/100\n",
      " - 4s - loss: 1.0633 - val_loss: 1.2394\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23126\n",
      "Epoch 6/100\n",
      " - 5s - loss: 1.0179 - val_loss: 1.2432\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23126\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.9778 - val_loss: 1.2723\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23126\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.9424 - val_loss: 1.2722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23126\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.9025 - val_loss: 1.2947\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23126\n",
      "Epoch 00009: early stopping\n",
      "8\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.8677 - val_loss: 1.5608\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23126\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.3696 - val_loss: 1.3012\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23126\n",
      "Epoch 3/100\n",
      " - 4s - loss: 1.1994 - val_loss: 1.2525\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23126\n",
      "Epoch 4/100\n",
      " - 4s - loss: 1.1165 - val_loss: 1.2331\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23126\n",
      "Epoch 5/100\n",
      " - 4s - loss: 1.0612 - val_loss: 1.2454\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23126\n",
      "Epoch 6/100\n",
      " - 4s - loss: 1.0135 - val_loss: 1.2575\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23126\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.9700 - val_loss: 1.2670\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23126\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.9350 - val_loss: 1.2957\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23126\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.8969 - val_loss: 1.3268\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23126\n",
      "Epoch 00009: early stopping\n",
      "9\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 1.8237 - val_loss: 1.4786\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.23126\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.3328 - val_loss: 1.2809\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.23126\n",
      "Epoch 3/100\n",
      " - 5s - loss: 1.1875 - val_loss: 1.2406\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.23126\n",
      "Epoch 4/100\n",
      " - 5s - loss: 1.1160 - val_loss: 1.2417\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23126\n",
      "Epoch 5/100\n",
      " - 4s - loss: 1.0682 - val_loss: 1.2434\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23126\n",
      "Epoch 6/100\n",
      " - 5s - loss: 1.0257 - val_loss: 1.2521\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.23126\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.9917 - val_loss: 1.2660\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.23126\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.9570 - val_loss: 1.2803\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.23126\n",
      "Epoch 00008: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow classification\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_classification = Sequential()\n",
    "    model_classification.add(Dense(50, input_dim=x_train_lr.shape[1], activation='relu')) # Hidden 1\n",
    "    model_classification.add(Dense(25, activation='relu')) # Hidden 2\n",
    "    model_classification.add(Dense(y_train_lr.shape[1], activation='softmax')) # Output\n",
    "    model_classification.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=2, mode='auto')\n",
    "    model_classification.fit(x_train_lr,y_train_lr,validation_data=(x_test_lr,y_test_lr),callbacks=[monitor,checkpointer_classification],verbose=2,epochs=100)\n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_classification.load_weights('./best_weights_softmax.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2000, 9)\n",
      "[[3.3878758e-05 9.1543414e-05 8.9627982e-04 ... 4.0991387e-01\n",
      "  4.8678383e-02 6.5963869e-03]\n",
      " [6.9252616e-07 8.9822033e-06 1.5236050e-04 ... 4.3009984e-01\n",
      "  5.8629435e-02 1.5350884e-03]\n",
      " [1.1523614e-06 2.7753495e-06 4.1048057e-05 ... 4.2310497e-01\n",
      "  3.4682915e-01 9.0379909e-02]\n",
      " ...\n",
      " [1.4983370e-02 1.4174576e-01 3.0316588e-01 ... 1.3866302e-03\n",
      "  8.1807193e-06 4.5280083e-07]\n",
      " [2.3610590e-02 3.7431344e-02 1.4308786e-01 ... 3.7967782e-02\n",
      "  5.4452880e-03 1.0299933e-03]\n",
      " [1.4992657e-06 1.7870778e-05 2.5218487e-04 ... 4.5084012e-01\n",
      "  4.1171301e-02 1.7219030e-03]]\n"
     ]
    }
   ],
   "source": [
    "pred_class = model_classification.predict(x_test_lr)\n",
    "print(\"Shape: {}\".format(pred_class.shape))\n",
    "print(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_stars = np.argmax(pred_class,axis=1)\n",
    "true_stars = np.argmax(y_test_lr,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 6, predicted Stars: 6\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 6, predicted Stars: 6\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 6, predicted Stars: 6\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 7, predicted Stars: 7\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 6, predicted Stars: 6\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 6, predicted Stars: 6\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 5, predicted Stars: 5\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 8, predicted Stars: 8\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 2, predicted Stars: 3\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 3, predicted Stars: 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],true_stars[i],predict_stars[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.495\n",
      "Precision score: 0.49186543188663984\n",
      "Recall score: 0.495\n",
      "F1 score: 0.48906518574106805\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "\n",
    "score_tf_acc_stopping = metrics.accuracy_score(true_stars, predict_stars)\n",
    "print(\"Accuracy score: {}\".format(score_tf_acc_stopping))\n",
    "\n",
    "score_tf_precision_stopping = metrics.precision_score(true_stars, predict_stars, average= \"weighted\")\n",
    "print(\"Precision score: {}\".format(score_tf_precision_stopping))\n",
    "\n",
    "score_tf_recall_stopping = metrics.recall_score(true_stars, predict_stars, average= \"weighted\")\n",
    "print(\"Recall score: {}\".format(score_tf_recall_stopping))\n",
    "\n",
    "score_tf_f1_stopping = metrics.f1_score(true_stars, predict_stars, average= \"weighted\")\n",
    "print(\"F1 score: {}\".format(score_tf_f1_stopping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Classification with Sigmoid **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train test data for classification\n",
    "\n",
    "x_train_lr, x_test_lr, y_train_lr, y_test_lr = train_test_split(x_matrix_minmax, y_stars_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_classification_sig = ModelCheckpoint(filepath=\"./best_weights_softmax_sig.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 2.0552 - val_loss: 1.9931\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.99312, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.9505 - val_loss: 1.8980\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.99312 to 1.89801, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 3/100\n",
      " - 5s - loss: 1.8194 - val_loss: 1.7438\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.89801 to 1.74384, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 1.6504 - val_loss: 1.5801\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.74384 to 1.58011, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 5/100\n",
      " - 5s - loss: 1.5100 - val_loss: 1.4736\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.58011 to 1.47360, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 6/100\n",
      " - 4s - loss: 1.4206 - val_loss: 1.4113\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.47360 to 1.41130, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 7/100\n",
      " - 4s - loss: 1.3583 - val_loss: 1.3669\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.41130 to 1.36688, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 8/100\n",
      " - 4s - loss: 1.3111 - val_loss: 1.3356\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.36688 to 1.33556, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 9/100\n",
      " - 4s - loss: 1.2724 - val_loss: 1.3130\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.33556 to 1.31298, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 10/100\n",
      " - 5s - loss: 1.2413 - val_loss: 1.2962\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.31298 to 1.29618, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 11/100\n",
      " - 4s - loss: 1.2132 - val_loss: 1.2892\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.29618 to 1.28923, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 12/100\n",
      " - 4s - loss: 1.1911 - val_loss: 1.2736\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.28923 to 1.27357, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 13/100\n",
      " - 4s - loss: 1.1706 - val_loss: 1.2662\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.27357 to 1.26621, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 14/100\n",
      " - 5s - loss: 1.1543 - val_loss: 1.2601\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.26621 to 1.26006, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 15/100\n",
      " - 4s - loss: 1.1370 - val_loss: 1.2589\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.26006 to 1.25887, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 16/100\n",
      " - 4s - loss: 1.1230 - val_loss: 1.2630\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.25887\n",
      "Epoch 17/100\n",
      " - 4s - loss: 1.1094 - val_loss: 1.2556\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.25887 to 1.25562, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 18/100\n",
      " - 5s - loss: 1.0991 - val_loss: 1.2578\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.25562\n",
      "Epoch 19/100\n",
      " - 4s - loss: 1.0857 - val_loss: 1.2582\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.25562\n",
      "Epoch 20/100\n",
      " - 4s - loss: 1.0752 - val_loss: 1.2608\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.25562\n",
      "Epoch 21/100\n",
      " - 4s - loss: 1.0662 - val_loss: 1.2589\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.25562\n",
      "Epoch 22/100\n",
      " - 4s - loss: 1.0555 - val_loss: 1.2593\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.25562\n",
      "Epoch 00022: early stopping\n",
      "1\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 2.0932 - val_loss: 2.0185\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.25562\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.9944 - val_loss: 1.9571\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.25562\n",
      "Epoch 3/100\n",
      " - 5s - loss: 1.8653 - val_loss: 1.7627\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.25562\n",
      "Epoch 4/100\n",
      " - 4s - loss: 1.6524 - val_loss: 1.5667\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.25562\n",
      "Epoch 5/100\n",
      " - 4s - loss: 1.4917 - val_loss: 1.4497\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.25562\n",
      "Epoch 6/100\n",
      " - 4s - loss: 1.4006 - val_loss: 1.3872\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.25562\n",
      "Epoch 7/100\n",
      " - 4s - loss: 1.3415 - val_loss: 1.3505\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.25562\n",
      "Epoch 8/100\n",
      " - 5s - loss: 1.2957 - val_loss: 1.3218\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.25562\n",
      "Epoch 9/100\n",
      " - 4s - loss: 1.2606 - val_loss: 1.2997\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.25562\n",
      "Epoch 10/100\n",
      " - 4s - loss: 1.2298 - val_loss: 1.2825\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.25562\n",
      "Epoch 11/100\n",
      " - 4s - loss: 1.2043 - val_loss: 1.2736\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.25562\n",
      "Epoch 12/100\n",
      " - 4s - loss: 1.1821 - val_loss: 1.2614\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.25562\n",
      "Epoch 13/100\n",
      " - 4s - loss: 1.1622 - val_loss: 1.2535\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.25562 to 1.25348, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 14/100\n",
      " - 4s - loss: 1.1443 - val_loss: 1.2516\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.25348 to 1.25160, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 15/100\n",
      " - 5s - loss: 1.1292 - val_loss: 1.2485\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.25160 to 1.24853, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 16/100\n",
      " - 4s - loss: 1.1146 - val_loss: 1.2516\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.24853\n",
      "Epoch 17/100\n",
      " - 5s - loss: 1.1010 - val_loss: 1.2438\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.24853 to 1.24380, saving model to ./best_weights_softmax_sig.hdf5\n",
      "Epoch 18/100\n",
      " - 4s - loss: 1.0890 - val_loss: 1.2448\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.24380\n",
      "Epoch 19/100\n",
      " - 5s - loss: 1.0774 - val_loss: 1.2461\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.24380\n",
      "Epoch 20/100\n",
      " - 5s - loss: 1.0669 - val_loss: 1.2501\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.24380\n",
      "Epoch 21/100\n",
      " - 4s - loss: 1.0556 - val_loss: 1.2506\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.24380\n",
      "Epoch 22/100\n",
      " - 5s - loss: 1.0463 - val_loss: 1.2507\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.24380\n",
      "Epoch 00022: early stopping\n",
      "2\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 2.0249 - val_loss: 1.9916\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24380\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.9391 - val_loss: 1.8833\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24380\n",
      "Epoch 3/100\n",
      " - 4s - loss: 1.7969 - val_loss: 1.7257\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24380\n",
      "Epoch 4/100\n",
      " - 4s - loss: 1.6343 - val_loss: 1.5830\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24380\n",
      "Epoch 5/100\n",
      " - 4s - loss: 1.5029 - val_loss: 1.4710\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24380\n",
      "Epoch 6/100\n",
      " - 4s - loss: 1.4150 - val_loss: 1.4040\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24380\n",
      "Epoch 7/100\n",
      " - 4s - loss: 1.3538 - val_loss: 1.3632\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24380\n",
      "Epoch 8/100\n",
      " - 4s - loss: 1.3053 - val_loss: 1.3301\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24380\n",
      "Epoch 9/100\n",
      " - 5s - loss: 1.2672 - val_loss: 1.3085\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.24380\n",
      "Epoch 10/100\n",
      " - 4s - loss: 1.2367 - val_loss: 1.2964\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.24380\n",
      "Epoch 11/100\n",
      " - 4s - loss: 1.2118 - val_loss: 1.2796\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.24380\n",
      "Epoch 12/100\n",
      " - 4s - loss: 1.1886 - val_loss: 1.2717\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.24380\n",
      "Epoch 13/100\n",
      " - 4s - loss: 1.1692 - val_loss: 1.2690\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.24380\n",
      "Epoch 14/100\n",
      " - 4s - loss: 1.1526 - val_loss: 1.2576\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.24380\n",
      "Epoch 15/100\n",
      " - 4s - loss: 1.1362 - val_loss: 1.2591\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.24380\n",
      "Epoch 16/100\n",
      " - 4s - loss: 1.1229 - val_loss: 1.2570\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.24380\n",
      "Epoch 17/100\n",
      " - 4s - loss: 1.1095 - val_loss: 1.2547\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.24380\n",
      "Epoch 18/100\n",
      " - 4s - loss: 1.0983 - val_loss: 1.2559\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.24380\n",
      "Epoch 19/100\n",
      " - 4s - loss: 1.0871 - val_loss: 1.2552\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.24380\n",
      "Epoch 20/100\n",
      " - 4s - loss: 1.0764 - val_loss: 1.2573\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.24380\n",
      "Epoch 21/100\n",
      " - 4s - loss: 1.0671 - val_loss: 1.2615\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.24380\n",
      "Epoch 22/100\n",
      " - 4s - loss: 1.0578 - val_loss: 1.2615\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.24380\n",
      "Epoch 00022: early stopping\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 2.0200 - val_loss: 1.9880\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24380\n",
      "Epoch 2/100\n",
      " - 4s - loss: 1.9327 - val_loss: 1.8668\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24380\n",
      "Epoch 3/100\n",
      " - 5s - loss: 1.7681 - val_loss: 1.6796\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24380\n",
      "Epoch 4/100\n",
      " - 4s - loss: 1.5873 - val_loss: 1.5286\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24380\n",
      "Epoch 5/100\n",
      " - 4s - loss: 1.4693 - val_loss: 1.4425\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24380\n",
      "Epoch 6/100\n",
      " - 4s - loss: 1.3932 - val_loss: 1.3908\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24380\n",
      "Epoch 7/100\n",
      " - 4s - loss: 1.3382 - val_loss: 1.3504\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24380\n",
      "Epoch 8/100\n",
      " - 4s - loss: 1.2952 - val_loss: 1.3241\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24380\n",
      "Epoch 9/100\n",
      " - 4s - loss: 1.2578 - val_loss: 1.3048\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.24380\n",
      "Epoch 10/100\n",
      " - 4s - loss: 1.2280 - val_loss: 1.2888\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.24380\n",
      "Epoch 11/100\n",
      " - 5s - loss: 1.2018 - val_loss: 1.2805\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.24380\n",
      "Epoch 12/100\n",
      " - 4s - loss: 1.1806 - val_loss: 1.2638\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.24380\n",
      "Epoch 13/100\n",
      " - 5s - loss: 1.1594 - val_loss: 1.2557\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.24380\n",
      "Epoch 14/100\n",
      " - 4s - loss: 1.1414 - val_loss: 1.2554\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.24380\n",
      "Epoch 15/100\n",
      " - 4s - loss: 1.1263 - val_loss: 1.2525\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.24380\n",
      "Epoch 16/100\n",
      " - 4s - loss: 1.1110 - val_loss: 1.2519\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.24380\n",
      "Epoch 17/100\n",
      " - 4s - loss: 1.0991 - val_loss: 1.2493\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.24380\n",
      "Epoch 18/100\n",
      " - 4s - loss: 1.0873 - val_loss: 1.2510\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.24380\n",
      "Epoch 19/100\n",
      " - 5s - loss: 1.0769 - val_loss: 1.2530\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.24380\n",
      "Epoch 20/100\n",
      " - 4s - loss: 1.0669 - val_loss: 1.2544\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.24380\n",
      "Epoch 21/100\n",
      " - 4s - loss: 1.0563 - val_loss: 1.2549\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.24380\n",
      "Epoch 22/100\n",
      " - 5s - loss: 1.0475 - val_loss: 1.2593\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.24380\n",
      "Epoch 00022: early stopping\n",
      "4\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 2.0191 - val_loss: 1.9768\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.24380\n",
      "Epoch 2/100\n",
      " - 5s - loss: 1.9067 - val_loss: 1.8157\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24380\n",
      "Epoch 3/100\n",
      " - 5s - loss: 1.7059 - val_loss: 1.6142\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24380\n",
      "Epoch 4/100\n",
      " - 5s - loss: 1.5487 - val_loss: 1.5049\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.24380\n",
      "Epoch 5/100\n",
      " - 5s - loss: 1.4555 - val_loss: 1.4340\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.24380\n",
      "Epoch 6/100\n",
      " - 5s - loss: 1.3905 - val_loss: 1.3893\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.24380\n",
      "Epoch 7/100\n",
      " - 5s - loss: 1.3402 - val_loss: 1.3517\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.24380\n",
      "Epoch 8/100\n",
      " - 5s - loss: 1.2985 - val_loss: 1.3254\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.24380\n",
      "Epoch 9/100\n"
     ]
    }
   ],
   "source": [
    "#Tensorflow classification\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_classification = Sequential()\n",
    "    model_classification.add(Dense(50, input_dim=x_train_lr.shape[1], activation='sigmoid')) # Hidden 1\n",
    "    model_classification.add(Dense(25, activation='sigmoid')) # Hidden 2\n",
    "    model_classification.add(Dense(y_train_lr.shape[1], activation='softmax')) # Output\n",
    "    model_classification.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=2, mode='auto')\n",
    "    model_classification.fit(x_train_lr,y_train_lr,validation_data=(x_test_lr,y_test_lr),callbacks=[monitor,checkpointer_classification_sig],verbose=2,epochs=100)\n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_classification.load_weights('./best_weights_softmax_sig.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_softmax_sig = model_class.predict(x_test_lr)\n",
    "print(\"Shape: {}\".format(pred_softmax_sig.shape))\n",
    "print(pred_softmax_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_stars = np.argmax(pred_softmax_sig,axis=1)\n",
    "true_stars = np.argmax(y_test_lr,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],true_stars[i],predict_stars[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Metrics\n",
    "\n",
    "score_acc_softmax_sig = metrics.accuracy_score(true_stars, predict_stars)\n",
    "print(\"Accuracy score: {}\".format(score_acc_softmax_sig))\n",
    "\n",
    "score_precision_softmax_sig = metrics.precision_score(true_stars, predict_stars, average= \"weighted\")\n",
    "print(\"Precision score: {}\".format(score_precision_softmax_sig))\n",
    "\n",
    "score_recall_softmax_sig = metrics.recall_score(true_stars, predict_stars, average= \"weighted\")\n",
    "print(\"Recall score: {}\".format(score_recall_softmax_sig))\n",
    "\n",
    "score_f1_softmax_sig = metrics.f1_score(true_stars, predict_stars, average= \"weighted\")\n",
    "print(\"F1 score: {}\".format(score_f1_softmax_sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Classification with Tanh **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_classification_tanh = ModelCheckpoint(filepath=\"./best_weights_softmax_tanh.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tensorflow classification\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    \n",
    "    # Build network\n",
    "    model_classification = Sequential()\n",
    "    model_classification.add(Dense(50, input_dim=x_train_lr.shape[1], activation='tanh')) # Hidden 1\n",
    "    model_classification.add(Dense(25, activation='tanh')) # Hidden 2\n",
    "    model_classification.add(Dense(y_train_lr.shape[1], activation='softmax')) # Output\n",
    "    model_classification.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=2, mode='auto')\n",
    "    model_classification.fit(x_train_lr,y_train_lr,validation_data=(x_test_lr,y_test_lr),callbacks=[monitor,checkpointer_classification_tanh],verbose=2,epochs=100)\n",
    "    \n",
    "print('Training finished...Loading the best model') \n",
    "print()\n",
    "model_classification.load_weights('./best_weights_softmax_tanh.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_class_tanh = model_classification.predict(x_test_lr)\n",
    "print(\"Shape: {}\".format(pred_class_tanh.shape))\n",
    "print(pred_class_tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_stars_tanh = np.argmax(pred_class_tanh,axis=1)\n",
    "true_stars = np.argmax(y_test_lr,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],true_stars[i],predict_stars_tanh[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Metrics\n",
    "\n",
    "score_tf_acc_tanh = metrics.accuracy_score(true_stars, predict_stars_tanh)\n",
    "print(\"Accuracy score: {}\".format(score_tf_acc_tanh))\n",
    "\n",
    "score_tf_precision_tanh = metrics.precision_score(true_stars, predict_stars_tanh, average= \"weighted\")\n",
    "print(\"Precision score: {}\".format(score_tf_precision_tanh))\n",
    "\n",
    "score_tf_recall_tanh = metrics.recall_score(true_stars, predict_stars_tanh, average= \"weighted\")\n",
    "print(\"Recall score: {}\".format(score_tf_recall_tanh))\n",
    "\n",
    "score_tf_f1_tanh = metrics.f1_score(true_stars, predict_stars_tanh, average= \"weighted\")\n",
    "print(\"F1 score: {}\".format(score_tf_f1_tanh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "from sklearn import metrics\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train test data\n",
    "x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x_matrix_minmax, y_stars_regression , test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#USe linear regression for regularization\n",
    "model_regularization = Sequential()\n",
    "model_regularization.add(Dense(50, input_dim=x_train_reg.shape[1], activation='relu'))\n",
    "model_regularization.add(Dense(25, activation='relu'))\n",
    "model_regularization.add(Dense(10, \n",
    "                kernel_regularizer=regularizers.l1(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "model_regularization.add(Dense(1)) \n",
    "model_regularization.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 20s - loss: 4.3367 - val_loss: 2.2657\n",
      "Epoch 2/100\n",
      " - 6s - loss: 1.7097 - val_loss: 1.3561\n",
      "Epoch 3/100\n",
      " - 6s - loss: 1.1760 - val_loss: 1.0891\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.9575 - val_loss: 0.9274\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.8107 - val_loss: 0.8123\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.6907 - val_loss: 0.7237\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.5859 - val_loss: 0.6551\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.4999 - val_loss: 0.6038\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.4322 - val_loss: 0.5663\n",
      "Epoch 10/100\n",
      " - 6s - loss: 0.3755 - val_loss: 0.5377\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.3289 - val_loss: 0.5132\n",
      "Epoch 12/100\n",
      " - 6s - loss: 0.2891 - val_loss: 0.4969\n",
      "Epoch 13/100\n",
      " - 5s - loss: 0.2566 - val_loss: 0.4748\n",
      "Epoch 14/100\n",
      " - 6s - loss: 0.2272 - val_loss: 0.4554\n",
      "Epoch 15/100\n",
      " - 6s - loss: 0.2044 - val_loss: 0.4384\n",
      "Epoch 16/100\n",
      " - 6s - loss: 0.1839 - val_loss: 0.4344\n",
      "Epoch 17/100\n",
      " - 6s - loss: 0.1670 - val_loss: 0.4177\n",
      "Epoch 18/100\n",
      " - 6s - loss: 0.1513 - val_loss: 0.4044\n",
      "Epoch 19/100\n",
      " - 6s - loss: 0.1391 - val_loss: 0.4012\n",
      "Epoch 20/100\n",
      " - 6s - loss: 0.1278 - val_loss: 0.3891\n",
      "Epoch 21/100\n",
      " - 5s - loss: 0.1187 - val_loss: 0.3819\n",
      "Epoch 22/100\n",
      " - 7s - loss: 0.1111 - val_loss: 0.3811\n",
      "Epoch 23/100\n",
      " - 7s - loss: 0.1049 - val_loss: 0.3745\n",
      "Epoch 24/100\n",
      " - 6s - loss: 0.0998 - val_loss: 0.3664\n",
      "Epoch 25/100\n",
      " - 6s - loss: 0.0941 - val_loss: 0.3629\n",
      "Epoch 26/100\n",
      " - 6s - loss: 0.0909 - val_loss: 0.3652\n",
      "Epoch 27/100\n",
      " - 5s - loss: 0.0869 - val_loss: 0.3592\n",
      "Epoch 28/100\n",
      " - 6s - loss: 0.0827 - val_loss: 0.3576\n",
      "Epoch 29/100\n",
      " - 5s - loss: 0.0794 - val_loss: 0.3543\n",
      "Epoch 30/100\n",
      " - 5s - loss: 0.0766 - val_loss: 0.3507\n",
      "Epoch 31/100\n",
      " - 5s - loss: 0.0739 - val_loss: 0.3522\n",
      "Epoch 32/100\n",
      " - 5s - loss: 0.0706 - val_loss: 0.3441\n",
      "Epoch 33/100\n",
      " - 5s - loss: 0.0674 - val_loss: 0.3499\n",
      "Epoch 34/100\n",
      " - 5s - loss: 0.0655 - val_loss: 0.3490\n",
      "Epoch 35/100\n",
      " - 5s - loss: 0.0626 - val_loss: 0.3414\n",
      "Epoch 36/100\n",
      " - 5s - loss: 0.0610 - val_loss: 0.3454\n",
      "Epoch 37/100\n",
      " - 5s - loss: 0.0590 - val_loss: 0.3452\n",
      "Epoch 38/100\n",
      " - 5s - loss: 0.0571 - val_loss: 0.3435\n",
      "Epoch 39/100\n",
      " - 5s - loss: 0.0548 - val_loss: 0.3438\n",
      "Epoch 40/100\n",
      " - 5s - loss: 0.0526 - val_loss: 0.3400\n",
      "Epoch 41/100\n",
      " - 5s - loss: 0.0514 - val_loss: 0.3366\n",
      "Epoch 42/100\n",
      " - 5s - loss: 0.0495 - val_loss: 0.3400\n",
      "Epoch 43/100\n",
      " - 5s - loss: 0.0476 - val_loss: 0.3320\n",
      "Epoch 44/100\n",
      " - 5s - loss: 0.0465 - val_loss: 0.3368\n",
      "Epoch 45/100\n",
      " - 5s - loss: 0.0451 - val_loss: 0.3383\n",
      "Epoch 46/100\n",
      " - 5s - loss: 0.0438 - val_loss: 0.3368\n",
      "Epoch 47/100\n",
      " - 5s - loss: 0.0420 - val_loss: 0.3298\n",
      "Epoch 48/100\n",
      " - 5s - loss: 0.0407 - val_loss: 0.3328\n",
      "Epoch 49/100\n",
      " - 5s - loss: 0.0395 - val_loss: 0.3329\n",
      "Epoch 50/100\n",
      " - 5s - loss: 0.0390 - val_loss: 0.3362\n",
      "Epoch 51/100\n",
      " - 5s - loss: 0.0383 - val_loss: 0.3295\n",
      "Epoch 52/100\n",
      " - 5s - loss: 0.0378 - val_loss: 0.3322\n",
      "Epoch 00052: early stopping\n"
     ]
    }
   ],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "model_regularization.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor],verbose=2,epochs=100)\n",
    "\n",
    "pred_regularization = model_regularization.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5542775392532349\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_regularization = np.sqrt(metrics.mean_squared_error(pred_regularization,y_test_reg))\n",
    "print(\"Final score (RMSE): {}\".format(score_regularization))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: early stopping\n",
      "Final score (RMSE): 0.49788129329681396\n"
     ]
    }
   ],
   "source": [
    "# Dropout\n",
    "\n",
    "model_dropout = Sequential()\n",
    "model_dropout.add(Dense(50, input_dim=x_train_reg.shape[1]))\n",
    "model_dropout.add(Dropout(0.1))\n",
    "\n",
    "model_dropout.add(Dense(25, activation='relu'))\n",
    "model_dropout.add(Dense(10, activation='relu'))\n",
    "model_dropout.add(Dense(1))\n",
    "\n",
    "model_dropout.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "model_dropout.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "\n",
    "pred_dropout = model_dropout.predict(x_test_reg)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_dropout = np.sqrt(metrics.mean_squared_error(pred_dropout,y_test_reg))\n",
    "print(\"Final score (RMSE): {}\".format(score_dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 50)                50100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 51,646\n",
      "Trainable params: 51,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Checking to see if regularization helps with over fitting when using postal code and categories and one hot coded values\n",
    "#train test data\n",
    "x_train_reg_ad, x_test_reg_ad, y_train_reg_ad, y_test_reg_ad = train_test_split(x_matrix_final, y_stars_regression , test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#USe linear regression for regularization\n",
    "model_regularization_ad = Sequential()\n",
    "model_regularization_ad.add(Dense(50, input_dim=x_train_reg_ad.shape[1], activation='relu'))\n",
    "model_regularization_ad.add(Dense(25, activation='relu'))\n",
    "model_regularization_ad.add(Dense(10, \n",
    "                kernel_regularizer=regularizers.l1(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "model_regularization_ad.add(Dense(1)) \n",
    "model_regularization_ad.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 18s - loss: 4.4570 - val_loss: 2.4116\n",
      "Epoch 2/100\n",
      " - 6s - loss: 1.8795 - val_loss: 1.6409\n",
      "Epoch 3/100\n",
      " - 5s - loss: 1.3024 - val_loss: 1.3105\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.9978 - val_loss: 1.0954\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.7967 - val_loss: 0.9675\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.6554 - val_loss: 0.8644\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.5439 - val_loss: 0.7992\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.4576 - val_loss: 0.7301\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.3906 - val_loss: 0.6778\n",
      "Epoch 10/100\n",
      " - 6s - loss: 0.3365 - val_loss: 0.6339\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.2923 - val_loss: 0.6078\n",
      "Epoch 12/100\n",
      " - 6s - loss: 0.2562 - val_loss: 0.5776\n",
      "Epoch 13/100\n",
      " - 6s - loss: 0.2272 - val_loss: 0.5579\n",
      "Epoch 14/100\n",
      " - 6s - loss: 0.2018 - val_loss: 0.5334\n",
      "Epoch 15/100\n",
      " - 5s - loss: 0.1801 - val_loss: 0.5166\n",
      "Epoch 16/100\n",
      " - 6s - loss: 0.1625 - val_loss: 0.5018\n",
      "Epoch 17/100\n",
      " - 5s - loss: 0.1473 - val_loss: 0.4803\n",
      "Epoch 18/100\n",
      " - 6s - loss: 0.1350 - val_loss: 0.4686\n",
      "Epoch 19/100\n",
      " - 5s - loss: 0.1238 - val_loss: 0.4651\n",
      "Epoch 20/100\n",
      " - 6s - loss: 0.1150 - val_loss: 0.4515\n",
      "Epoch 21/100\n",
      " - 5s - loss: 0.1084 - val_loss: 0.4386\n",
      "Epoch 22/100\n",
      " - 6s - loss: 0.1023 - val_loss: 0.4339\n",
      "Epoch 23/100\n",
      " - 5s - loss: 0.0972 - val_loss: 0.4268\n",
      "Epoch 24/100\n",
      " - 6s - loss: 0.0928 - val_loss: 0.4339\n",
      "Epoch 25/100\n",
      " - 5s - loss: 0.0893 - val_loss: 0.4216\n",
      "Epoch 26/100\n",
      " - 6s - loss: 0.0852 - val_loss: 0.4152\n",
      "Epoch 27/100\n",
      " - 7s - loss: 0.0809 - val_loss: 0.4106\n",
      "Epoch 28/100\n",
      " - 6s - loss: 0.0782 - val_loss: 0.4088\n",
      "Epoch 29/100\n",
      " - 8s - loss: 0.0757 - val_loss: 0.4043\n",
      "Epoch 30/100\n",
      " - 5s - loss: 0.0725 - val_loss: 0.4071\n",
      "Epoch 31/100\n",
      " - 5s - loss: 0.0707 - val_loss: 0.4172\n",
      "Epoch 32/100\n",
      " - 6s - loss: 0.0681 - val_loss: 0.3952\n",
      "Epoch 33/100\n",
      " - 5s - loss: 0.0652 - val_loss: 0.4010\n",
      "Epoch 34/100\n",
      " - 5s - loss: 0.0633 - val_loss: 0.3929\n",
      "Epoch 35/100\n",
      " - 6s - loss: 0.0613 - val_loss: 0.3983\n",
      "Epoch 36/100\n",
      " - 5s - loss: 0.0590 - val_loss: 0.3869\n",
      "Epoch 37/100\n",
      " - 5s - loss: 0.0553 - val_loss: 0.3927\n",
      "Epoch 38/100\n",
      " - 5s - loss: 0.0530 - val_loss: 0.3869\n",
      "Epoch 39/100\n",
      " - 7s - loss: 0.0513 - val_loss: 0.3883\n",
      "Epoch 40/100\n",
      " - 9s - loss: 0.0501 - val_loss: 0.3859\n",
      "Epoch 41/100\n",
      " - 6s - loss: 0.0498 - val_loss: 0.3799\n",
      "Epoch 42/100\n",
      " - 6s - loss: 0.0486 - val_loss: 0.3832\n",
      "Epoch 43/100\n",
      " - 7s - loss: 0.0458 - val_loss: 0.3872\n",
      "Epoch 44/100\n",
      " - 7s - loss: 0.0437 - val_loss: 0.3785\n",
      "Epoch 45/100\n",
      " - 6s - loss: 0.0421 - val_loss: 0.3788\n",
      "Epoch 46/100\n",
      " - 5s - loss: 0.0411 - val_loss: 0.3802\n",
      "Epoch 47/100\n",
      " - 5s - loss: 0.0408 - val_loss: 0.3790\n",
      "Epoch 48/100\n",
      " - 5s - loss: 0.0392 - val_loss: 0.3803\n",
      "Epoch 49/100\n",
      " - 5s - loss: 0.0377 - val_loss: 0.3752\n",
      "Epoch 50/100\n",
      " - 5s - loss: 0.0375 - val_loss: 0.3755\n",
      "Epoch 51/100\n",
      " - 5s - loss: 0.0369 - val_loss: 0.3821\n",
      "Epoch 52/100\n",
      " - 6s - loss: 0.0355 - val_loss: 0.3739\n",
      "Epoch 53/100\n",
      " - 5s - loss: 0.0341 - val_loss: 0.3712\n",
      "Epoch 54/100\n",
      " - 5s - loss: 0.0337 - val_loss: 0.3764\n",
      "Epoch 55/100\n",
      " - 6s - loss: 0.0332 - val_loss: 0.3707\n",
      "Epoch 56/100\n",
      " - 5s - loss: 0.0318 - val_loss: 0.3743\n",
      "Epoch 57/100\n",
      " - 5s - loss: 0.0305 - val_loss: 0.3709\n",
      "Epoch 58/100\n",
      " - 5s - loss: 0.0297 - val_loss: 0.3750\n",
      "Epoch 00058: early stopping\n"
     ]
    }
   ],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "model_regularization_ad.fit(x_train_reg_ad,y_train_reg_ad,validation_data=(x_test_reg_ad,y_test_reg_ad),callbacks=[monitor],verbose=2,epochs=100)\n",
    "\n",
    "pred_regularization_ad = model_regularization_ad.predict(x_test_reg_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5967134833335876\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_regularization_ad = np.sqrt(metrics.mean_squared_error(pred_regularization_ad,y_test_reg_ad))\n",
    "print(\"Final score (RMSE): {}\".format(score_regularization_ad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009: early stopping\n",
      "Final score (RMSE): 0.6171209812164307\n"
     ]
    }
   ],
   "source": [
    "# Dropout\n",
    "\n",
    "model_dropout_ad = Sequential()\n",
    "model_dropout_ad.add(Dense(50, input_dim=x_train_reg_ad.shape[1]))\n",
    "model_dropout_ad.add(Dropout(0.1))\n",
    "\n",
    "model_dropout_ad.add(Dense(25, activation='relu'))\n",
    "model_dropout_ad.add(Dense(10, activation='relu'))\n",
    "model_dropout_ad.add(Dense(1))\n",
    "\n",
    "model_dropout_ad.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "model_dropout_ad.fit(x_train_reg_ad,y_train_reg_ad,validation_data=(x_test_reg_ad,y_test_reg_ad),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "\n",
    "pred_dropout_ad = model_dropout_ad.predict(x_test_reg_ad)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_dropout_ad = np.sqrt(metrics.mean_squared_error(pred_dropout_ad,y_test_reg_ad))\n",
    "print(\"Final score (RMSE): {}\".format(score_dropout_ad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_85 (Dense)             (None, 50)                275400    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 276,946\n",
      "Trainable params: 276,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dropout_ad.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
