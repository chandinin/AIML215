{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChandiniNagendra\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import io\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "import collections\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Open business.json file, create tsv file with business_id, business name, categories, and review count to be used as features \n",
    "#and stars as label\n",
    "\n",
    "outfile = open(\"business.tsv\", 'w')\n",
    "sfile = csv.writer(outfile, delimiter =\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "sfile.writerow(['business_id','categories', 'stars', 'review_count', 'postal code'])\n",
    "with open('yelp_academic_dataset_business.json', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        sfile.writerow([row['business_id'], row['categories'], row['stars'], row['review_count'], row['postal_code']])\n",
    "\n",
    "outfile.close()\n",
    "\n",
    "business_df= pd.read_csv('business.tsv', delimiter =\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Open review.json file, create tsv file with business_id,text to be used as features \n",
    "#and stars as label\n",
    "\n",
    "outfile = open(\"review_stars.tsv\", 'w')\n",
    "sfile = csv.writer(outfile, delimiter =\"\\t\", quoting=csv.QUOTE_MINIMAL)\n",
    "sfile.writerow(['business_id','stars', 'text'])\n",
    "with open('yelp_academic_dataset_review.json', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        row = json.loads(line)\n",
    "        # some special char must be encoded in 'utf-8'\n",
    "        sfile.writerow([row['business_id'], row['stars'], (row['text']).encode('utf-8')])\n",
    "\n",
    "outfile.close()\n",
    "\n",
    "review_df= pd.read_csv('review_stars.tsv', delimiter =\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group all reviews by business_id\n",
    "review_agg_df = review_df.groupby('business_id')['text'].sum()\n",
    "review_df_ready_for_sklearn = pd.DataFrame({'business_id': review_agg_df.index, 'all_reviews': review_agg_df.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merge the resulting review aggregate dataframe with business dataframe\n",
    "merge_df = pd.merge(business_df, review_df_ready_for_sklearn, on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalization of review count field so it becomes comparable and remove bias\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "merge_df.insert(3,'normalized_count',((merge_df['review_count'] - merge_df['review_count'].min()) / (merge_df['review_count'].max() - merge_df['review_count'].min())).astype(float))\n",
    "merge_df['review_count'] = zscore(merge_df['review_count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removing NaN categories\n",
    "\n",
    "merge_df = merge_df[merge_df['categories'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting categories\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "encoded_categories = MultiLabelBinarizer()\n",
    "category_matrix = encoded_categories.fit_transform(merge_df['categories'].str.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TF-IDF calculation\n",
    "\n",
    "tfidf = sk_text.TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    " stop_words= 'english',ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the reviews column with TFIDFvectorizer\n",
    "matrix = tfidf.fit_transform(merge_df['all_reviews'])\n",
    "matrix = matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are adding the normalized count to the original matrix with TFIDFvectorizer\n",
    "x_matrix_minmax = np.column_stack((matrix, merge_df['normalized_count']))\n",
    "\n",
    "# Zscore\n",
    "x_matrix_zscore = np.column_stack((matrix, merge_df['review_count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train test data for linear regression\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_matrix_minmax, merge_df['stars'] , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# linear regression\n",
    "\n",
    "lin_reg_model = LinearRegression()\n",
    "\n",
    "lin_reg_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred_linear = lin_reg_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business id - EmezZdxbvjydG5FkN6Mecw actual stars  - 2.000000 predicted - 2.663625\n",
      "business id - cmaPrML-0zCJOs8_1VYmaw actual stars  - 4.500000 predicted - 4.174117\n",
      "business id - E6U8zl527AsspbTf5nZCdw actual stars  - 3.000000 predicted - 3.135507\n",
      "business id - zXRf_6Bs1yX9an_QKpzbHQ actual stars  - 2.000000 predicted - 2.148644\n",
      "business id - vllzSssD2HXGlzGUcITxhw actual stars  - 4.000000 predicted - 3.575649\n",
      "business id - AcGRSWCpb7YB95MTsHlGEw actual stars  - 2.000000 predicted - 2.569646\n",
      "business id - zfEcOCrgUKe8xYOdqNVmmA actual stars  - 3.500000 predicted - 3.318817\n",
      "business id - z-q6Wu-L-iDCftYVfoElPw actual stars  - 5.000000 predicted - 5.078186\n",
      "business id - K7c5wAhxd6CqtmBmY47c7g actual stars  - 3.500000 predicted - 2.295289\n",
      "business id - b30HREePgMGPZMPaExTZSA actual stars  - 4.000000 predicted - 4.860883\n"
     ]
    }
   ],
   "source": [
    "# list  the business with the stars and prediction\n",
    "\n",
    "for i in range(0,10):\n",
    "    idx=y_test.index[i]\n",
    "    print(\"business id - %s actual stars  - %f predicted - %f\" \n",
    "          %(merge_df['business_id'][idx], y_test[idx], y_pred_linear[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 0.31\n",
      "Variance score: 0.69\n"
     ]
    }
   ],
   "source": [
    "# RMS value\n",
    "\n",
    "score_lin_classic = np.sqrt(mean_squared_error(y_test, y_pred_linear))\n",
    "print(\"Root Mean Squared Error: %.2f\" % score_lin_classic)\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label encoding data for logistic regression\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "merge_df['encoded_stars'] = label_encoder.fit_transform(merge_df['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test data afor other models\n",
    "\n",
    "x_train_lr, x_test_lr, y_train_lr, y_test_lr = train_test_split(x_matrix_minmax, merge_df['encoded_stars'] , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logistic Regression\n",
    "\n",
    "Log_reg_model = LogisticRegression()\n",
    "\n",
    "Log_reg_model.fit(x_train_lr, y_train_lr)\n",
    "\n",
    "y_pred_logistic = Log_reg_model.predict(x_test_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[ 0.54123407  0.4596704   0.24957758 ... -0.09934215 -0.1649154\n",
      "  -0.50320092]\n",
      " [ 0.8270038   0.3860916   0.11110198 ... -0.04999578 -0.27721436\n",
      "  -0.34176423]\n",
      " [ 1.15831347 -0.04428173  0.10653449 ... -0.18289116 -0.43772759\n",
      "  -0.87256034]\n",
      " ...\n",
      " [-0.24115021  0.12496914 -0.48373097 ...  0.65980756  0.92526212\n",
      "   1.99547613]\n",
      " [-0.64472009 -0.40898215 -0.27480355 ...  0.50743112  0.40815838\n",
      "   0.75420204]\n",
      " [-1.37678973 -1.06791059 -0.30742935 ... -0.28820785  0.1929923\n",
      "  -1.0200172 ]]\n",
      "Mean squared error: 1.94\n",
      "Variance score: 0.51\n"
     ]
    }
   ],
   "source": [
    "# RMs for logistic\n",
    "\n",
    "score_log_classic = np.sqrt(mean_squared_error(y_test_lr, y_pred_logistic))\n",
    "print(\"Root Mean Squared Error: %.2f\" % score_log_classic)\n",
    "print('Variance score: %.2f' % r2_score(y_test_lr, y_pred_logistic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Model for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training without early stopping and Model Checkpoint and RELU **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tensor flow works well with 32 bit\n",
    "y_stars_regression = merge_df['stars'].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train test data\n",
    "x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x_matrix_minmax, y_stars_regression , test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow model for Regression with RELU\n",
    "\n",
    "model_reg_relu = Sequential()\n",
    "\n",
    "model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "model_reg_relu.add(Dense(1)) # Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 1.7844\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.3280\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2671\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2474\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2377\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.2264\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.2039\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.1809\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.1569\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.1371\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.1156\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0998\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.0857\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.0760\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0664\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0600\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0537\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.0476\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.0421\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.0394\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.0365\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.0335\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0308\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.0282\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0264\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0245\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0235\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0236\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.0223\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.0199\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.0195\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.0176\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0156\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.0151\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.0142\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.0149\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.0147\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0144\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0142\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.0128\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.0128\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.0141\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0140\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.0128\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0115\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0109\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.0103\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.0101\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.0104\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0100\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0097\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.0093\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.0104\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.0107\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0100\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0107\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0089\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0089\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0091\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.0078\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.0076\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.0084\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.0082\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.0084\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.0085\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.0087\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.0079\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.0071\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.0069\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.0073\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.0079\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.0077\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.0077\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.0072\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.0072\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0070\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0068\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0068\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0063\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.0062\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.0063\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0059\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.0067\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.0070\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.0067\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.0063\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0054\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0055\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0061\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.0063\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.0057\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.0055\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0054\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0054\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.0058\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.0058\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.0059\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0055\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0055\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x203b44b77b8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model training with Optimizer = adam\n",
    "\n",
    "model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_reg_relu.fit(x_train_reg,y_train_reg,verbose=2,epochs=100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1996, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_simple = model_reg_relu.predict(x_test_reg)\n",
    "print(\"Shape: {}\".format(pred_reg_simple.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 4.0, predicted Stars: [3.932604]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 5.0, predicted Stars: [4.406552]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [5.098876]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 3.0, predicted Stars: [2.5978472]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [5.0414157]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 2.0, predicted Stars: [1.7984514]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 2.5, predicted Stars: [2.4023979]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.049566]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [4.8751554]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 5.0, predicted Stars: [4.797533]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_simple[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.571011483669281\n",
      "R2 score: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_nn_relu = np.sqrt(mean_squared_error(y_test_reg,pred_reg_simple))\n",
    "print(\"Final score (RMSE): {}\".format(score_nn_relu))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training with early stopping and Model Checkpoint ReLU **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup early stopping monitor\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0053 - mean_absolute_error: 0.0520 - val_loss: 0.3349 - val_mean_absolute_error: 0.4353\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33489, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0049 - mean_absolute_error: 0.0513 - val_loss: 0.3279 - val_mean_absolute_error: 0.4311\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33489 to 0.32794, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0059 - mean_absolute_error: 0.0563 - val_loss: 0.3301 - val_mean_absolute_error: 0.4322\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32794\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0057 - mean_absolute_error: 0.0548 - val_loss: 0.3282 - val_mean_absolute_error: 0.4305\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32794\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0051 - mean_absolute_error: 0.0519 - val_loss: 0.3348 - val_mean_absolute_error: 0.4354\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32794\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0051 - mean_absolute_error: 0.0519 - val_loss: 0.3347 - val_mean_absolute_error: 0.4358\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32794\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0047 - mean_absolute_error: 0.0501 - val_loss: 0.3258 - val_mean_absolute_error: 0.4291\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.32794 to 0.32580, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0053 - mean_absolute_error: 0.0535 - val_loss: 0.3293 - val_mean_absolute_error: 0.4320\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32580\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0052 - mean_absolute_error: 0.0518 - val_loss: 0.3331 - val_mean_absolute_error: 0.4344\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32580\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0049 - mean_absolute_error: 0.0506 - val_loss: 0.3264 - val_mean_absolute_error: 0.4297\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32580\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0049 - mean_absolute_error: 0.0508 - val_loss: 0.3307 - val_mean_absolute_error: 0.4316\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32580\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0046 - mean_absolute_error: 0.0499 - val_loss: 0.3289 - val_mean_absolute_error: 0.4315\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32580\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0047 - mean_absolute_error: 0.0501 - val_loss: 0.3305 - val_mean_absolute_error: 0.4321\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32580\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0051 - mean_absolute_error: 0.0524 - val_loss: 0.3288 - val_mean_absolute_error: 0.4314\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32580\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0049 - mean_absolute_error: 0.0497 - val_loss: 0.3273 - val_mean_absolute_error: 0.4306\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32580\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0049 - mean_absolute_error: 0.0502 - val_loss: 0.3321 - val_mean_absolute_error: 0.4318\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32580\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0049 - mean_absolute_error: 0.0509 - val_loss: 0.3305 - val_mean_absolute_error: 0.4317\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32580\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0049 - mean_absolute_error: 0.0506 - val_loss: 0.3318 - val_mean_absolute_error: 0.4319\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32580\n",
      "Epoch 00008: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0046 - mean_absolute_error: 0.0490 - val_loss: 0.3288 - val_mean_absolute_error: 0.4301\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32580\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0043 - mean_absolute_error: 0.0473 - val_loss: 0.3307 - val_mean_absolute_error: 0.4310\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32580\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0044 - mean_absolute_error: 0.0483 - val_loss: 0.3277 - val_mean_absolute_error: 0.4295\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32580\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0045 - mean_absolute_error: 0.0489 - val_loss: 0.3285 - val_mean_absolute_error: 0.4305\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32580\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0048 - mean_absolute_error: 0.0502 - val_loss: 0.3273 - val_mean_absolute_error: 0.4289\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32580\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0045 - mean_absolute_error: 0.0489 - val_loss: 0.3279 - val_mean_absolute_error: 0.4296\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32580\n",
      "Epoch 00006: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0044 - mean_absolute_error: 0.0470 - val_loss: 0.3290 - val_mean_absolute_error: 0.4298\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32580\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0040 - mean_absolute_error: 0.0460 - val_loss: 0.3285 - val_mean_absolute_error: 0.4301\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32580\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0040 - mean_absolute_error: 0.0455 - val_loss: 0.3276 - val_mean_absolute_error: 0.4288\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32580\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0046 - mean_absolute_error: 0.0498 - val_loss: 0.3240 - val_mean_absolute_error: 0.4274\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.32580 to 0.32402, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0048 - mean_absolute_error: 0.0507 - val_loss: 0.3280 - val_mean_absolute_error: 0.4290\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32402\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0044 - mean_absolute_error: 0.0479 - val_loss: 0.3244 - val_mean_absolute_error: 0.4273\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32402\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0043 - mean_absolute_error: 0.0477 - val_loss: 0.3265 - val_mean_absolute_error: 0.4284\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32402\n",
      "Epoch 00007: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0039 - mean_absolute_error: 0.0454 - val_loss: 0.3269 - val_mean_absolute_error: 0.4287\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32402\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0040 - mean_absolute_error: 0.0467 - val_loss: 0.3274 - val_mean_absolute_error: 0.4293\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32402\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0043 - mean_absolute_error: 0.0484 - val_loss: 0.3282 - val_mean_absolute_error: 0.4299\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32402\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0039 - mean_absolute_error: 0.0460 - val_loss: 0.3285 - val_mean_absolute_error: 0.4303\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32402\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0038 - mean_absolute_error: 0.0450 - val_loss: 0.3260 - val_mean_absolute_error: 0.4281\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32402\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0035 - mean_absolute_error: 0.0436 - val_loss: 0.3284 - val_mean_absolute_error: 0.4303\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32402\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0041 - mean_absolute_error: 0.0472 - val_loss: 0.3270 - val_mean_absolute_error: 0.4294\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32402\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0041 - mean_absolute_error: 0.0468 - val_loss: 0.3239 - val_mean_absolute_error: 0.4267\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.32402 to 0.32390, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0039 - mean_absolute_error: 0.0452 - val_loss: 0.3250 - val_mean_absolute_error: 0.4274\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32390\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0040 - mean_absolute_error: 0.0461 - val_loss: 0.3266 - val_mean_absolute_error: 0.4300\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32390\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0038 - mean_absolute_error: 0.0459 - val_loss: 0.3264 - val_mean_absolute_error: 0.4277\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32390\n",
      "Epoch 00007: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0035 - mean_absolute_error: 0.0437 - val_loss: 0.3249 - val_mean_absolute_error: 0.4286\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32390\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0034 - mean_absolute_error: 0.0427 - val_loss: 0.3258 - val_mean_absolute_error: 0.4280\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32390\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.0038 - mean_absolute_error: 0.0454 - val_loss: 0.3248 - val_mean_absolute_error: 0.4276\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32390\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0036 - mean_absolute_error: 0.0437 - val_loss: 0.3238 - val_mean_absolute_error: 0.4265\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.32390 to 0.32380, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0038 - mean_absolute_error: 0.0456 - val_loss: 0.3264 - val_mean_absolute_error: 0.4290\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32380\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0038 - mean_absolute_error: 0.0447 - val_loss: 0.3246 - val_mean_absolute_error: 0.4271\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32380\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.0036 - mean_absolute_error: 0.0441 - val_loss: 0.3249 - val_mean_absolute_error: 0.4280\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32380\n",
      "Epoch 00007: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.0033 - mean_absolute_error: 0.0421 - val_loss: 0.3234 - val_mean_absolute_error: 0.4262\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32380 to 0.32336, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0030 - mean_absolute_error: 0.0399 - val_loss: 0.3250 - val_mean_absolute_error: 0.4286\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32336\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0033 - mean_absolute_error: 0.0427 - val_loss: 0.3248 - val_mean_absolute_error: 0.4286\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32336\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0037 - mean_absolute_error: 0.0448 - val_loss: 0.3248 - val_mean_absolute_error: 0.4287\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32336\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0035 - mean_absolute_error: 0.0433 - val_loss: 0.3251 - val_mean_absolute_error: 0.4282\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32336\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0027 - mean_absolute_error: 0.0385 - val_loss: 0.3247 - val_mean_absolute_error: 0.4284\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32336\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0027 - mean_absolute_error: 0.0386 - val_loss: 0.3208 - val_mean_absolute_error: 0.4253\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32336 to 0.32081, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0032 - mean_absolute_error: 0.0416 - val_loss: 0.3218 - val_mean_absolute_error: 0.4261\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32081\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0039 - mean_absolute_error: 0.0452 - val_loss: 0.3249 - val_mean_absolute_error: 0.4280\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32081\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0036 - mean_absolute_error: 0.0445 - val_loss: 0.3233 - val_mean_absolute_error: 0.4272\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32081\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "\n",
    "model_reg_relu.load_weights('./best_weights_relu.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1996, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_stopping = model_reg_relu.predict(x_test_reg)\n",
    "print(\"Shape: {}\".format(pred_reg_stopping.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 4.0, predicted Stars: [4.173663]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 5.0, predicted Stars: [4.563887]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [5.1475673]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 3.0, predicted Stars: [2.724129]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [5.0381064]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 2.0, predicted Stars: [1.8037164]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 2.5, predicted Stars: [2.463274]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.127126]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [5.0190687]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 5.0, predicted Stars: [4.821728]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_stopping[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5663977265357971\n",
      "R2 score: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_nn_relu_stopping = np.sqrt(mean_squared_error(y_test_reg,pred_reg_stopping))\n",
    "print(\"Final score (RMSE): {}\".format(score_nn_relu_stopping))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_stopping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training without early stopping and Model Checkpoint and Sigmoid **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow model for Regression with sigmoid\n",
    "model_reg_sig = Sequential()\n",
    "\n",
    "model_reg_sig.add(Dense(25, input_dim=x_train_reg.shape[1], activation='sigmoid'))  \n",
    "model_reg_sig.add(Dense(10, activation='sigmoid')) # Hidden 2\n",
    "model_reg_sig.add(Dense(1)) # Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 4.7493\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.1528\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.0442\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.0178\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.9361\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.6990\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.4578\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.3319\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.2782\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.2521\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.2368\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.2270\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.2200\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.2145\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.2104\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.2066\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.2032\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.2003\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.1977\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.1953\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.1934\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.1907\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.1892\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.1878\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.1856\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.1848\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.1838\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.1821\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.1805\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.1799\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.1777\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.1772\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.1763\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.1748\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.1744\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.1733\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.1725\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.1716\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.1713\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.1696\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.1686\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.1683\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.1670\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.1672\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.1661\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.1654\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.1644\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.1636\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.1631\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.1623\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.1619\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.1610\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.1605\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.1596\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.1589\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.1585\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.1584\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.1571\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.1565\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.1559\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.1552\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.1550\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.1545\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.1532\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.1530\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.1529\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.1519\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.1510\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.1504\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.1507\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.1496\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.1492\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.1486\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.1482\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.1476\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.1467\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.1465\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.1458\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.1456\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.1445\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.1440\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.1436\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.1432\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.1430\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.1422\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.1423\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.1414\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.1404\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.1403\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.1392\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.1390\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.1380\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.1375\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.1373\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.1369\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.1363\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.1358\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.1354\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.1346\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.1341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20395591518>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training with sigmoid \n",
    "model_reg_sig.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_reg_sig.fit(x_train_reg,y_train_reg,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1996, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_sig_simple = model_reg_sig.predict(x_test_reg)\n",
    "print(\"Shape: {}\".format(pred_reg_sig_simple.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 4.0, predicted Stars: [4.3263874]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 5.0, predicted Stars: [4.8745313]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.9969363]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 3.0, predicted Stars: [2.9743967]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [5.036073]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 2.0, predicted Stars: [2.214703]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 2.5, predicted Stars: [2.3479881]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.137304]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [4.7220745]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 5.0, predicted Stars: [4.7905393]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_sig_simple[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.49363577365875244\n",
      "R2 score: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_nn_sig = np.sqrt(mean_squared_error(y_test_reg,pred_reg_sig_simple))\n",
    "print(\"Final score (RMSE): {}\".format(score_nn_sig))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_sig_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training with early stopping and Model Checkpoint and Sigmoid **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup early stopping monitor\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_sigmoid = ModelCheckpoint(filepath=\"./best_weights_sigmoid.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.1337 - mean_absolute_error: 0.2757 - val_loss: 0.2471 - val_mean_absolute_error: 0.3644\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24711, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.1332 - mean_absolute_error: 0.2748 - val_loss: 0.2433 - val_mean_absolute_error: 0.3608\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24711 to 0.24332, saving model to ./best_weights_sigmoid.hdf5\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.1326 - mean_absolute_error: 0.2745 - val_loss: 0.2444 - val_mean_absolute_error: 0.3623\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24332\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.1317 - mean_absolute_error: 0.2739 - val_loss: 0.2448 - val_mean_absolute_error: 0.3611\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24332\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.1316 - mean_absolute_error: 0.2734 - val_loss: 0.2453 - val_mean_absolute_error: 0.3613\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.24332\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.1308 - mean_absolute_error: 0.2723 - val_loss: 0.2461 - val_mean_absolute_error: 0.3619\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24332\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.1304 - mean_absolute_error: 0.2719 - val_loss: 0.2459 - val_mean_absolute_error: 0.3624\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24332\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.1294 - mean_absolute_error: 0.2713 - val_loss: 0.2481 - val_mean_absolute_error: 0.3637\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24332\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.1289 - mean_absolute_error: 0.2708 - val_loss: 0.2474 - val_mean_absolute_error: 0.3629\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24332\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.1288 - mean_absolute_error: 0.2707 - val_loss: 0.2473 - val_mean_absolute_error: 0.3628\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24332\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.1282 - mean_absolute_error: 0.2696 - val_loss: 0.2474 - val_mean_absolute_error: 0.3647\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24332\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.1274 - mean_absolute_error: 0.2692 - val_loss: 0.2490 - val_mean_absolute_error: 0.3641\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24332\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.1263 - mean_absolute_error: 0.2679 - val_loss: 0.2513 - val_mean_absolute_error: 0.3673\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24332\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.1261 - mean_absolute_error: 0.2675 - val_loss: 0.2483 - val_mean_absolute_error: 0.3645\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24332\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.1252 - mean_absolute_error: 0.2664 - val_loss: 0.2527 - val_mean_absolute_error: 0.3692\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24332\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.1249 - mean_absolute_error: 0.2666 - val_loss: 0.2517 - val_mean_absolute_error: 0.3657\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24332\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.1241 - mean_absolute_error: 0.2657 - val_loss: 0.2511 - val_mean_absolute_error: 0.3659\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24332\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.1236 - mean_absolute_error: 0.2653 - val_loss: 0.2508 - val_mean_absolute_error: 0.3657\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24332\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.1229 - mean_absolute_error: 0.2643 - val_loss: 0.2521 - val_mean_absolute_error: 0.3665\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24332\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.1218 - mean_absolute_error: 0.2634 - val_loss: 0.2523 - val_mean_absolute_error: 0.3673\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24332\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.1220 - mean_absolute_error: 0.2635 - val_loss: 0.2525 - val_mean_absolute_error: 0.3663\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24332\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.1208 - mean_absolute_error: 0.2620 - val_loss: 0.2525 - val_mean_absolute_error: 0.3661\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24332\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.1199 - mean_absolute_error: 0.2618 - val_loss: 0.2549 - val_mean_absolute_error: 0.3678\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24332\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.1191 - mean_absolute_error: 0.2609 - val_loss: 0.2533 - val_mean_absolute_error: 0.3687\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24332\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.1183 - mean_absolute_error: 0.2597 - val_loss: 0.2532 - val_mean_absolute_error: 0.3681\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24332\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.1179 - mean_absolute_error: 0.2593 - val_loss: 0.2567 - val_mean_absolute_error: 0.3704\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24332\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.1173 - mean_absolute_error: 0.2586 - val_loss: 0.2547 - val_mean_absolute_error: 0.3683\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24332\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.1164 - mean_absolute_error: 0.2582 - val_loss: 0.2569 - val_mean_absolute_error: 0.3709\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24332\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.1159 - mean_absolute_error: 0.2576 - val_loss: 0.2557 - val_mean_absolute_error: 0.3688\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24332\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.1148 - mean_absolute_error: 0.2563 - val_loss: 0.2572 - val_mean_absolute_error: 0.3694\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.24332\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.1147 - mean_absolute_error: 0.2560 - val_loss: 0.2590 - val_mean_absolute_error: 0.3721\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24332\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.1136 - mean_absolute_error: 0.2550 - val_loss: 0.2582 - val_mean_absolute_error: 0.3696\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24332\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.1128 - mean_absolute_error: 0.2540 - val_loss: 0.2622 - val_mean_absolute_error: 0.3738\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24332\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.1117 - mean_absolute_error: 0.2532 - val_loss: 0.2637 - val_mean_absolute_error: 0.3754\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24332\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.1115 - mean_absolute_error: 0.2530 - val_loss: 0.2680 - val_mean_absolute_error: 0.3789\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24332\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.1106 - mean_absolute_error: 0.2519 - val_loss: 0.2633 - val_mean_absolute_error: 0.3741\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24332\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.1095 - mean_absolute_error: 0.2506 - val_loss: 0.2620 - val_mean_absolute_error: 0.3720\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24332\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.1091 - mean_absolute_error: 0.2506 - val_loss: 0.2623 - val_mean_absolute_error: 0.3743\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24332\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.1082 - mean_absolute_error: 0.2497 - val_loss: 0.2643 - val_mean_absolute_error: 0.3758\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.24332\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1074 - mean_absolute_error: 0.2490 - val_loss: 0.2651 - val_mean_absolute_error: 0.3752\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.24332\n",
      "Epoch 00006: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.1068 - mean_absolute_error: 0.2481 - val_loss: 0.2663 - val_mean_absolute_error: 0.3750\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24332\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.1064 - mean_absolute_error: 0.2472 - val_loss: 0.2645 - val_mean_absolute_error: 0.3748\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24332\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.1050 - mean_absolute_error: 0.2459 - val_loss: 0.2670 - val_mean_absolute_error: 0.3770\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24332\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.1045 - mean_absolute_error: 0.2457 - val_loss: 0.2678 - val_mean_absolute_error: 0.3777\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24332\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.1037 - mean_absolute_error: 0.2445 - val_loss: 0.2678 - val_mean_absolute_error: 0.3770\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.24332\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model_reg_sig.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_reg_sig.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_sigmoid],verbose=2,epochs=100) \n",
    "\n",
    "model_reg_sig.load_weights('./best_weights_sigmoid.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1996, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_sig_stopping = model_reg_sig.predict(x_test_reg)\n",
    "print(\"Shape: {}\".format(pred_reg_sig_stopping.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 4.0, predicted Stars: [4.3110037]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 5.0, predicted Stars: [4.848142]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 5.0, predicted Stars: [4.971846]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 3.0, predicted Stars: [2.980784]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 5.0, predicted Stars: [5.0126925]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 2.0, predicted Stars: [2.21557]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 2.5, predicted Stars: [2.3348935]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.1198955]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5.0, predicted Stars: [4.702338]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 5.0, predicted Stars: [4.772306]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_sig_stopping[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.4932701885700226\n",
      "R2 score: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_nn_sig_stopping = np.sqrt(mean_squared_error(y_test_reg,pred_reg_sig_stopping))\n",
    "print(\"Final score (RMSE): {}\".format(score_nn_sig_stopping))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_sig_stopping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training without early stopping and Model Checkpoint and Tanh **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train test data\n",
    "x_train_reg_tanh, x_test_reg_tanh, y_train_reg_tanh, y_test_reg_tanh = train_test_split(x_matrix_zscore, y_stars_regression , test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow model for Regression with sigmoid\n",
    "model_reg_tanh = Sequential()\n",
    "\n",
    "model_reg_tanh.add(Dense(25, input_dim=x_train_reg_tanh.shape[1], activation='tanh'))  \n",
    "model_reg_tanh.add(Dense(10, activation='tanh')) # Hidden 2\n",
    "model_reg_tanh.add(Dense(1)) # Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 1.8583\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.3537\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2513\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.2288\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.2163\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.2090\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.2025\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.1961\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.1911\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.1857\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.1812\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.1784\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1735\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1692\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.1651\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.1625\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.1602\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.1569\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.1555\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.1529\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.1496\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.1488\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.1454\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.1433\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.1416\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.1399\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.1379\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.1354\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.1348\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.1324\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.1302\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.1282\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.1264\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.1249\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.1229\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.1212\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.1192\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.1179\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.1164\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.1154\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.1128\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.1110\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.1088\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.1073\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.1052\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.1035\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.1024\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.1004\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0992\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0969\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0952\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0935\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0914\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0894\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.0879\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.0863\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.0841\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.0829\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.0809\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.0787\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.0772\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.0752\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.0739\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.0713\n",
      "Epoch 65/100\n",
      " - 2s - loss: 0.0695\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.0682\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.0662\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.0646\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.0630\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.0613\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.0604\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.0583\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.0569\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0557\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0545\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0528\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0515\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0501\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0487\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0473\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0463\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.0452\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.0439\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.0433\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.0418\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.0413\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.0399\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0383\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0381\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0368\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0363\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0355\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.0344\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.0333\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0325\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0321\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0317\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0306\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0298\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201cbdb04a8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training with sigmoid \n",
    "model_reg_tanh.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_reg_tanh.fit(x_train_reg_tanh,y_train_reg_tanh,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1996, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_tanh_simple = model_reg_tanh.predict(x_test_reg_tanh)\n",
    "print(\"Shape: {}\".format(pred_reg_tanh_simple.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 4.0, predicted Stars: [4.5639753]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.0, predicted Stars: [3.845708]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [3.7652197]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.5, predicted Stars: [5.173068]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 3.5, predicted Stars: [3.076366]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.0, predicted Stars: [3.0328262]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [3.4399014]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.311018]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 4.5, predicted Stars: [3.6813293]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.5, predicted Stars: [4.638321]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg_tanh[i],pred_reg_tanh_simple[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.7128996849060059\n",
      "R2 score: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_nn_tanh = np.sqrt(mean_squared_error(y_test_reg_tanh,pred_reg_tanh_simple))\n",
    "print(\"Final score (RMSE): {}\".format(score_nn_tanh))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg_tanh, pred_reg_tanh_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training with early stopping and Model Checkpoint and Tanh **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup early stopping monitor\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_tanh = ModelCheckpoint(filepath=\"./best_weights_tanh.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0294 - mean_absolute_error: 0.1266 - val_loss: 0.4955 - val_mean_absolute_error: 0.5021\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.49546, saving model to ./best_weights_tanh.hdf5\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0278 - mean_absolute_error: 0.1225 - val_loss: 0.5096 - val_mean_absolute_error: 0.5077\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.49546\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0273 - mean_absolute_error: 0.1215 - val_loss: 0.5030 - val_mean_absolute_error: 0.5041\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.49546\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0271 - mean_absolute_error: 0.1210 - val_loss: 0.5135 - val_mean_absolute_error: 0.5110\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.49546\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0267 - mean_absolute_error: 0.1199 - val_loss: 0.5035 - val_mean_absolute_error: 0.5069\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.49546\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0255 - mean_absolute_error: 0.1171 - val_loss: 0.5070 - val_mean_absolute_error: 0.5058\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.49546\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0250 - mean_absolute_error: 0.1163 - val_loss: 0.5174 - val_mean_absolute_error: 0.5121\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.49546\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0247 - mean_absolute_error: 0.1150 - val_loss: 0.5147 - val_mean_absolute_error: 0.5113\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.49546\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0249 - mean_absolute_error: 0.1163 - val_loss: 0.5086 - val_mean_absolute_error: 0.5127\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.49546\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0234 - mean_absolute_error: 0.1120 - val_loss: 0.5158 - val_mean_absolute_error: 0.5119\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.49546\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0226 - mean_absolute_error: 0.1102 - val_loss: 0.5183 - val_mean_absolute_error: 0.5161\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.49546\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0223 - mean_absolute_error: 0.1089 - val_loss: 0.5174 - val_mean_absolute_error: 0.5142\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.49546\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0227 - mean_absolute_error: 0.1106 - val_loss: 0.5182 - val_mean_absolute_error: 0.5161\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.49546\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0215 - mean_absolute_error: 0.1071 - val_loss: 0.5190 - val_mean_absolute_error: 0.5159\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.49546\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0215 - mean_absolute_error: 0.1072 - val_loss: 0.5221 - val_mean_absolute_error: 0.5166\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.49546\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0204 - mean_absolute_error: 0.1038 - val_loss: 0.5257 - val_mean_absolute_error: 0.5178\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.49546\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0205 - mean_absolute_error: 0.1045 - val_loss: 0.5180 - val_mean_absolute_error: 0.5150\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.49546\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0197 - mean_absolute_error: 0.1018 - val_loss: 0.5213 - val_mean_absolute_error: 0.5175\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.49546\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0195 - mean_absolute_error: 0.1012 - val_loss: 0.5250 - val_mean_absolute_error: 0.5195\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.49546\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0192 - mean_absolute_error: 0.1014 - val_loss: 0.5191 - val_mean_absolute_error: 0.5172\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.49546\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0192 - mean_absolute_error: 0.1014 - val_loss: 0.5234 - val_mean_absolute_error: 0.5187\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.49546\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0180 - mean_absolute_error: 0.0975 - val_loss: 0.5231 - val_mean_absolute_error: 0.5195\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.49546\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0178 - mean_absolute_error: 0.0966 - val_loss: 0.5260 - val_mean_absolute_error: 0.5208\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.49546\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0173 - mean_absolute_error: 0.0950 - val_loss: 0.5283 - val_mean_absolute_error: 0.5215\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.49546\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0175 - mean_absolute_error: 0.0959 - val_loss: 0.5299 - val_mean_absolute_error: 0.5226\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.49546\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0167 - mean_absolute_error: 0.0933 - val_loss: 0.5441 - val_mean_absolute_error: 0.5267\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.49546\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0160 - mean_absolute_error: 0.0913 - val_loss: 0.5379 - val_mean_absolute_error: 0.5263\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.49546\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0160 - mean_absolute_error: 0.0915 - val_loss: 0.5357 - val_mean_absolute_error: 0.5255\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.49546\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.0162 - mean_absolute_error: 0.0922 - val_loss: 0.5327 - val_mean_absolute_error: 0.5239\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.49546\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0152 - mean_absolute_error: 0.0890 - val_loss: 0.5374 - val_mean_absolute_error: 0.5271\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.49546\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0150 - mean_absolute_error: 0.0879 - val_loss: 0.5322 - val_mean_absolute_error: 0.5256\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.49546\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0148 - mean_absolute_error: 0.0878 - val_loss: 0.5326 - val_mean_absolute_error: 0.5243\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.49546\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.0148 - mean_absolute_error: 0.0879 - val_loss: 0.5310 - val_mean_absolute_error: 0.5242\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.49546\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0145 - mean_absolute_error: 0.0862 - val_loss: 0.5359 - val_mean_absolute_error: 0.5257\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.49546\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0140 - mean_absolute_error: 0.0847 - val_loss: 0.5367 - val_mean_absolute_error: 0.5255\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.49546\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0135 - mean_absolute_error: 0.0825 - val_loss: 0.5362 - val_mean_absolute_error: 0.5257\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.49546\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.0140 - mean_absolute_error: 0.0855 - val_loss: 0.5368 - val_mean_absolute_error: 0.5269\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.49546\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0133 - mean_absolute_error: 0.0827 - val_loss: 0.5367 - val_mean_absolute_error: 0.5264\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.49546\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0130 - mean_absolute_error: 0.0817 - val_loss: 0.5355 - val_mean_absolute_error: 0.5268\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.49546\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0129 - mean_absolute_error: 0.0815 - val_loss: 0.5431 - val_mean_absolute_error: 0.5285\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.49546\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0124 - mean_absolute_error: 0.0800 - val_loss: 0.5440 - val_mean_absolute_error: 0.5291\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.49546\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.0126 - mean_absolute_error: 0.0792 - val_loss: 0.5399 - val_mean_absolute_error: 0.5293\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.49546\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model_reg_tanh.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_reg_tanh.fit(x_train_reg_tanh,y_train_reg_tanh,validation_data=(x_test_reg_tanh,y_test_reg_tanh),callbacks=[monitor,checkpointer_tanh],verbose=2,epochs=100) \n",
    "\n",
    "model_reg_tanh.load_weights('./best_weights_tanh.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1996, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_tanh_stopping = model_reg_tanh.predict(x_test_reg_tanh)\n",
    "print(\"Shape: {}\".format(pred_reg_tanh_stopping.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 4.0, predicted Stars: [4.504297]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 4.0, predicted Stars: [3.8482068]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 3.5, predicted Stars: [3.6773396]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 4.5, predicted Stars: [5.1430335]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 3.5, predicted Stars: [3.172525]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.0, predicted Stars: [3.00534]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 4.0, predicted Stars: [3.407479]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 4.0, predicted Stars: [4.2344093]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 4.5, predicted Stars: [3.590742]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.5, predicted Stars: [4.5824337]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg_tanh[i],pred_reg_tanh_stopping[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.7038869261741638\n",
      "R2 score: 0.55\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_nn_tanh_stopping = np.sqrt(mean_squared_error(y_test_reg_tanh,pred_reg_tanh_stopping))\n",
    "print(\"Final score (RMSE): {}\".format(score_nn_tanh_stopping))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg_tanh, pred_reg_tanh_stopping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu with Postal Code and Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot cooding of postal codes \n",
    "\n",
    "postal_hotcoded_df = pd.get_dummies(merge_df['postal code'], sparse = 'true')\n",
    "\n",
    "x_matrix_postal = np.column_stack((x_matrix_minmax, postal_hotcoded_df))\n",
    "x_matrix_final = np.column_stack((x_matrix_postal, category_matrix))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9977,)\n"
     ]
    }
   ],
   "source": [
    "print(y_stars_regression.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train test data\n",
    "x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x_matrix_final, y_stars_regression , test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_postal.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tensorflow model for regression\n",
    "model_reg_relu = Sequential()\n",
    "\n",
    "model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu')) \n",
    "model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "model_reg_relu.add(Dense(1)) # Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 0.0035 - mean_absolute_error: 0.0448 - val_loss: 0.3192 - val_mean_absolute_error: 0.4348\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31693\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.0027 - mean_absolute_error: 0.0399 - val_loss: 0.3195 - val_mean_absolute_error: 0.4340\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31693\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.0031 - mean_absolute_error: 0.0423 - val_loss: 0.3221 - val_mean_absolute_error: 0.4359\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31693\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.0034 - mean_absolute_error: 0.0440 - val_loss: 0.3211 - val_mean_absolute_error: 0.4359\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31693\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.0035 - mean_absolute_error: 0.0448 - val_loss: 0.3212 - val_mean_absolute_error: 0.4365\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31693\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.0027 - mean_absolute_error: 0.0395 - val_loss: 0.3193 - val_mean_absolute_error: 0.4341\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31693\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.0030 - mean_absolute_error: 0.0422 - val_loss: 0.3210 - val_mean_absolute_error: 0.4366\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31693\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.0033 - mean_absolute_error: 0.0436 - val_loss: 0.3195 - val_mean_absolute_error: 0.4343\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31693\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.0034 - mean_absolute_error: 0.0440 - val_loss: 0.3205 - val_mean_absolute_error: 0.4356\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31693\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 0.0031 - mean_absolute_error: 0.0422 - val_loss: 0.3186 - val_mean_absolute_error: 0.4333\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31693\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.0026 - mean_absolute_error: 0.0390 - val_loss: 0.3200 - val_mean_absolute_error: 0.4353\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31693\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.0028 - mean_absolute_error: 0.0397 - val_loss: 0.3201 - val_mean_absolute_error: 0.4358\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31693\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.0030 - mean_absolute_error: 0.0417 - val_loss: 0.3229 - val_mean_absolute_error: 0.4374\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31693\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 0.0030 - mean_absolute_error: 0.0415 - val_loss: 0.3186 - val_mean_absolute_error: 0.4341\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31693\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.0023 - mean_absolute_error: 0.0368 - val_loss: 0.3206 - val_mean_absolute_error: 0.4348\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31693\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.0028 - mean_absolute_error: 0.0404 - val_loss: 0.3200 - val_mean_absolute_error: 0.4351\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31693\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.0031 - mean_absolute_error: 0.0428 - val_loss: 0.3187 - val_mean_absolute_error: 0.4334\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31693\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 0.0029 - mean_absolute_error: 0.0411 - val_loss: 0.3188 - val_mean_absolute_error: 0.4342\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31693\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.0025 - mean_absolute_error: 0.0380 - val_loss: 0.3205 - val_mean_absolute_error: 0.4356\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31693\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.0027 - mean_absolute_error: 0.0393 - val_loss: 0.3165 - val_mean_absolute_error: 0.4322\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.31693 to 0.31655, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.0029 - mean_absolute_error: 0.0409 - val_loss: 0.3208 - val_mean_absolute_error: 0.4341\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31655\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.0028 - mean_absolute_error: 0.0400 - val_loss: 0.3179 - val_mean_absolute_error: 0.4339\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31655\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0029 - mean_absolute_error: 0.0407 - val_loss: 0.3214 - val_mean_absolute_error: 0.4361\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31655\n",
      "Epoch 00006: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 0.0026 - mean_absolute_error: 0.0391 - val_loss: 0.3176 - val_mean_absolute_error: 0.4328\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31655\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0022 - mean_absolute_error: 0.0356 - val_loss: 0.3200 - val_mean_absolute_error: 0.4351\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31655\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.0028 - mean_absolute_error: 0.0402 - val_loss: 0.3185 - val_mean_absolute_error: 0.4346\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31655\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.0030 - mean_absolute_error: 0.0420 - val_loss: 0.3171 - val_mean_absolute_error: 0.4331\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31655\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 0.0026 - mean_absolute_error: 0.0386 - val_loss: 0.3168 - val_mean_absolute_error: 0.4335\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31655\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0023 - mean_absolute_error: 0.0375 - val_loss: 0.3174 - val_mean_absolute_error: 0.4338\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31655\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.0025 - mean_absolute_error: 0.0382 - val_loss: 0.3165 - val_mean_absolute_error: 0.4335\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.31655 to 0.31654, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.0027 - mean_absolute_error: 0.0400 - val_loss: 0.3194 - val_mean_absolute_error: 0.4337\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31654\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 7s - loss: 0.0027 - mean_absolute_error: 0.0395 - val_loss: 0.3179 - val_mean_absolute_error: 0.4334\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31654\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0022 - mean_absolute_error: 0.0358 - val_loss: 0.3160 - val_mean_absolute_error: 0.4326\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31654 to 0.31599, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.0023 - mean_absolute_error: 0.0362 - val_loss: 0.3176 - val_mean_absolute_error: 0.4334\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31599\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.0023 - mean_absolute_error: 0.0362 - val_loss: 0.3194 - val_mean_absolute_error: 0.4338\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31599\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.0024 - mean_absolute_error: 0.0368 - val_loss: 0.3173 - val_mean_absolute_error: 0.4334\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31599\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 0.0025 - mean_absolute_error: 0.0380 - val_loss: 0.3177 - val_mean_absolute_error: 0.4323\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31599\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.0019 - mean_absolute_error: 0.0333 - val_loss: 0.3171 - val_mean_absolute_error: 0.4321\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31599\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.0024 - mean_absolute_error: 0.0371 - val_loss: 0.3180 - val_mean_absolute_error: 0.4324\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31599\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.0026 - mean_absolute_error: 0.0386 - val_loss: 0.3169 - val_mean_absolute_error: 0.4331\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31599\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 0.0025 - mean_absolute_error: 0.0378 - val_loss: 0.3151 - val_mean_absolute_error: 0.4298\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31599 to 0.31507, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.0019 - mean_absolute_error: 0.0330 - val_loss: 0.3161 - val_mean_absolute_error: 0.4323\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31507\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.0020 - mean_absolute_error: 0.0337 - val_loss: 0.3149 - val_mean_absolute_error: 0.4310\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.31507 to 0.31491, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 3s - loss: 0.0024 - mean_absolute_error: 0.0371 - val_loss: 0.3146 - val_mean_absolute_error: 0.4310\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.31491 to 0.31459, saving model to ./best_weights_relu.hdf5\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "\n",
    "model_reg_relu.load_weights('./best_weights_relu_postal.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1996, 1)\n"
     ]
    }
   ],
   "source": [
    "# Predict stars\n",
    "pred_reg_stopping = model_reg_relu.predict(x_test_reg)\n",
    "print(\"Shape: {}\".format(pred_reg_stopping.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [4.993835]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.5794392]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 4.5, predicted Stars: [3.8313274]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 2.5, predicted Stars: [2.8150606]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 4.5, predicted Stars: [4.0937324]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.6672797]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 3.0, predicted Stars: [3.667501]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 3.0, predicted Stars: [3.0535188]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 3.5, predicted Stars: [3.469771]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.0, predicted Stars: [4.739553]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_stopping[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5608825087547302\n",
      "R2 score: 0.69\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_postal = np.sqrt(mean_squared_error(y_test_reg,pred_reg_stopping))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_postal))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_stopping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with different optimizers for ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_sgd.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 0.0018 - mean_absolute_error: 0.0320 - val_loss: 0.3161 - val_mean_absolute_error: 0.4370\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31609, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0019 - mean_absolute_error: 0.0322 - val_loss: 0.3112 - val_mean_absolute_error: 0.4337\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31609 to 0.31120, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0018 - mean_absolute_error: 0.0314 - val_loss: 0.3111 - val_mean_absolute_error: 0.4337\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.31120 to 0.31107, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.0018 - mean_absolute_error: 0.0313 - val_loss: 0.3105 - val_mean_absolute_error: 0.4334\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.31107 to 0.31047, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.0017 - mean_absolute_error: 0.0304 - val_loss: 0.3100 - val_mean_absolute_error: 0.4332\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.31047 to 0.31001, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.0017 - mean_absolute_error: 0.0301 - val_loss: 0.3128 - val_mean_absolute_error: 0.4348\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31001\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0017 - mean_absolute_error: 0.0302 - val_loss: 0.3107 - val_mean_absolute_error: 0.4335\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31001\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0016 - mean_absolute_error: 0.0300 - val_loss: 0.3102 - val_mean_absolute_error: 0.4333\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31001\n",
      "Epoch 00008: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 0.0016 - mean_absolute_error: 0.0299 - val_loss: 0.3101 - val_mean_absolute_error: 0.4334\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31001\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0015 - mean_absolute_error: 0.0286 - val_loss: 0.3118 - val_mean_absolute_error: 0.4342\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31001\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.0017 - mean_absolute_error: 0.0304 - val_loss: 0.3103 - val_mean_absolute_error: 0.4333\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31001\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.0016 - mean_absolute_error: 0.0292 - val_loss: 0.3114 - val_mean_absolute_error: 0.4339\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31001\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 0.0015 - mean_absolute_error: 0.0292 - val_loss: 0.3114 - val_mean_absolute_error: 0.4339\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31001\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0016 - mean_absolute_error: 0.0293 - val_loss: 0.3101 - val_mean_absolute_error: 0.4332\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31001\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.0016 - mean_absolute_error: 0.0295 - val_loss: 0.3106 - val_mean_absolute_error: 0.4335\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31001\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.0015 - mean_absolute_error: 0.0286 - val_loss: 0.3104 - val_mean_absolute_error: 0.4333\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31001\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.0015 - mean_absolute_error: 0.0287 - val_loss: 0.3108 - val_mean_absolute_error: 0.4335\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31001\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 0.0015 - mean_absolute_error: 0.0288 - val_loss: 0.3116 - val_mean_absolute_error: 0.4340\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31001\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0015 - mean_absolute_error: 0.0286 - val_loss: 0.3106 - val_mean_absolute_error: 0.4334\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31001\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0014 - mean_absolute_error: 0.0281 - val_loss: 0.3113 - val_mean_absolute_error: 0.4338\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31001\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.0014 - mean_absolute_error: 0.0274 - val_loss: 0.3104 - val_mean_absolute_error: 0.4333\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31001\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.0014 - mean_absolute_error: 0.0280 - val_loss: 0.3105 - val_mean_absolute_error: 0.4334\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31001\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 0.0014 - mean_absolute_error: 0.0275 - val_loss: 0.3100 - val_mean_absolute_error: 0.4333\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31001\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0014 - mean_absolute_error: 0.0277 - val_loss: 0.3103 - val_mean_absolute_error: 0.4332\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31001\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.0014 - mean_absolute_error: 0.0274 - val_loss: 0.3100 - val_mean_absolute_error: 0.4332\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31001\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0014 - mean_absolute_error: 0.0277 - val_loss: 0.3107 - val_mean_absolute_error: 0.4335\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31001\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 0.0014 - mean_absolute_error: 0.0279 - val_loss: 0.3111 - val_mean_absolute_error: 0.4337\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31001\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0013 - mean_absolute_error: 0.0269 - val_loss: 0.3100 - val_mean_absolute_error: 0.4332\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31001\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.0014 - mean_absolute_error: 0.0274 - val_loss: 0.3128 - val_mean_absolute_error: 0.4348\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31001\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.0013 - mean_absolute_error: 0.0265 - val_loss: 0.3120 - val_mean_absolute_error: 0.4342\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31001\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.0013 - mean_absolute_error: 0.0270 - val_loss: 0.3109 - val_mean_absolute_error: 0.4336\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31001\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 0.0013 - mean_absolute_error: 0.0271 - val_loss: 0.3106 - val_mean_absolute_error: 0.4334\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31001\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0013 - mean_absolute_error: 0.0269 - val_loss: 0.3103 - val_mean_absolute_error: 0.4333\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31001\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.0013 - mean_absolute_error: 0.0268 - val_loss: 0.3106 - val_mean_absolute_error: 0.4334\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31001\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.0013 - mean_absolute_error: 0.0270 - val_loss: 0.3104 - val_mean_absolute_error: 0.4333\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31001\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0013 - mean_absolute_error: 0.0273 - val_loss: 0.3114 - val_mean_absolute_error: 0.4339\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31001\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0013 - mean_absolute_error: 0.0266 - val_loss: 0.3099 - val_mean_absolute_error: 0.4333\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31001 to 0.30994, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.0013 - mean_absolute_error: 0.0264 - val_loss: 0.3108 - val_mean_absolute_error: 0.4335\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30994\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.0013 - mean_absolute_error: 0.0266 - val_loss: 0.3102 - val_mean_absolute_error: 0.4332\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30994\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.0013 - mean_absolute_error: 0.0270 - val_loss: 0.3102 - val_mean_absolute_error: 0.4332\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30994\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 0.0012 - mean_absolute_error: 0.0256 - val_loss: 0.3103 - val_mean_absolute_error: 0.4332\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30994\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0013 - mean_absolute_error: 0.0265 - val_loss: 0.3104 - val_mean_absolute_error: 0.4333\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30994\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.0012 - mean_absolute_error: 0.0260 - val_loss: 0.3106 - val_mean_absolute_error: 0.4334\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30994\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 4s - loss: 0.0012 - mean_absolute_error: 0.0258 - val_loss: 0.3111 - val_mean_absolute_error: 0.4336\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30994\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0013 - mean_absolute_error: 0.0266 - val_loss: 0.3099 - val_mean_absolute_error: 0.4332\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30994 to 0.30989, saving model to ./best_weights_relu_sgd.hdf5\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0012 - mean_absolute_error: 0.0256 - val_loss: 0.3106 - val_mean_absolute_error: 0.4334\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30989\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.0012 - mean_absolute_error: 0.0257 - val_loss: 0.3109 - val_mean_absolute_error: 0.4335\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30989\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.0012 - mean_absolute_error: 0.0259 - val_loss: 0.3105 - val_mean_absolute_error: 0.4333\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30989\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Model training with Stochastic gradient descent optimizer(SGD).\n",
    "for i in range(10):\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "\n",
    "model_reg_relu.load_weights('./best_weights_relu_sgd.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_sgd = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [4.9187746]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.6321445]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 4.5, predicted Stars: [4.071268]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 2.5, predicted Stars: [2.6122594]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 4.5, predicted Stars: [3.9623418]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.6999474]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 3.0, predicted Stars: [3.9084706]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 3.0, predicted Stars: [2.7844324]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 3.5, predicted Stars: [3.488697]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.0, predicted Stars: [4.9579816]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_sgd[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5566757917404175\n",
      "R2 score: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_sgd = np.sqrt(mean_squared_error(y_test_reg,pred_reg_sgd))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_sgd))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_rmsprop.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0035 - mean_absolute_error: 0.0445 - val_loss: 0.3135 - val_mean_absolute_error: 0.4350\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31351, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0030 - mean_absolute_error: 0.0431 - val_loss: 0.3188 - val_mean_absolute_error: 0.4389\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31351\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0030 - mean_absolute_error: 0.0431 - val_loss: 0.3119 - val_mean_absolute_error: 0.4352\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.31351 to 0.31194, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0029 - mean_absolute_error: 0.0423 - val_loss: 0.3115 - val_mean_absolute_error: 0.4344\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.31194 to 0.31149, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0029 - mean_absolute_error: 0.0422 - val_loss: 0.3169 - val_mean_absolute_error: 0.4371\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31149\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0029 - mean_absolute_error: 0.0424 - val_loss: 0.3135 - val_mean_absolute_error: 0.4364\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31149\n",
      "Epoch 00006: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 0.0030 - mean_absolute_error: 0.0426 - val_loss: 0.3110 - val_mean_absolute_error: 0.4338\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31149 to 0.31097, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0028 - mean_absolute_error: 0.0419 - val_loss: 0.3171 - val_mean_absolute_error: 0.4379\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31097\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0028 - mean_absolute_error: 0.0410 - val_loss: 0.3156 - val_mean_absolute_error: 0.4368\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31097\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0029 - mean_absolute_error: 0.0422 - val_loss: 0.3122 - val_mean_absolute_error: 0.4346\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31097\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 0.0029 - mean_absolute_error: 0.0417 - val_loss: 0.3096 - val_mean_absolute_error: 0.4331\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31097 to 0.30965, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0028 - mean_absolute_error: 0.0414 - val_loss: 0.3101 - val_mean_absolute_error: 0.4325\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30965\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0027 - mean_absolute_error: 0.0404 - val_loss: 0.3103 - val_mean_absolute_error: 0.4331\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30965\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0027 - mean_absolute_error: 0.0409 - val_loss: 0.3152 - val_mean_absolute_error: 0.4360\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30965\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 0.0029 - mean_absolute_error: 0.0417 - val_loss: 0.3122 - val_mean_absolute_error: 0.4343\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30965\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0027 - mean_absolute_error: 0.0410 - val_loss: 0.3123 - val_mean_absolute_error: 0.4342\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30965\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0027 - mean_absolute_error: 0.0409 - val_loss: 0.3114 - val_mean_absolute_error: 0.4341\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30965\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0026 - mean_absolute_error: 0.0398 - val_loss: 0.3100 - val_mean_absolute_error: 0.4333\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30965\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0027 - mean_absolute_error: 0.0410 - val_loss: 0.3101 - val_mean_absolute_error: 0.4339\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30965\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0026 - mean_absolute_error: 0.0402 - val_loss: 0.3150 - val_mean_absolute_error: 0.4366\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30965\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0027 - mean_absolute_error: 0.0411 - val_loss: 0.3128 - val_mean_absolute_error: 0.4348\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.30965\n",
      "Epoch 00007: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0028 - mean_absolute_error: 0.0408 - val_loss: 0.3113 - val_mean_absolute_error: 0.4351\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30965\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0026 - mean_absolute_error: 0.0402 - val_loss: 0.3147 - val_mean_absolute_error: 0.4363\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30965\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0026 - mean_absolute_error: 0.0405 - val_loss: 0.3134 - val_mean_absolute_error: 0.4351\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30965\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0026 - mean_absolute_error: 0.0400 - val_loss: 0.3183 - val_mean_absolute_error: 0.4385\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30965\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0027 - mean_absolute_error: 0.0401 - val_loss: 0.3117 - val_mean_absolute_error: 0.4342\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30965\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0025 - mean_absolute_error: 0.0389 - val_loss: 0.3100 - val_mean_absolute_error: 0.4333\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30965\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0025 - mean_absolute_error: 0.0395 - val_loss: 0.3110 - val_mean_absolute_error: 0.4334\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30965\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0025 - mean_absolute_error: 0.0389 - val_loss: 0.3120 - val_mean_absolute_error: 0.4357\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30965\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0025 - mean_absolute_error: 0.0386 - val_loss: 0.3134 - val_mean_absolute_error: 0.4356\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30965\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 0.0026 - mean_absolute_error: 0.0396 - val_loss: 0.3115 - val_mean_absolute_error: 0.4340\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30965\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0025 - mean_absolute_error: 0.0396 - val_loss: 0.3121 - val_mean_absolute_error: 0.4360\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30965\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0025 - mean_absolute_error: 0.0389 - val_loss: 0.3102 - val_mean_absolute_error: 0.4326\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30965\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0024 - mean_absolute_error: 0.0385 - val_loss: 0.3191 - val_mean_absolute_error: 0.4396\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30965\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0024 - mean_absolute_error: 0.0387 - val_loss: 0.3158 - val_mean_absolute_error: 0.4376\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30965\n",
      "Epoch 6/100\n",
      " - 4s - loss: 0.0024 - mean_absolute_error: 0.0386 - val_loss: 0.3102 - val_mean_absolute_error: 0.4339\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30965\n",
      "Epoch 00006: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0026 - mean_absolute_error: 0.0393 - val_loss: 0.3100 - val_mean_absolute_error: 0.4340\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30965\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0024 - mean_absolute_error: 0.0381 - val_loss: 0.3100 - val_mean_absolute_error: 0.4336\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30965\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0024 - mean_absolute_error: 0.0380 - val_loss: 0.3104 - val_mean_absolute_error: 0.4334\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30965\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0024 - mean_absolute_error: 0.0383 - val_loss: 0.3089 - val_mean_absolute_error: 0.4325\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.30965 to 0.30891, saving model to ./best_weights_relu_rmsprop.hdf5\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0023 - mean_absolute_error: 0.0380 - val_loss: 0.3097 - val_mean_absolute_error: 0.4327\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30891\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0024 - mean_absolute_error: 0.0383 - val_loss: 0.3096 - val_mean_absolute_error: 0.4333\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30891\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0024 - mean_absolute_error: 0.0378 - val_loss: 0.3145 - val_mean_absolute_error: 0.4355\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.30891\n",
      "Epoch 00007: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 12s - loss: 0.0025 - mean_absolute_error: 0.0387 - val_loss: 0.3144 - val_mean_absolute_error: 0.4361\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30891\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0023 - mean_absolute_error: 0.0382 - val_loss: 0.3130 - val_mean_absolute_error: 0.4368\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30891\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.0024 - mean_absolute_error: 0.0384 - val_loss: 0.3109 - val_mean_absolute_error: 0.4339\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30891\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0022 - mean_absolute_error: 0.0371 - val_loss: 0.3104 - val_mean_absolute_error: 0.4341\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30891\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0023 - mean_absolute_error: 0.0382 - val_loss: 0.3124 - val_mean_absolute_error: 0.4362\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30891\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0023 - mean_absolute_error: 0.0371 - val_loss: 0.3107 - val_mean_absolute_error: 0.4340\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30891\n",
      "Epoch 00006: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0024 - mean_absolute_error: 0.0372 - val_loss: 0.3126 - val_mean_absolute_error: 0.4351\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30891\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0023 - mean_absolute_error: 0.0379 - val_loss: 0.3103 - val_mean_absolute_error: 0.4352\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30891\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0022 - mean_absolute_error: 0.0369 - val_loss: 0.3105 - val_mean_absolute_error: 0.4338\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30891\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0023 - mean_absolute_error: 0.0372 - val_loss: 0.3161 - val_mean_absolute_error: 0.4367\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30891\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.0022 - mean_absolute_error: 0.0368 - val_loss: 0.3094 - val_mean_absolute_error: 0.4330\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30891\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Model training with RMSProp optimizer.\n",
    "for i in range(10):\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "\n",
    "model_reg_relu.load_weights('./best_weights_relu_rmsprop.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_rmsprop = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [4.9493213]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.58076]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 4.5, predicted Stars: [4.0033565]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 2.5, predicted Stars: [2.6006212]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 4.5, predicted Stars: [3.9112868]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.6256251]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 3.0, predicted Stars: [3.8134456]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 3.0, predicted Stars: [2.7809153]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 3.5, predicted Stars: [3.480331]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.0, predicted Stars: [4.8759866]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_rmsprop[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5557924509048462\n",
      "R2 score: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_rmsprop = np.sqrt(mean_squared_error(y_test_reg,pred_reg_rmsprop))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_rmsprop))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_rmsprop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_adagrad.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0042 - val_loss: 0.3104\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31041, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 2/100\n",
      " - 5s - loss: 8.3106e-04 - val_loss: 0.3103\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31041 to 0.31034, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 3/100\n",
      " - 5s - loss: 2.2155e-04 - val_loss: 0.3114\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31034\n",
      "Epoch 4/100\n",
      " - 5s - loss: 8.7464e-05 - val_loss: 0.3106\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31034\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 0.0027 - val_loss: 0.3105\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31034\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0012 - val_loss: 0.3109\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31034\n",
      "Epoch 3/100\n",
      " - 5s - loss: 3.1699e-04 - val_loss: 0.3108\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31034\n",
      "Epoch 4/100\n",
      " - 5s - loss: 1.1624e-04 - val_loss: 0.3108\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31034\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0028 - val_loss: 0.3111\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31034\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0011 - val_loss: 0.3114\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31034\n",
      "Epoch 3/100\n",
      " - 5s - loss: 2.9873e-04 - val_loss: 0.3103\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.31034 to 0.31032, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 1.2092e-04 - val_loss: 0.3102\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.31032 to 0.31017, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 21s - loss: 0.0031 - val_loss: 0.3098\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31017 to 0.30984, saving model to ./best_weights_relu_adagrad.hdf5\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0011 - val_loss: 0.3103\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30984\n",
      "Epoch 3/100\n",
      " - 5s - loss: 2.7102e-04 - val_loss: 0.3104\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30984\n",
      "Epoch 4/100\n",
      " - 5s - loss: 1.0155e-04 - val_loss: 0.3106\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30984\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0026 - val_loss: 0.3118\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30984\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0011 - val_loss: 0.3130\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30984\n",
      "Epoch 3/100\n",
      " - 5s - loss: 3.2236e-04 - val_loss: 0.3112\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30984\n",
      "Epoch 4/100\n",
      " - 6s - loss: 1.1407e-04 - val_loss: 0.3111\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30984\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0028 - val_loss: 0.3112\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30984\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0011 - val_loss: 0.3104\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30984\n",
      "Epoch 3/100\n",
      " - 5s - loss: 2.8679e-04 - val_loss: 0.3103\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30984\n",
      "Epoch 4/100\n",
      " - 5s - loss: 1.0816e-04 - val_loss: 0.3108\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30984\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 0.0026 - val_loss: 0.3111\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30984\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0011 - val_loss: 0.3116\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30984\n",
      "Epoch 3/100\n",
      " - 5s - loss: 3.0286e-04 - val_loss: 0.3109\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30984\n",
      "Epoch 4/100\n",
      " - 7s - loss: 1.0980e-04 - val_loss: 0.3113\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30984\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 0.0026 - val_loss: 0.3113\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30984\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0011 - val_loss: 0.3113\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30984\n",
      "Epoch 3/100\n",
      " - 4s - loss: 3.1936e-04 - val_loss: 0.3114\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30984\n",
      "Epoch 4/100\n",
      " - 5s - loss: 1.1870e-04 - val_loss: 0.3117\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30984\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 12s - loss: 0.0028 - val_loss: 0.3113\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30984\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0012 - val_loss: 0.3116\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30984\n",
      "Epoch 3/100\n",
      " - 4s - loss: 3.1756e-04 - val_loss: 0.3112\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30984\n",
      "Epoch 4/100\n",
      " - 4s - loss: 1.0771e-04 - val_loss: 0.3112\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30984\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0030 - val_loss: 0.3122\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30984\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0011 - val_loss: 0.3108\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30984\n",
      "Epoch 3/100\n",
      " - 4s - loss: 2.9154e-04 - val_loss: 0.3108\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30984\n",
      "Epoch 4/100\n",
      " - 4s - loss: 1.1073e-04 - val_loss: 0.3113\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30984\n",
      "Epoch 5/100\n",
      " - 5s - loss: 5.4224e-05 - val_loss: 0.3111\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30984\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Model training with Adagrad.\n",
    "for i in range(10):\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adagrad')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "\n",
    "model_reg_relu.load_weights('./best_weights_relu_adagrad.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_adagrad = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [5.0349708]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.6384451]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 4.5, predicted Stars: [4.023394]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 2.5, predicted Stars: [2.6242118]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 4.5, predicted Stars: [3.9797232]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.7541223]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 3.0, predicted Stars: [3.8522465]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 3.0, predicted Stars: [2.8507853]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 3.5, predicted Stars: [3.4768906]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.0, predicted Stars: [4.9576845]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_adagrad[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.556630551815033\n",
      "R2 score: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_adagrad = np.sqrt(mean_squared_error(y_test_reg,pred_reg_adagrad))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_adagrad))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_adagrad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_adadelta.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0031 - val_loss: 0.3109\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31085, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0033 - val_loss: 0.3095\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31085 to 0.30953, saving model to ./best_weights_relu_adadelta.hdf5\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0025 - val_loss: 0.3096\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30953\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0034 - val_loss: 0.3131\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30953\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0029 - val_loss: 0.3097\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30953\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0032 - val_loss: 0.3098\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30953\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0021 - val_loss: 0.3102\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30953\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0027 - val_loss: 0.3101\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30953\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0025 - val_loss: 0.3110\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30953\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0019 - val_loss: 0.3100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30953\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0027 - val_loss: 0.3123\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30953\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0020 - val_loss: 0.3108\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30953\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0021 - val_loss: 0.3128\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30953\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0025 - val_loss: 0.3113\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30953\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0020 - val_loss: 0.3108\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30953\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0020 - val_loss: 0.3106\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30953\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0028 - val_loss: 0.3110\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30953\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0019 - val_loss: 0.3221\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30953\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0028 - val_loss: 0.3114\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30953\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0021 - val_loss: 0.3113\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30953\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0026 - val_loss: 0.3176\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30953\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0031 - val_loss: 0.3160\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30953\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0016 - val_loss: 0.3120\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30953\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0022 - val_loss: 0.3113\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30953\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0030 - val_loss: 0.3117\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30953\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0023 - val_loss: 0.3101\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30953\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0027 - val_loss: 0.3104\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30953\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.0025 - val_loss: 0.3132\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30953\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0021 - val_loss: 0.3110\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.30953\n",
      "Epoch 00007: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0023 - val_loss: 0.3105\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30953\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0018 - val_loss: 0.3166\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30953\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0017 - val_loss: 0.3117\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30953\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0022 - val_loss: 0.3114\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30953\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0014 - val_loss: 0.3224\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30953\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0014 - val_loss: 0.3211\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30953\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0016 - val_loss: 0.3107\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30953\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0017 - val_loss: 0.3106\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30953\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0018 - val_loss: 0.3123\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30953\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0017 - val_loss: 0.3107\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30953\n",
      "Epoch 00006: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0016 - val_loss: 0.3154\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30953\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0022 - val_loss: 0.3118\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30953\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0015 - val_loss: 0.3120\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30953\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0019 - val_loss: 0.3131\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30953\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0022 - val_loss: 0.3100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30953\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.0022 - val_loss: 0.3121\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30953\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0022 - val_loss: 0.3131\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.30953\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.0012 - val_loss: 0.3146\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.30953\n",
      "Epoch 00008: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 0.0021 - val_loss: 0.3111\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30953\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0017 - val_loss: 0.3127\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30953\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0015 - val_loss: 0.3109\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30953\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0021 - val_loss: 0.3100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30953\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0022 - val_loss: 0.3119\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30953\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.0020 - val_loss: 0.3102\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30953\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0017 - val_loss: 0.3122\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.30953\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Model training with ADadelta.\n",
    "for i in range(10):\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adadelta')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "\n",
    "model_reg_relu.load_weights('./best_weights_relu_adadelta.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_adadelta = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [5.014692]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.629376]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 4.5, predicted Stars: [4.0018387]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 2.5, predicted Stars: [2.617671]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 4.5, predicted Stars: [3.9684253]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.7200139]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 3.0, predicted Stars: [3.8755937]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 3.0, predicted Stars: [2.8827367]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 3.5, predicted Stars: [3.450332]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.0, predicted Stars: [4.9467916]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_adadelta[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.556352972984314\n",
      "R2 score: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_adadelta = np.sqrt(mean_squared_error(y_test_reg,pred_reg_adadelta))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_adadelta))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_adadelta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_adamax.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 9.0234e-04 - val_loss: 0.3114\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31136, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 2/100\n",
      " - 5s - loss: 3.5951e-04 - val_loss: 0.3108\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31136 to 0.31083, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 3/100\n",
      " - 5s - loss: 1.8484e-04 - val_loss: 0.3105\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.31083 to 0.31051, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 1.0698e-04 - val_loss: 0.3105\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31051\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 3.2482e-04 - val_loss: 0.3108\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31051\n",
      "Epoch 2/100\n",
      " - 6s - loss: 1.1103e-04 - val_loss: 0.3107\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31051\n",
      "Epoch 3/100\n",
      " - 5s - loss: 5.4349e-05 - val_loss: 0.3105\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31051\n",
      "Epoch 4/100\n",
      " - 5s - loss: 4.4422e-05 - val_loss: 0.3105\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.31051 to 0.31046, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 1.4769e-04 - val_loss: 0.3112\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31046\n",
      "Epoch 2/100\n",
      " - 5s - loss: 1.1260e-04 - val_loss: 0.3109\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31046\n",
      "Epoch 3/100\n",
      " - 5s - loss: 7.3506e-05 - val_loss: 0.3108\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31046\n",
      "Epoch 4/100\n",
      " - 5s - loss: 6.5273e-05 - val_loss: 0.3106\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31046\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 2.9415e-04 - val_loss: 0.3107\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31046\n",
      "Epoch 2/100\n",
      " - 5s - loss: 9.0988e-05 - val_loss: 0.3101\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31046 to 0.31013, saving model to ./best_weights_relu_adamax.hdf5\n",
      "Epoch 3/100\n",
      " - 5s - loss: 4.0504e-05 - val_loss: 0.3107\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31013\n",
      "Epoch 4/100\n",
      " - 5s - loss: 3.2163e-05 - val_loss: 0.3105\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31013\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 3.1477e-04 - val_loss: 0.3111\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31013\n",
      "Epoch 2/100\n",
      " - 5s - loss: 8.3588e-05 - val_loss: 0.3110\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31013\n",
      "Epoch 3/100\n",
      " - 5s - loss: 3.7583e-05 - val_loss: 0.3110\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31013\n",
      "Epoch 4/100\n",
      " - 5s - loss: 3.1128e-05 - val_loss: 0.3106\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31013\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 2.5393e-04 - val_loss: 0.3109\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31013\n",
      "Epoch 2/100\n",
      " - 5s - loss: 1.0217e-04 - val_loss: 0.3109\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31013\n",
      "Epoch 3/100\n",
      " - 5s - loss: 5.1537e-05 - val_loss: 0.3110\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31013\n",
      "Epoch 4/100\n",
      " - 5s - loss: 3.9981e-05 - val_loss: 0.3105\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31013\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 1.5685e-04 - val_loss: 0.3109\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31013\n",
      "Epoch 2/100\n",
      " - 5s - loss: 1.0018e-04 - val_loss: 0.3105\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31013\n",
      "Epoch 3/100\n",
      " - 5s - loss: 5.9779e-05 - val_loss: 0.3110\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31013\n",
      "Epoch 4/100\n",
      " - 5s - loss: 5.7202e-05 - val_loss: 0.3103\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31013\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 3.6967e-04 - val_loss: 0.3109\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31013\n",
      "Epoch 2/100\n",
      " - 5s - loss: 8.4501e-05 - val_loss: 0.3105\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31013\n",
      "Epoch 3/100\n",
      " - 5s - loss: 3.8719e-05 - val_loss: 0.3106\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31013\n",
      "Epoch 4/100\n",
      " - 5s - loss: 2.9021e-05 - val_loss: 0.3106\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31013\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 3.3334e-04 - val_loss: 0.3110\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31013\n",
      "Epoch 2/100\n",
      " - 5s - loss: 8.0910e-05 - val_loss: 0.3102\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31013\n",
      "Epoch 3/100\n",
      " - 5s - loss: 3.9585e-05 - val_loss: 0.3106\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31013\n",
      "Epoch 4/100\n",
      " - 5s - loss: 3.1882e-05 - val_loss: 0.3106\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31013\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 3.4131e-04 - val_loss: 0.3104\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31013\n",
      "Epoch 2/100\n",
      " - 5s - loss: 8.5879e-05 - val_loss: 0.3104\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31013\n",
      "Epoch 3/100\n",
      " - 5s - loss: 3.7806e-05 - val_loss: 0.3104\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31013\n",
      "Epoch 4/100\n",
      " - 5s - loss: 3.0072e-05 - val_loss: 0.3102\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31013\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Model training with Stochastic gradient descent optimizer(SGD).\n",
    "for i in range(10):\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adamax')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "\n",
    "model_reg_relu.load_weights('./best_weights_relu_adamax.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_adamax = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [5.0025473]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.614849]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 4.5, predicted Stars: [4.0129156]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 2.5, predicted Stars: [2.6334472]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 4.5, predicted Stars: [3.9461608]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.7136426]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 3.0, predicted Stars: [3.8818626]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 3.0, predicted Stars: [2.888313]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 3.5, predicted Stars: [3.4684021]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.0, predicted Stars: [4.972292]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_adamax[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5568938851356506\n",
      "R2 score: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_adamax = np.sqrt(mean_squared_error(y_test_reg,pred_reg_adamax))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_adamax))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_adamax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_nadam.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 0.0040 - mean_absolute_error: 0.0468 - val_loss: 0.3084 - val_mean_absolute_error: 0.4325\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.30843, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0107 - mean_absolute_error: 0.0793 - val_loss: 0.3127 - val_mean_absolute_error: 0.4322\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30843\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0088 - mean_absolute_error: 0.0701 - val_loss: 0.3100 - val_mean_absolute_error: 0.4347\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30843\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.0067 - mean_absolute_error: 0.0615 - val_loss: 0.3092 - val_mean_absolute_error: 0.4309\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30843\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 0.0073 - mean_absolute_error: 0.0639 - val_loss: 0.3100 - val_mean_absolute_error: 0.4344\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30843\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0059 - mean_absolute_error: 0.0581 - val_loss: 0.3148 - val_mean_absolute_error: 0.4346\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30843\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0066 - mean_absolute_error: 0.0616 - val_loss: 0.3081 - val_mean_absolute_error: 0.4314\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.30843 to 0.30808, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0068 - mean_absolute_error: 0.0624 - val_loss: 0.3053 - val_mean_absolute_error: 0.4281\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.30808 to 0.30532, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0065 - mean_absolute_error: 0.0602 - val_loss: 0.3108 - val_mean_absolute_error: 0.4323\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30532\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.0063 - mean_absolute_error: 0.0591 - val_loss: 0.3064 - val_mean_absolute_error: 0.4296\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30532\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0052 - mean_absolute_error: 0.0531 - val_loss: 0.3087 - val_mean_absolute_error: 0.4312\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.30532\n",
      "Epoch 00007: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 0.0056 - mean_absolute_error: 0.0559 - val_loss: 0.3041 - val_mean_absolute_error: 0.4290\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30532 to 0.30406, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0060 - mean_absolute_error: 0.0587 - val_loss: 0.3064 - val_mean_absolute_error: 0.4296\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30406\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0061 - mean_absolute_error: 0.0592 - val_loss: 0.3085 - val_mean_absolute_error: 0.4302\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30406\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0057 - mean_absolute_error: 0.0566 - val_loss: 0.3061 - val_mean_absolute_error: 0.4278\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30406\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 0.0059 - mean_absolute_error: 0.0581 - val_loss: 0.3087 - val_mean_absolute_error: 0.4319\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30406\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0056 - mean_absolute_error: 0.0568 - val_loss: 0.3034 - val_mean_absolute_error: 0.4270\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.30406 to 0.30338, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0054 - mean_absolute_error: 0.0556 - val_loss: 0.3133 - val_mean_absolute_error: 0.4344\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30338\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0059 - mean_absolute_error: 0.0576 - val_loss: 0.3095 - val_mean_absolute_error: 0.4306\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30338\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0053 - mean_absolute_error: 0.0547 - val_loss: 0.3049 - val_mean_absolute_error: 0.4287\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30338\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 0.0056 - mean_absolute_error: 0.0554 - val_loss: 0.3094 - val_mean_absolute_error: 0.4289\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30338\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0049 - mean_absolute_error: 0.0530 - val_loss: 0.3062 - val_mean_absolute_error: 0.4296\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30338\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0053 - mean_absolute_error: 0.0554 - val_loss: 0.3042 - val_mean_absolute_error: 0.4275\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30338\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0054 - mean_absolute_error: 0.0550 - val_loss: 0.3092 - val_mean_absolute_error: 0.4292\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30338\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0048 - mean_absolute_error: 0.0519 - val_loss: 0.3082 - val_mean_absolute_error: 0.4300\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30338\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0046 - mean_absolute_error: 0.0507 - val_loss: 0.3035 - val_mean_absolute_error: 0.4274\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30338\n",
      "Epoch 00006: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 0.0048 - mean_absolute_error: 0.0521 - val_loss: 0.3058 - val_mean_absolute_error: 0.4277\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30338\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0047 - mean_absolute_error: 0.0516 - val_loss: 0.3068 - val_mean_absolute_error: 0.4287\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30338\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0050 - mean_absolute_error: 0.0531 - val_loss: 0.3041 - val_mean_absolute_error: 0.4299\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30338\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0048 - mean_absolute_error: 0.0522 - val_loss: 0.3065 - val_mean_absolute_error: 0.4295\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30338\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0045 - mean_absolute_error: 0.0502 - val_loss: 0.3057 - val_mean_absolute_error: 0.4280\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30338\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.0044 - mean_absolute_error: 0.0493 - val_loss: 0.3050 - val_mean_absolute_error: 0.4285\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30338\n",
      "Epoch 00006: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 0.0044 - mean_absolute_error: 0.0493 - val_loss: 0.3141 - val_mean_absolute_error: 0.4326\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30338\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0045 - mean_absolute_error: 0.0506 - val_loss: 0.3290 - val_mean_absolute_error: 0.4446\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30338\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0048 - mean_absolute_error: 0.0518 - val_loss: 0.3053 - val_mean_absolute_error: 0.4292\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30338\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0048 - mean_absolute_error: 0.0510 - val_loss: 0.3064 - val_mean_absolute_error: 0.4278\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30338\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0046 - mean_absolute_error: 0.0499 - val_loss: 0.3061 - val_mean_absolute_error: 0.4298\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30338\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.0043 - mean_absolute_error: 0.0481 - val_loss: 0.3033 - val_mean_absolute_error: 0.4274\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.30338 to 0.30330, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0034 - mean_absolute_error: 0.0428 - val_loss: 0.3076 - val_mean_absolute_error: 0.4292\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.30330\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.0031 - mean_absolute_error: 0.0407 - val_loss: 0.3023 - val_mean_absolute_error: 0.4263\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.30330 to 0.30234, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.0029 - mean_absolute_error: 0.0394 - val_loss: 0.3021 - val_mean_absolute_error: 0.4265\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.30234 to 0.30212, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 10/100\n",
      " - 7s - loss: 0.0030 - mean_absolute_error: 0.0406 - val_loss: 0.2994 - val_mean_absolute_error: 0.4247\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.30212 to 0.29938, saving model to ./best_weights_relu_nadam.hdf5\n",
      "Epoch 11/100\n",
      " - 6s - loss: 0.0033 - mean_absolute_error: 0.0425 - val_loss: 0.3032 - val_mean_absolute_error: 0.4261\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.29938\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 6s - loss: 0.0034 - mean_absolute_error: 0.0432 - val_loss: 0.3042 - val_mean_absolute_error: 0.4277\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.29938\n",
      "Epoch 13/100\n",
      " - 6s - loss: 0.0031 - mean_absolute_error: 0.0410 - val_loss: 0.3061 - val_mean_absolute_error: 0.4278\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.29938\n",
      "Epoch 00013: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 0.0038 - mean_absolute_error: 0.0463 - val_loss: 0.3041 - val_mean_absolute_error: 0.4262\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.29938\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0040 - mean_absolute_error: 0.0481 - val_loss: 0.3066 - val_mean_absolute_error: 0.4269\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.29938\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0043 - mean_absolute_error: 0.0493 - val_loss: 0.3023 - val_mean_absolute_error: 0.4261\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.29938\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0042 - mean_absolute_error: 0.0484 - val_loss: 0.3007 - val_mean_absolute_error: 0.4260\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.29938\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0035 - mean_absolute_error: 0.0432 - val_loss: 0.3026 - val_mean_absolute_error: 0.4252\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.29938\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.0033 - mean_absolute_error: 0.0423 - val_loss: 0.3023 - val_mean_absolute_error: 0.4262\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.29938\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0031 - mean_absolute_error: 0.0412 - val_loss: 0.3018 - val_mean_absolute_error: 0.4264\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.29938\n",
      "Epoch 00007: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 0.0036 - mean_absolute_error: 0.0455 - val_loss: 0.3026 - val_mean_absolute_error: 0.4285\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.29938\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0037 - mean_absolute_error: 0.0463 - val_loss: 0.3059 - val_mean_absolute_error: 0.4269\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.29938\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0040 - mean_absolute_error: 0.0470 - val_loss: 0.3061 - val_mean_absolute_error: 0.4281\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.29938\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0036 - mean_absolute_error: 0.0450 - val_loss: 0.3015 - val_mean_absolute_error: 0.4261\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.29938\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0028 - mean_absolute_error: 0.0394 - val_loss: 0.3018 - val_mean_absolute_error: 0.4251\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.29938\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0029 - mean_absolute_error: 0.0402 - val_loss: 0.3079 - val_mean_absolute_error: 0.4292\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.29938\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0038 - mean_absolute_error: 0.0455 - val_loss: 0.3048 - val_mean_absolute_error: 0.4264\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.29938\n",
      "Epoch 00007: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 18s - loss: 0.0040 - mean_absolute_error: 0.0474 - val_loss: 0.3006 - val_mean_absolute_error: 0.4260\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.29938\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0034 - mean_absolute_error: 0.0436 - val_loss: 0.3014 - val_mean_absolute_error: 0.4250\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.29938\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0031 - mean_absolute_error: 0.0419 - val_loss: 0.3063 - val_mean_absolute_error: 0.4308\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.29938\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0032 - mean_absolute_error: 0.0418 - val_loss: 0.3005 - val_mean_absolute_error: 0.4257\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.29938\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Model training with Stochastic gradient descent optimizer(SGD).\n",
    "for i in range(10):\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='nadam')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "\n",
    "model_reg_relu.load_weights('./best_weights_relu_nadam.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_nadam = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [4.909003]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.6149395]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 4.5, predicted Stars: [3.999168]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 2.5, predicted Stars: [2.7483773]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 4.5, predicted Stars: [3.9290817]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.7371616]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 3.0, predicted Stars: [3.9110315]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 3.0, predicted Stars: [2.754163]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 3.5, predicted Stars: [3.287781]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.0, predicted Stars: [5.002371]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_nadam[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5471599102020264\n",
      "R2 score: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_relu_nadam = np.sqrt(mean_squared_error(y_test_reg,pred_reg_nadam))\n",
    "print(\"Final score (RMSE): {}\".format(score_relu_nadam))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_nadam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Experiments with Hidden nodes selection in hidden layer **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_2l.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow model for Regression with sigmoid and forward approach\n",
    "model_reg_relu = Sequential()\n",
    "\n",
    "model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu'))  \n",
    "model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "model_reg_relu.add(Dense(1)) # Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 1.7546 - mean_absolute_error: 0.9536 - val_loss: 0.4214 - val_mean_absolute_error: 0.5134\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42140, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3120 - mean_absolute_error: 0.4340 - val_loss: 0.3650 - val_mean_absolute_error: 0.4751\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.42140 to 0.36504, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.2118 - mean_absolute_error: 0.3532 - val_loss: 0.3479 - val_mean_absolute_error: 0.4601\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36504 to 0.34788, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1716 - mean_absolute_error: 0.3142 - val_loss: 0.3500 - val_mean_absolute_error: 0.4592\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34788\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1422 - mean_absolute_error: 0.2837 - val_loss: 0.3608 - val_mean_absolute_error: 0.4699\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34788\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1219 - mean_absolute_error: 0.2623 - val_loss: 0.3658 - val_mean_absolute_error: 0.4701\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34788\n",
      "Epoch 00006: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 0.1161 - mean_absolute_error: 0.2572 - val_loss: 0.3664 - val_mean_absolute_error: 0.4725\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34788\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0962 - mean_absolute_error: 0.2356 - val_loss: 0.3814 - val_mean_absolute_error: 0.4798\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34788\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0763 - mean_absolute_error: 0.2092 - val_loss: 0.3713 - val_mean_absolute_error: 0.4736\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34788\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0624 - mean_absolute_error: 0.1886 - val_loss: 0.3811 - val_mean_absolute_error: 0.4808\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34788\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 0.0570 - mean_absolute_error: 0.1821 - val_loss: 0.3782 - val_mean_absolute_error: 0.4765\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34788\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0479 - mean_absolute_error: 0.1680 - val_loss: 0.3782 - val_mean_absolute_error: 0.4759\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34788\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0389 - mean_absolute_error: 0.1513 - val_loss: 0.3842 - val_mean_absolute_error: 0.4804\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34788\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0323 - mean_absolute_error: 0.1383 - val_loss: 0.3831 - val_mean_absolute_error: 0.4780\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34788\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 0.0311 - mean_absolute_error: 0.1354 - val_loss: 0.3819 - val_mean_absolute_error: 0.4776\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34788\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0275 - mean_absolute_error: 0.1287 - val_loss: 0.3747 - val_mean_absolute_error: 0.4721\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34788\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0244 - mean_absolute_error: 0.1206 - val_loss: 0.3824 - val_mean_absolute_error: 0.4768\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34788\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0226 - mean_absolute_error: 0.1158 - val_loss: 0.3717 - val_mean_absolute_error: 0.4714\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34788\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0207 - mean_absolute_error: 0.1105 - val_loss: 0.3776 - val_mean_absolute_error: 0.4760\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34788\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0184 - mean_absolute_error: 0.1044 - val_loss: 0.3754 - val_mean_absolute_error: 0.4727\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34788\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0166 - mean_absolute_error: 0.0987 - val_loss: 0.3752 - val_mean_absolute_error: 0.4717\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34788\n",
      "Epoch 00007: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 0.0165 - mean_absolute_error: 0.0989 - val_loss: 0.3745 - val_mean_absolute_error: 0.4739\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34788\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0171 - mean_absolute_error: 0.1016 - val_loss: 0.3695 - val_mean_absolute_error: 0.4699\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34788\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0167 - mean_absolute_error: 0.0997 - val_loss: 0.3635 - val_mean_absolute_error: 0.4676\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34788\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0158 - mean_absolute_error: 0.0967 - val_loss: 0.3676 - val_mean_absolute_error: 0.4697\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34788\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0135 - mean_absolute_error: 0.0890 - val_loss: 0.3612 - val_mean_absolute_error: 0.4641\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34788\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0125 - mean_absolute_error: 0.0846 - val_loss: 0.3639 - val_mean_absolute_error: 0.4666\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34788\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0111 - mean_absolute_error: 0.0799 - val_loss: 0.3621 - val_mean_absolute_error: 0.4664\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34788\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0102 - mean_absolute_error: 0.0776 - val_loss: 0.3716 - val_mean_absolute_error: 0.4713\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34788\n",
      "Epoch 00008: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0111 - mean_absolute_error: 0.0808 - val_loss: 0.3665 - val_mean_absolute_error: 0.4681\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34788\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0121 - mean_absolute_error: 0.0845 - val_loss: 0.3580 - val_mean_absolute_error: 0.4632\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34788\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0129 - mean_absolute_error: 0.0879 - val_loss: 0.3668 - val_mean_absolute_error: 0.4677\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34788\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0124 - mean_absolute_error: 0.0861 - val_loss: 0.3655 - val_mean_absolute_error: 0.4668\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34788\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0104 - mean_absolute_error: 0.0780 - val_loss: 0.3570 - val_mean_absolute_error: 0.4621\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34788\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 13s - loss: 0.0097 - mean_absolute_error: 0.0754 - val_loss: 0.3545 - val_mean_absolute_error: 0.4621\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34788\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0096 - mean_absolute_error: 0.0759 - val_loss: 0.3578 - val_mean_absolute_error: 0.4619\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34788\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0098 - mean_absolute_error: 0.0760 - val_loss: 0.3582 - val_mean_absolute_error: 0.4621\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34788\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0108 - mean_absolute_error: 0.0797 - val_loss: 0.3535 - val_mean_absolute_error: 0.4593\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34788\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 0.0101 - mean_absolute_error: 0.0769 - val_loss: 0.3551 - val_mean_absolute_error: 0.4620\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34788\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0084 - mean_absolute_error: 0.0700 - val_loss: 0.3572 - val_mean_absolute_error: 0.4620\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34788\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0081 - mean_absolute_error: 0.0689 - val_loss: 0.3609 - val_mean_absolute_error: 0.4618\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34788\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0087 - mean_absolute_error: 0.0709 - val_loss: 0.3490 - val_mean_absolute_error: 0.4578\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34788\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0089 - mean_absolute_error: 0.0710 - val_loss: 0.3544 - val_mean_absolute_error: 0.4578\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34788\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0075 - mean_absolute_error: 0.0656 - val_loss: 0.3500 - val_mean_absolute_error: 0.4569\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34788\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0067 - mean_absolute_error: 0.0625 - val_loss: 0.3556 - val_mean_absolute_error: 0.4590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34788\n",
      "Epoch 00007: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 0.0070 - mean_absolute_error: 0.0641 - val_loss: 0.3482 - val_mean_absolute_error: 0.4570\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34788\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0079 - mean_absolute_error: 0.0683 - val_loss: 0.3506 - val_mean_absolute_error: 0.4582\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34788\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0080 - mean_absolute_error: 0.0689 - val_loss: 0.3495 - val_mean_absolute_error: 0.4552\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34788\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0072 - mean_absolute_error: 0.0649 - val_loss: 0.3484 - val_mean_absolute_error: 0.4572\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34788\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 0.0070 - mean_absolute_error: 0.0633 - val_loss: 0.3541 - val_mean_absolute_error: 0.4585\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34788\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0062 - mean_absolute_error: 0.0607 - val_loss: 0.3486 - val_mean_absolute_error: 0.4570\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34788\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0068 - mean_absolute_error: 0.0629 - val_loss: 0.3450 - val_mean_absolute_error: 0.4551\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.34788 to 0.34502, saving model to ./best_weights_relu_2l.hdf5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0068 - mean_absolute_error: 0.0623 - val_loss: 0.3471 - val_mean_absolute_error: 0.4559\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34502\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0068 - mean_absolute_error: 0.0623 - val_loss: 0.3467 - val_mean_absolute_error: 0.4551\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34502\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0066 - mean_absolute_error: 0.0613 - val_loss: 0.3464 - val_mean_absolute_error: 0.4567\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34502\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "\n",
    "model_reg_relu.load_weights('./best_weights_relu_2l.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_hl = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [5.2980175]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.3337855]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 4.5, predicted Stars: [3.955951]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 2.5, predicted Stars: [2.738479]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 4.5, predicted Stars: [4.1582956]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.6227615]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 3.0, predicted Stars: [3.6236231]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 3.0, predicted Stars: [2.9315176]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 3.5, predicted Stars: [3.6149912]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.0, predicted Stars: [4.893476]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_hl[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5873870253562927\n",
      "R2 score: 0.66\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_2l = np.sqrt(mean_squared_error(y_test_reg,pred_reg_hl))\n",
    "print(\"Final score (RMSE): {}\".format(score_2l))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_hl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_3l.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow model for Regression with relu and forward approach with 3 hidden layers\n",
    "model_reg_relu = Sequential()\n",
    "\n",
    "model_reg_relu.add(Dense(60, input_dim=x_train_reg.shape[1], activation='relu'))  \n",
    "model_reg_relu.add(Dense(30, activation='relu')) # Hidden 2\n",
    "model_reg_relu.add(Dense(10, activation='relu')) # Hidden 3\n",
    "model_reg_relu.add(Dense(1)) # Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 2.0383 - mean_absolute_error: 1.0240 - val_loss: 0.4214 - val_mean_absolute_error: 0.5161\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42140, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.3085 - mean_absolute_error: 0.4299 - val_loss: 0.3570 - val_mean_absolute_error: 0.4703\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.42140 to 0.35701, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.2127 - mean_absolute_error: 0.3539 - val_loss: 0.3450 - val_mean_absolute_error: 0.4583\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.35701 to 0.34503, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.1721 - mean_absolute_error: 0.3152 - val_loss: 0.3581 - val_mean_absolute_error: 0.4639\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34503\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.1401 - mean_absolute_error: 0.2845 - val_loss: 0.3612 - val_mean_absolute_error: 0.4692\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34503\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.1164 - mean_absolute_error: 0.2553 - val_loss: 0.3535 - val_mean_absolute_error: 0.4652\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34503\n",
      "Epoch 00006: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 0.1055 - mean_absolute_error: 0.2447 - val_loss: 0.3758 - val_mean_absolute_error: 0.4809\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34503\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0816 - mean_absolute_error: 0.2197 - val_loss: 0.3644 - val_mean_absolute_error: 0.4724\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34503\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0637 - mean_absolute_error: 0.1929 - val_loss: 0.3753 - val_mean_absolute_error: 0.4799\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34503\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0498 - mean_absolute_error: 0.1711 - val_loss: 0.3715 - val_mean_absolute_error: 0.4770\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34503\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0403 - mean_absolute_error: 0.1549 - val_loss: 0.3743 - val_mean_absolute_error: 0.4765\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34503\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 0.0372 - mean_absolute_error: 0.1490 - val_loss: 0.3700 - val_mean_absolute_error: 0.4735\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34503\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0333 - mean_absolute_error: 0.1415 - val_loss: 0.3639 - val_mean_absolute_error: 0.4685\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34503\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0275 - mean_absolute_error: 0.1277 - val_loss: 0.3629 - val_mean_absolute_error: 0.4706\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34503\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0235 - mean_absolute_error: 0.1174 - val_loss: 0.3626 - val_mean_absolute_error: 0.4691\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34503\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0207 - mean_absolute_error: 0.1102 - val_loss: 0.3683 - val_mean_absolute_error: 0.4724\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34503\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0194 - mean_absolute_error: 0.1073 - val_loss: 0.3553 - val_mean_absolute_error: 0.4635\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34503\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0201 - mean_absolute_error: 0.1086 - val_loss: 0.3564 - val_mean_absolute_error: 0.4653\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34503\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0179 - mean_absolute_error: 0.1030 - val_loss: 0.3515 - val_mean_absolute_error: 0.4614\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34503\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.0151 - mean_absolute_error: 0.0938 - val_loss: 0.3519 - val_mean_absolute_error: 0.4619\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34503\n",
      "Epoch 10/100\n",
      " - 5s - loss: 0.0123 - mean_absolute_error: 0.0849 - val_loss: 0.3558 - val_mean_absolute_error: 0.4634\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34503\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.0109 - mean_absolute_error: 0.0802 - val_loss: 0.3470 - val_mean_absolute_error: 0.4578\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.34503\n",
      "Epoch 12/100\n",
      " - 5s - loss: 0.0111 - mean_absolute_error: 0.0805 - val_loss: 0.3435 - val_mean_absolute_error: 0.4561\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.34503 to 0.34349, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 13/100\n",
      " - 5s - loss: 0.0114 - mean_absolute_error: 0.0805 - val_loss: 0.3474 - val_mean_absolute_error: 0.4586\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.34349\n",
      "Epoch 14/100\n",
      " - 5s - loss: 0.0115 - mean_absolute_error: 0.0812 - val_loss: 0.3466 - val_mean_absolute_error: 0.4588\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.34349\n",
      "Epoch 15/100\n",
      " - 5s - loss: 0.0119 - mean_absolute_error: 0.0832 - val_loss: 0.3452 - val_mean_absolute_error: 0.4580\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.34349\n",
      "Epoch 00015: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 0.0123 - mean_absolute_error: 0.0849 - val_loss: 0.3450 - val_mean_absolute_error: 0.4555\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34349\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0129 - mean_absolute_error: 0.0877 - val_loss: 0.3461 - val_mean_absolute_error: 0.4597\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34349\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0131 - mean_absolute_error: 0.0884 - val_loss: 0.3407 - val_mean_absolute_error: 0.4544\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.34349 to 0.34068, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0123 - mean_absolute_error: 0.0854 - val_loss: 0.3397 - val_mean_absolute_error: 0.4511\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.34068 to 0.33972, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0106 - mean_absolute_error: 0.0782 - val_loss: 0.3382 - val_mean_absolute_error: 0.4506\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.33972 to 0.33825, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0098 - mean_absolute_error: 0.0753 - val_loss: 0.3407 - val_mean_absolute_error: 0.4530\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.33825\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0091 - mean_absolute_error: 0.0724 - val_loss: 0.3371 - val_mean_absolute_error: 0.4514\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.33825 to 0.33709, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0085 - mean_absolute_error: 0.0699 - val_loss: 0.3367 - val_mean_absolute_error: 0.4483\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.33709 to 0.33672, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.0077 - mean_absolute_error: 0.0673 - val_loss: 0.3350 - val_mean_absolute_error: 0.4511\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33672 to 0.33502, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 10/100\n",
      " - 5s - loss: 0.0076 - mean_absolute_error: 0.0667 - val_loss: 0.3357 - val_mean_absolute_error: 0.4499\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.33502\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.0078 - mean_absolute_error: 0.0670 - val_loss: 0.3347 - val_mean_absolute_error: 0.4481\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33502 to 0.33470, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 12/100\n",
      " - 5s - loss: 0.0077 - mean_absolute_error: 0.0662 - val_loss: 0.3367 - val_mean_absolute_error: 0.4501\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.33470\n",
      "Epoch 00012: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 0.0080 - mean_absolute_error: 0.0681 - val_loss: 0.3338 - val_mean_absolute_error: 0.4462\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.33470 to 0.33377, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0087 - mean_absolute_error: 0.0717 - val_loss: 0.3314 - val_mean_absolute_error: 0.4475\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33377 to 0.33141, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0087 - mean_absolute_error: 0.0717 - val_loss: 0.3274 - val_mean_absolute_error: 0.4429\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33141 to 0.32738, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0079 - mean_absolute_error: 0.0676 - val_loss: 0.3322 - val_mean_absolute_error: 0.4476\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32738\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0074 - mean_absolute_error: 0.0651 - val_loss: 0.3308 - val_mean_absolute_error: 0.4457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32738\n",
      "Epoch 6/100\n",
      " - 8s - loss: 0.0068 - mean_absolute_error: 0.0630 - val_loss: 0.3289 - val_mean_absolute_error: 0.4461\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32738\n",
      "Epoch 00006: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 17s - loss: 0.0069 - mean_absolute_error: 0.0627 - val_loss: 0.3268 - val_mean_absolute_error: 0.4441\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32738 to 0.32682, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0065 - mean_absolute_error: 0.0623 - val_loss: 0.3288 - val_mean_absolute_error: 0.4447\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32682\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0074 - mean_absolute_error: 0.0658 - val_loss: 0.3249 - val_mean_absolute_error: 0.4416\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32682 to 0.32490, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0082 - mean_absolute_error: 0.0697 - val_loss: 0.3232 - val_mean_absolute_error: 0.4410\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.32490 to 0.32322, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0076 - mean_absolute_error: 0.0660 - val_loss: 0.3204 - val_mean_absolute_error: 0.4377\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.32322 to 0.32038, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0059 - mean_absolute_error: 0.0576 - val_loss: 0.3271 - val_mean_absolute_error: 0.4438\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32038\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0053 - mean_absolute_error: 0.0552 - val_loss: 0.3225 - val_mean_absolute_error: 0.4402\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32038\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0052 - mean_absolute_error: 0.0548 - val_loss: 0.3244 - val_mean_absolute_error: 0.4408\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32038\n",
      "Epoch 00008: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 0.0054 - mean_absolute_error: 0.0560 - val_loss: 0.3199 - val_mean_absolute_error: 0.4394\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32038 to 0.31991, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0059 - mean_absolute_error: 0.0589 - val_loss: 0.3213 - val_mean_absolute_error: 0.4396\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31991\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0062 - mean_absolute_error: 0.0602 - val_loss: 0.3238 - val_mean_absolute_error: 0.4409\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31991\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0062 - mean_absolute_error: 0.0603 - val_loss: 0.3202 - val_mean_absolute_error: 0.4384\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31991\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 18s - loss: 0.0057 - mean_absolute_error: 0.0571 - val_loss: 0.3243 - val_mean_absolute_error: 0.4410\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31991\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0047 - mean_absolute_error: 0.0527 - val_loss: 0.3189 - val_mean_absolute_error: 0.4377\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31991 to 0.31887, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0056 - mean_absolute_error: 0.0569 - val_loss: 0.3173 - val_mean_absolute_error: 0.4350\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.31887 to 0.31735, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0059 - mean_absolute_error: 0.0584 - val_loss: 0.3199 - val_mean_absolute_error: 0.4369\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31735\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0055 - mean_absolute_error: 0.0564 - val_loss: 0.3207 - val_mean_absolute_error: 0.4397\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31735\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.0047 - mean_absolute_error: 0.0518 - val_loss: 0.3200 - val_mean_absolute_error: 0.4358\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31735\n",
      "Epoch 00006: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 0.0046 - mean_absolute_error: 0.0515 - val_loss: 0.3212 - val_mean_absolute_error: 0.4383\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31735\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.0047 - mean_absolute_error: 0.0526 - val_loss: 0.3191 - val_mean_absolute_error: 0.4369\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31735\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.0049 - mean_absolute_error: 0.0531 - val_loss: 0.3192 - val_mean_absolute_error: 0.4372\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31735\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.0049 - mean_absolute_error: 0.0534 - val_loss: 0.3187 - val_mean_absolute_error: 0.4374\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31735\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.0049 - mean_absolute_error: 0.0534 - val_loss: 0.3173 - val_mean_absolute_error: 0.4360\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.31735 to 0.31726, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0044 - mean_absolute_error: 0.0507 - val_loss: 0.3162 - val_mean_absolute_error: 0.4335\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.31726 to 0.31619, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.0046 - mean_absolute_error: 0.0513 - val_loss: 0.3150 - val_mean_absolute_error: 0.4346\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.31619 to 0.31502, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.0046 - mean_absolute_error: 0.0516 - val_loss: 0.3146 - val_mean_absolute_error: 0.4344\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.31502 to 0.31457, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.0044 - mean_absolute_error: 0.0507 - val_loss: 0.3143 - val_mean_absolute_error: 0.4335\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.31457 to 0.31431, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 10/100\n",
      " - 6s - loss: 0.0038 - mean_absolute_error: 0.0471 - val_loss: 0.3185 - val_mean_absolute_error: 0.4357\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.31431\n",
      "Epoch 00010: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 15s - loss: 0.0037 - mean_absolute_error: 0.0460 - val_loss: 0.3134 - val_mean_absolute_error: 0.4334\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31431 to 0.31337, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0038 - mean_absolute_error: 0.0476 - val_loss: 0.3185 - val_mean_absolute_error: 0.4372\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31337\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0043 - mean_absolute_error: 0.0503 - val_loss: 0.3145 - val_mean_absolute_error: 0.4324\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31337\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0042 - mean_absolute_error: 0.0491 - val_loss: 0.3134 - val_mean_absolute_error: 0.4331\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.31337 to 0.31337, saving model to ./best_weights_relu_3l.hdf5\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "\n",
    "model_reg_relu.load_weights('./best_weights_relu_3l.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_hl_3 = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [5.205835]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.612089]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 4.5, predicted Stars: [4.167994]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 2.5, predicted Stars: [2.5880194]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 4.5, predicted Stars: [4.0089335]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.809264]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 3.0, predicted Stars: [3.5154214]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 3.0, predicted Stars: [3.4075544]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 3.5, predicted Stars: [3.7099614]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.0, predicted Stars: [4.588487]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_hl_3[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5597916841506958\n",
      "R2 score: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_3l = np.sqrt(mean_squared_error(y_test_reg,pred_reg_hl_3))\n",
    "print(\"Final score (RMSE): {}\".format(score_3l))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_hl_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_4l.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow model for Regression with sigmoid and forward approach with 4 hidden layers\n",
    "model_reg_relu = Sequential()\n",
    "\n",
    "model_reg_relu.add(Dense(80, input_dim=x_train_reg.shape[1], activation='relu'))  \n",
    "model_reg_relu.add(Dense(60, activation='relu')) # Hidden 2\n",
    "model_reg_relu.add(Dense(20, activation='relu')) # Hidden 3\n",
    "model_reg_relu.add(Dense(10, activation='relu')) # Hidden 4\n",
    "model_reg_relu.add(Dense(1)) # Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 20s - loss: 1.5814 - mean_absolute_error: 0.8688 - val_loss: 0.3751 - val_mean_absolute_error: 0.4818\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37512, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.2693 - mean_absolute_error: 0.4017 - val_loss: 0.3414 - val_mean_absolute_error: 0.4545\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37512 to 0.34138, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.1912 - mean_absolute_error: 0.3339 - val_loss: 0.3490 - val_mean_absolute_error: 0.4589\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34138\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.1484 - mean_absolute_error: 0.2911 - val_loss: 0.3491 - val_mean_absolute_error: 0.4596\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34138\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.1166 - mean_absolute_error: 0.2600 - val_loss: 0.3547 - val_mean_absolute_error: 0.4658\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34138\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 19s - loss: 0.0987 - mean_absolute_error: 0.2408 - val_loss: 0.3566 - val_mean_absolute_error: 0.4613\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.34138\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0734 - mean_absolute_error: 0.2089 - val_loss: 0.3471 - val_mean_absolute_error: 0.4600\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34138\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0549 - mean_absolute_error: 0.1805 - val_loss: 0.3477 - val_mean_absolute_error: 0.4580\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34138\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0424 - mean_absolute_error: 0.1584 - val_loss: 0.3465 - val_mean_absolute_error: 0.4558\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34138\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0352 - mean_absolute_error: 0.1446 - val_loss: 0.3409 - val_mean_absolute_error: 0.4557\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.34138 to 0.34090, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.0313 - mean_absolute_error: 0.1354 - val_loss: 0.3513 - val_mean_absolute_error: 0.4616\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34090\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0258 - mean_absolute_error: 0.1230 - val_loss: 0.3365 - val_mean_absolute_error: 0.4486\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.34090 to 0.33648, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 8/100\n",
      " - 7s - loss: 0.0211 - mean_absolute_error: 0.1102 - val_loss: 0.3374 - val_mean_absolute_error: 0.4522\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.33648\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.0204 - mean_absolute_error: 0.1086 - val_loss: 0.3344 - val_mean_absolute_error: 0.4505\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.33648 to 0.33440, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 10/100\n",
      " - 6s - loss: 0.0184 - mean_absolute_error: 0.1037 - val_loss: 0.3358 - val_mean_absolute_error: 0.4484\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.33440\n",
      "Epoch 11/100\n",
      " - 6s - loss: 0.0169 - mean_absolute_error: 0.0995 - val_loss: 0.3324 - val_mean_absolute_error: 0.4473\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33440 to 0.33242, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 12/100\n",
      " - 6s - loss: 0.0160 - mean_absolute_error: 0.0968 - val_loss: 0.3369 - val_mean_absolute_error: 0.4505\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.33242\n",
      "Epoch 13/100\n",
      " - 6s - loss: 0.0162 - mean_absolute_error: 0.0969 - val_loss: 0.3332 - val_mean_absolute_error: 0.4473\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.33242\n",
      "Epoch 14/100\n",
      " - 6s - loss: 0.0158 - mean_absolute_error: 0.0960 - val_loss: 0.3291 - val_mean_absolute_error: 0.4473\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.33242 to 0.32908, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 15/100\n",
      " - 6s - loss: 0.0147 - mean_absolute_error: 0.0927 - val_loss: 0.3305 - val_mean_absolute_error: 0.4465\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.32908\n",
      "Epoch 16/100\n",
      " - 6s - loss: 0.0136 - mean_absolute_error: 0.0891 - val_loss: 0.3318 - val_mean_absolute_error: 0.4475\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.32908\n",
      "Epoch 17/100\n",
      " - 6s - loss: 0.0142 - mean_absolute_error: 0.0915 - val_loss: 0.3305 - val_mean_absolute_error: 0.4455\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.32908\n",
      "Epoch 00017: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 17s - loss: 0.0152 - mean_absolute_error: 0.0948 - val_loss: 0.3276 - val_mean_absolute_error: 0.4456\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.32908 to 0.32762, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.0159 - mean_absolute_error: 0.0975 - val_loss: 0.3352 - val_mean_absolute_error: 0.4474\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32762\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0165 - mean_absolute_error: 0.0982 - val_loss: 0.3238 - val_mean_absolute_error: 0.4436\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32762 to 0.32376, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.0148 - mean_absolute_error: 0.0930 - val_loss: 0.3333 - val_mean_absolute_error: 0.4461\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32376\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0129 - mean_absolute_error: 0.0874 - val_loss: 0.3234 - val_mean_absolute_error: 0.4424\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.32376 to 0.32340, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0109 - mean_absolute_error: 0.0800 - val_loss: 0.3230 - val_mean_absolute_error: 0.4408\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.32340 to 0.32303, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 00006: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 21s - loss: 0.0107 - mean_absolute_error: 0.0786 - val_loss: 0.3254 - val_mean_absolute_error: 0.4413\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32303\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.0111 - mean_absolute_error: 0.0815 - val_loss: 0.3242 - val_mean_absolute_error: 0.4436\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32303\n",
      "Epoch 3/100\n",
      " - 8s - loss: 0.0126 - mean_absolute_error: 0.0868 - val_loss: 0.3186 - val_mean_absolute_error: 0.4391\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32303 to 0.31856, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.0124 - mean_absolute_error: 0.0850 - val_loss: 0.3195 - val_mean_absolute_error: 0.4385\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31856\n",
      "Epoch 5/100\n",
      " - 8s - loss: 0.0117 - mean_absolute_error: 0.0825 - val_loss: 0.3168 - val_mean_absolute_error: 0.4363\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.31856 to 0.31681, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0094 - mean_absolute_error: 0.0746 - val_loss: 0.3159 - val_mean_absolute_error: 0.4374\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.31681 to 0.31589, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 7/100\n",
      " - 7s - loss: 0.0079 - mean_absolute_error: 0.0675 - val_loss: 0.3181 - val_mean_absolute_error: 0.4361\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31589\n",
      "Epoch 8/100\n",
      " - 7s - loss: 0.0072 - mean_absolute_error: 0.0645 - val_loss: 0.3188 - val_mean_absolute_error: 0.4372\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.31589\n",
      "Epoch 00008: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 20s - loss: 0.0084 - mean_absolute_error: 0.0693 - val_loss: 0.3100 - val_mean_absolute_error: 0.4324\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31589 to 0.30995, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.0093 - mean_absolute_error: 0.0745 - val_loss: 0.3155 - val_mean_absolute_error: 0.4362\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30995\n",
      "Epoch 3/100\n",
      " - 8s - loss: 0.0092 - mean_absolute_error: 0.0737 - val_loss: 0.3144 - val_mean_absolute_error: 0.4342\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30995\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.0084 - mean_absolute_error: 0.0702 - val_loss: 0.3162 - val_mean_absolute_error: 0.4344\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30995\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 20s - loss: 0.0080 - mean_absolute_error: 0.0685 - val_loss: 0.3115 - val_mean_absolute_error: 0.4327\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30995\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.0081 - mean_absolute_error: 0.0698 - val_loss: 0.3089 - val_mean_absolute_error: 0.4318\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.30995 to 0.30886, saving model to ./best_weights_relu_4l.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      " - 7s - loss: 0.0077 - mean_absolute_error: 0.0675 - val_loss: 0.3108 - val_mean_absolute_error: 0.4313\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30886\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.0066 - mean_absolute_error: 0.0622 - val_loss: 0.3085 - val_mean_absolute_error: 0.4306\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.30886 to 0.30847, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 5/100\n",
      " - 8s - loss: 0.0064 - mean_absolute_error: 0.0612 - val_loss: 0.3091 - val_mean_absolute_error: 0.4306\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30847\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 22s - loss: 0.0067 - mean_absolute_error: 0.0623 - val_loss: 0.3096 - val_mean_absolute_error: 0.4306\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30847\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0063 - mean_absolute_error: 0.0611 - val_loss: 0.3140 - val_mean_absolute_error: 0.4353\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30847\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0073 - mean_absolute_error: 0.0650 - val_loss: 0.3097 - val_mean_absolute_error: 0.4332\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30847\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0065 - mean_absolute_error: 0.0619 - val_loss: 0.3064 - val_mean_absolute_error: 0.4292\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.30847 to 0.30640, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0059 - mean_absolute_error: 0.0582 - val_loss: 0.3065 - val_mean_absolute_error: 0.4293\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30640\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.0054 - mean_absolute_error: 0.0564 - val_loss: 0.3068 - val_mean_absolute_error: 0.4291\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30640\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0048 - mean_absolute_error: 0.0532 - val_loss: 0.3044 - val_mean_absolute_error: 0.4278\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.30640 to 0.30435, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.0047 - mean_absolute_error: 0.0513 - val_loss: 0.3057 - val_mean_absolute_error: 0.4278\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.30435\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.0047 - mean_absolute_error: 0.0518 - val_loss: 0.3039 - val_mean_absolute_error: 0.4284\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.30435 to 0.30394, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 10/100\n",
      " - 6s - loss: 0.0046 - mean_absolute_error: 0.0519 - val_loss: 0.3061 - val_mean_absolute_error: 0.4295\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.30394\n",
      "Epoch 00010: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 0.0051 - mean_absolute_error: 0.0543 - val_loss: 0.3023 - val_mean_absolute_error: 0.4271\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30394 to 0.30226, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0050 - mean_absolute_error: 0.0544 - val_loss: 0.3021 - val_mean_absolute_error: 0.4253\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.30226 to 0.30212, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0057 - mean_absolute_error: 0.0581 - val_loss: 0.3049 - val_mean_absolute_error: 0.4286\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30212\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0058 - mean_absolute_error: 0.0579 - val_loss: 0.3046 - val_mean_absolute_error: 0.4274\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30212\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 18s - loss: 0.0051 - mean_absolute_error: 0.0547 - val_loss: 0.3075 - val_mean_absolute_error: 0.4295\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30212\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0043 - mean_absolute_error: 0.0505 - val_loss: 0.3076 - val_mean_absolute_error: 0.4305\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30212\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.0048 - mean_absolute_error: 0.0526 - val_loss: 0.3055 - val_mean_absolute_error: 0.4273\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30212\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0049 - mean_absolute_error: 0.0534 - val_loss: 0.3042 - val_mean_absolute_error: 0.4277\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30212\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0052 - mean_absolute_error: 0.0549 - val_loss: 0.3037 - val_mean_absolute_error: 0.4271\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30212\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0045 - mean_absolute_error: 0.0510 - val_loss: 0.3064 - val_mean_absolute_error: 0.4278\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30212\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0040 - mean_absolute_error: 0.0474 - val_loss: 0.3049 - val_mean_absolute_error: 0.4275\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.30212\n",
      "Epoch 00007: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 17s - loss: 0.0039 - mean_absolute_error: 0.0472 - val_loss: 0.3049 - val_mean_absolute_error: 0.4262\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.30212\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0043 - mean_absolute_error: 0.0504 - val_loss: 0.3038 - val_mean_absolute_error: 0.4280\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30212\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0049 - mean_absolute_error: 0.0534 - val_loss: 0.3049 - val_mean_absolute_error: 0.4288\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30212\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0044 - mean_absolute_error: 0.0504 - val_loss: 0.3011 - val_mean_absolute_error: 0.4261\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.30212 to 0.30108, saving model to ./best_weights_relu_4l.hdf5\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0037 - mean_absolute_error: 0.0462 - val_loss: 0.3059 - val_mean_absolute_error: 0.4291\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30108\n",
      "Epoch 6/100\n",
      " - 8s - loss: 0.0035 - mean_absolute_error: 0.0445 - val_loss: 0.3050 - val_mean_absolute_error: 0.4266\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30108\n",
      "Epoch 7/100\n",
      " - 9s - loss: 0.0033 - mean_absolute_error: 0.0431 - val_loss: 0.3027 - val_mean_absolute_error: 0.4258\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.30108\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "\n",
    "model_reg_relu.load_weights('./best_weights_relu_4l.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_hl_4 = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [5.336504]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.6343367]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 4.5, predicted Stars: [3.9705586]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 2.5, predicted Stars: [2.8183677]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 4.5, predicted Stars: [4.2699523]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.806445]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 3.0, predicted Stars: [3.8777049]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 3.0, predicted Stars: [3.33152]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 3.5, predicted Stars: [3.7277024]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.0, predicted Stars: [4.5496783]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_hl_4[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5487036108970642\n",
      "R2 score: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_4l = np.sqrt(mean_squared_error(y_test_reg,pred_reg_hl_4))\n",
    "print(\"Final score (RMSE): {}\".format(score_4l))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_hl_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up checkpointer\n",
    "checkpointer_relu = ModelCheckpoint(filepath=\"./best_weights_relu_5l.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow model for Regression with sigmoid and forward approach with 5 hidden layers\n",
    "model_reg_relu = Sequential()\n",
    "\n",
    "model_reg_relu.add(Dense(80, input_dim=x_train_reg.shape[1], activation='relu'))  \n",
    "model_reg_relu.add(Dense(60, activation='relu')) # Hidden 2\n",
    "model_reg_relu.add(Dense(40, activation='relu')) # Hidden 2\n",
    "model_reg_relu.add(Dense(20, activation='relu')) # Hidden 2\n",
    "model_reg_relu.add(Dense(10, activation='relu')) # Hidden 2\n",
    "model_reg_relu.add(Dense(1)) # Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 19s - loss: 1.5056 - mean_absolute_error: 0.8583 - val_loss: 0.4115 - val_mean_absolute_error: 0.5049\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41153, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.2810 - mean_absolute_error: 0.4141 - val_loss: 0.3467 - val_mean_absolute_error: 0.4621\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.41153 to 0.34671, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.1910 - mean_absolute_error: 0.3346 - val_loss: 0.3379 - val_mean_absolute_error: 0.4516\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.34671 to 0.33792, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.1459 - mean_absolute_error: 0.2903 - val_loss: 0.3441 - val_mean_absolute_error: 0.4567\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.33792\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.1144 - mean_absolute_error: 0.2577 - val_loss: 0.3523 - val_mean_absolute_error: 0.4644\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.33792\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0849 - mean_absolute_error: 0.2210 - val_loss: 0.3552 - val_mean_absolute_error: 0.4619\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.33792\n",
      "Epoch 00006: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 21s - loss: 0.0746 - mean_absolute_error: 0.2109 - val_loss: 0.3551 - val_mean_absolute_error: 0.4622\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.33792\n",
      "Epoch 2/100\n",
      " - 8s - loss: 0.0611 - mean_absolute_error: 0.1927 - val_loss: 0.3610 - val_mean_absolute_error: 0.4642\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.33792\n",
      "Epoch 3/100\n",
      " - 8s - loss: 0.0465 - mean_absolute_error: 0.1684 - val_loss: 0.3571 - val_mean_absolute_error: 0.4661\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.33792\n",
      "Epoch 4/100\n",
      " - 8s - loss: 0.0359 - mean_absolute_error: 0.1467 - val_loss: 0.3380 - val_mean_absolute_error: 0.4509\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.33792\n",
      "Epoch 5/100\n",
      " - 8s - loss: 0.0283 - mean_absolute_error: 0.1286 - val_loss: 0.3496 - val_mean_absolute_error: 0.4536\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.33792\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0242 - mean_absolute_error: 0.1194 - val_loss: 0.3401 - val_mean_absolute_error: 0.4509\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.33792\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0224 - mean_absolute_error: 0.1155 - val_loss: 0.3418 - val_mean_absolute_error: 0.4534\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.33792\n",
      "Epoch 00007: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 17s - loss: 0.0244 - mean_absolute_error: 0.1206 - val_loss: 0.3497 - val_mean_absolute_error: 0.4559\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.33792\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.0272 - mean_absolute_error: 0.1270 - val_loss: 0.3477 - val_mean_absolute_error: 0.4584\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.33792\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.0257 - mean_absolute_error: 0.1234 - val_loss: 0.3379 - val_mean_absolute_error: 0.4499\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.33792\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.0211 - mean_absolute_error: 0.1117 - val_loss: 0.3417 - val_mean_absolute_error: 0.4495\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.33792\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0165 - mean_absolute_error: 0.0990 - val_loss: 0.3319 - val_mean_absolute_error: 0.4448\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.33792 to 0.33194, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0137 - mean_absolute_error: 0.0891 - val_loss: 0.3386 - val_mean_absolute_error: 0.4486\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.33194\n",
      "Epoch 7/100\n",
      " - 7s - loss: 0.0147 - mean_absolute_error: 0.0919 - val_loss: 0.3332 - val_mean_absolute_error: 0.4453\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.33194\n",
      "Epoch 8/100\n",
      " - 7s - loss: 0.0151 - mean_absolute_error: 0.0938 - val_loss: 0.3371 - val_mean_absolute_error: 0.4506\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.33194\n",
      "Epoch 00008: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 20s - loss: 0.0155 - mean_absolute_error: 0.0953 - val_loss: 0.3335 - val_mean_absolute_error: 0.4460\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.33194\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.0154 - mean_absolute_error: 0.0957 - val_loss: 0.3251 - val_mean_absolute_error: 0.4385\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33194 to 0.32509, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.0156 - mean_absolute_error: 0.0953 - val_loss: 0.3386 - val_mean_absolute_error: 0.4452\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32509\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0143 - mean_absolute_error: 0.0919 - val_loss: 0.3304 - val_mean_absolute_error: 0.4410\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32509\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0144 - mean_absolute_error: 0.0915 - val_loss: 0.3225 - val_mean_absolute_error: 0.4358\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.32509 to 0.32248, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.0114 - mean_absolute_error: 0.0811 - val_loss: 0.3280 - val_mean_absolute_error: 0.4417\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32248\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0100 - mean_absolute_error: 0.0758 - val_loss: 0.3261 - val_mean_absolute_error: 0.4383\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32248\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.0101 - mean_absolute_error: 0.0756 - val_loss: 0.3227 - val_mean_absolute_error: 0.4366\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32248\n",
      "Epoch 00008: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 17s - loss: 0.0100 - mean_absolute_error: 0.0757 - val_loss: 0.3255 - val_mean_absolute_error: 0.4389\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.32248\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0111 - mean_absolute_error: 0.0812 - val_loss: 0.3233 - val_mean_absolute_error: 0.4388\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32248\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0126 - mean_absolute_error: 0.0860 - val_loss: 0.3207 - val_mean_absolute_error: 0.4345\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32248 to 0.32071, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0109 - mean_absolute_error: 0.0797 - val_loss: 0.3245 - val_mean_absolute_error: 0.4399\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32071\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0089 - mean_absolute_error: 0.0722 - val_loss: 0.3201 - val_mean_absolute_error: 0.4339\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.32071 to 0.32005, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.0086 - mean_absolute_error: 0.0699 - val_loss: 0.3182 - val_mean_absolute_error: 0.4348\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.32005 to 0.31820, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.0076 - mean_absolute_error: 0.0656 - val_loss: 0.3223 - val_mean_absolute_error: 0.4352\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.31820\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.0078 - mean_absolute_error: 0.0663 - val_loss: 0.3177 - val_mean_absolute_error: 0.4356\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.31820 to 0.31773, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.0082 - mean_absolute_error: 0.0684 - val_loss: 0.3169 - val_mean_absolute_error: 0.4339\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.31773 to 0.31692, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 10/100\n",
      " - 7s - loss: 0.0079 - mean_absolute_error: 0.0674 - val_loss: 0.3146 - val_mean_absolute_error: 0.4301\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.31692 to 0.31455, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 11/100\n",
      " - 6s - loss: 0.0072 - mean_absolute_error: 0.0640 - val_loss: 0.3184 - val_mean_absolute_error: 0.4341\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.31455\n",
      "Epoch 12/100\n",
      " - 6s - loss: 0.0067 - mean_absolute_error: 0.0614 - val_loss: 0.3252 - val_mean_absolute_error: 0.4380\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.31455\n",
      "Epoch 13/100\n",
      " - 7s - loss: 0.0068 - mean_absolute_error: 0.0623 - val_loss: 0.3167 - val_mean_absolute_error: 0.4328\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31455\n",
      "Epoch 00013: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 19s - loss: 0.0076 - mean_absolute_error: 0.0656 - val_loss: 0.3179 - val_mean_absolute_error: 0.4336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31455\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.0069 - mean_absolute_error: 0.0636 - val_loss: 0.3161 - val_mean_absolute_error: 0.4329\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31455\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.0076 - mean_absolute_error: 0.0663 - val_loss: 0.3188 - val_mean_absolute_error: 0.4333\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31455\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.0078 - mean_absolute_error: 0.0668 - val_loss: 0.3174 - val_mean_absolute_error: 0.4329\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31455\n",
      "Epoch 5/100\n",
      " - 8s - loss: 0.0073 - mean_absolute_error: 0.0643 - val_loss: 0.3176 - val_mean_absolute_error: 0.4338\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31455\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 18s - loss: 0.0064 - mean_absolute_error: 0.0605 - val_loss: 0.3172 - val_mean_absolute_error: 0.4315\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31455\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.0060 - mean_absolute_error: 0.0588 - val_loss: 0.3176 - val_mean_absolute_error: 0.4320\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31455\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0067 - mean_absolute_error: 0.0623 - val_loss: 0.3173 - val_mean_absolute_error: 0.4325\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31455\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0077 - mean_absolute_error: 0.0662 - val_loss: 0.3181 - val_mean_absolute_error: 0.4364\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31455\n",
      "Epoch 00004: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 18s - loss: 0.0066 - mean_absolute_error: 0.0613 - val_loss: 0.3143 - val_mean_absolute_error: 0.4315\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.31455 to 0.31432, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.0049 - mean_absolute_error: 0.0530 - val_loss: 0.3125 - val_mean_absolute_error: 0.4309\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31432 to 0.31245, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.0059 - mean_absolute_error: 0.0577 - val_loss: 0.3156 - val_mean_absolute_error: 0.4295\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.31245\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.0060 - mean_absolute_error: 0.0585 - val_loss: 0.3129 - val_mean_absolute_error: 0.4301\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.31245\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0061 - mean_absolute_error: 0.0586 - val_loss: 0.3222 - val_mean_absolute_error: 0.4355\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31245\n",
      "Epoch 00005: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 18s - loss: 0.0058 - mean_absolute_error: 0.0569 - val_loss: 0.3144 - val_mean_absolute_error: 0.4308\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.31245\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.0050 - mean_absolute_error: 0.0540 - val_loss: 0.3164 - val_mean_absolute_error: 0.4319\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.31245\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.0058 - mean_absolute_error: 0.0570 - val_loss: 0.3096 - val_mean_absolute_error: 0.4275\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.31245 to 0.30963, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.0059 - mean_absolute_error: 0.0576 - val_loss: 0.3133 - val_mean_absolute_error: 0.4300\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30963\n",
      "Epoch 5/100\n",
      " - 6s - loss: 0.0057 - mean_absolute_error: 0.0560 - val_loss: 0.3124 - val_mean_absolute_error: 0.4292\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30963\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0045 - mean_absolute_error: 0.0501 - val_loss: 0.3104 - val_mean_absolute_error: 0.4268\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30963\n",
      "Epoch 00006: early stopping\n",
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 18s - loss: 0.0044 - mean_absolute_error: 0.0492 - val_loss: 0.3065 - val_mean_absolute_error: 0.4249\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30963 to 0.30653, saving model to ./best_weights_relu_5l.hdf5\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.0043 - mean_absolute_error: 0.0498 - val_loss: 0.3115 - val_mean_absolute_error: 0.4287\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30653\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.0051 - mean_absolute_error: 0.0536 - val_loss: 0.3121 - val_mean_absolute_error: 0.4294\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30653\n",
      "Epoch 4/100\n",
      " - 8s - loss: 0.0055 - mean_absolute_error: 0.0558 - val_loss: 0.3092 - val_mean_absolute_error: 0.4275\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30653\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model_reg_relu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_reg_relu.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor,checkpointer_relu],verbose=2,epochs=100) \n",
    "\n",
    "model_reg_relu.load_weights('./best_weights_relu_5l.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict stars\n",
    "pred_reg_hl_5 = model_reg_relu.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 5.0, predicted Stars: [5.336504]\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 3.5, predicted Stars: [3.6343367]\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 4.5, predicted Stars: [3.9705586]\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 2.5, predicted Stars: [2.8183677]\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 4.5, predicted Stars: [4.2699523]\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 3.5, predicted Stars: [3.806445]\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 3.0, predicted Stars: [3.8777049]\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 3.0, predicted Stars: [3.33152]\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 3.5, predicted Stars: [3.7277024]\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 4.0, predicted Stars: [4.5496783]\n"
     ]
    }
   ],
   "source": [
    "#Display 10 business\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],y_test_reg[i],pred_reg_hl_4[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5536472797393799\n",
      "R2 score: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_5l = np.sqrt(mean_squared_error(y_test_reg,pred_reg_hl_5))\n",
    "print(\"Final score (RMSE): {}\".format(score_5l))\n",
    "print('R2 score: %.2f' % r2_score(y_test_reg, pred_reg_hl_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Model for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train test data for linear regression\n",
    "\n",
    "x_train_lr, x_test_lr, y_train_lr, y_test_lr = train_test_split(x_matrix_minmax, merge_df['encoded_stars'] , test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implementing Nearest Neighbor\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(x_train_lr, y_train_lr) \n",
    "\n",
    "y_pred_knn = knn.predict(x_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business id - EmezZdxbvjydG5FkN6Mecw actual stars label - 2 predicted - 4\n",
      "business id - cmaPrML-0zCJOs8_1VYmaw actual stars label - 7 predicted - 6\n",
      "business id - E6U8zl527AsspbTf5nZCdw actual stars label - 4 predicted - 5\n",
      "business id - zXRf_6Bs1yX9an_QKpzbHQ actual stars label - 2 predicted - 2\n",
      "business id - vllzSssD2HXGlzGUcITxhw actual stars label - 6 predicted - 7\n",
      "business id - AcGRSWCpb7YB95MTsHlGEw actual stars label - 2 predicted - 2\n",
      "business id - zfEcOCrgUKe8xYOdqNVmmA actual stars label - 5 predicted - 7\n",
      "business id - z-q6Wu-L-iDCftYVfoElPw actual stars label - 8 predicted - 7\n",
      "business id - K7c5wAhxd6CqtmBmY47c7g actual stars label - 5 predicted - 7\n",
      "business id - b30HREePgMGPZMPaExTZSA actual stars label - 6 predicted - 8\n"
     ]
    }
   ],
   "source": [
    "# list  the business with the stars and prediction\n",
    "\n",
    "for i in range(0,10):\n",
    "    idx=y_test_lr.index[i]\n",
    "    print(\"business id - %s actual stars label - %d predicted - %d\" \n",
    "          %(merge_df['business_id'][idx], y_test_lr[idx], y_pred_knn[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 1.8179962102383167\n",
      "R2 score: 0.17\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "\n",
    "score_acc_knn = accuracy_score(true_stars, predict_stars)\n",
    "score_f1_knn =\n",
    "score_precision_knn = \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "\n",
    "svm_model.fit(x_train_lr, y_train_lr)\n",
    "\n",
    "y_pred_svm = svm_model.predict(x_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business id - EmezZdxbvjydG5FkN6Mecw actual stars label - 2 predicted - 6\n",
      "business id - cmaPrML-0zCJOs8_1VYmaw actual stars label - 7 predicted - 6\n",
      "business id - E6U8zl527AsspbTf5nZCdw actual stars label - 4 predicted - 6\n",
      "business id - zXRf_6Bs1yX9an_QKpzbHQ actual stars label - 2 predicted - 6\n",
      "business id - vllzSssD2HXGlzGUcITxhw actual stars label - 6 predicted - 6\n",
      "business id - AcGRSWCpb7YB95MTsHlGEw actual stars label - 2 predicted - 6\n",
      "business id - zfEcOCrgUKe8xYOdqNVmmA actual stars label - 5 predicted - 6\n",
      "business id - z-q6Wu-L-iDCftYVfoElPw actual stars label - 8 predicted - 6\n",
      "business id - K7c5wAhxd6CqtmBmY47c7g actual stars label - 5 predicted - 6\n",
      "business id - b30HREePgMGPZMPaExTZSA actual stars label - 6 predicted - 6\n"
     ]
    }
   ],
   "source": [
    "# list  the business with the stars and prediction\n",
    "\n",
    "for i in range(0,10):\n",
    "    idx=y_test_lr.index[i]\n",
    "    print(\"business id - %s actual stars label - %d predicted - %d\" \n",
    "          %(merge_df['business_id'][idx], y_test_lr[idx], y_pred_svm[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 2.14247062073706\n",
      "R2 score: -0.16\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_svm = np.sqrt(mean_squared_error(y_test_lr,y_pred_svm))\n",
    "print(\"Final score (RMSE): {}\".format(score_svm))\n",
    "print('R2 score: %.2f' % r2_score(y_test_lr, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb_model = MultinomialNB()\n",
    "\n",
    "mnb_model.fit(x_train_lr, y_train_lr)\n",
    "\n",
    "y_pred_mnb = mnb_model.predict(x_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business id - EmezZdxbvjydG5FkN6Mecw actual stars label - 2 predicted - 5\n",
      "business id - cmaPrML-0zCJOs8_1VYmaw actual stars label - 7 predicted - 6\n",
      "business id - E6U8zl527AsspbTf5nZCdw actual stars label - 4 predicted - 5\n",
      "business id - zXRf_6Bs1yX9an_QKpzbHQ actual stars label - 2 predicted - 3\n",
      "business id - vllzSssD2HXGlzGUcITxhw actual stars label - 6 predicted - 5\n",
      "business id - AcGRSWCpb7YB95MTsHlGEw actual stars label - 2 predicted - 5\n",
      "business id - zfEcOCrgUKe8xYOdqNVmmA actual stars label - 5 predicted - 8\n",
      "business id - z-q6Wu-L-iDCftYVfoElPw actual stars label - 8 predicted - 8\n",
      "business id - K7c5wAhxd6CqtmBmY47c7g actual stars label - 5 predicted - 5\n",
      "business id - b30HREePgMGPZMPaExTZSA actual stars label - 6 predicted - 7\n"
     ]
    }
   ],
   "source": [
    "# list  the business with the stars and prediction\n",
    "\n",
    "for i in range(0,10):\n",
    "    idx=y_test_lr.index[i]\n",
    "    print(\"business id - %s actual stars label - %d predicted - %d\" \n",
    "          %(merge_df['business_id'][idx], y_test_lr[idx], y_pred_mnb[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 1.8771113696817183\n",
      "R2 score: 0.11\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_mnb = np.sqrt(mean_squared_error(y_test_lr,y_pred_mnb))\n",
    "print(\"Final score (RMSE): {}\".format(score_mnb))\n",
    "print('R2 score: %.2f' % r2_score(y_test_lr, y_pred_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot cooding of postal codes \n",
    "\n",
    "hotcoded_stars_df = pd.get_dummies(merge_df['encoded_stars'], sparse = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_stars_encoded = hotcoded_stars_df.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train test data for linear regression\n",
    "\n",
    "x_train_lr, x_test_lr, y_train_lr, y_test_lr = train_test_split(x_matrix_minmax, y_stars_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 7s - loss: 1.8531\n",
      "Epoch 2/50\n",
      " - 2s - loss: 1.3560\n",
      "Epoch 3/50\n",
      " - 3s - loss: 1.1827\n",
      "Epoch 4/50\n",
      " - 2s - loss: 1.1068\n",
      "Epoch 5/50\n",
      " - 2s - loss: 1.0512\n",
      "Epoch 6/50\n",
      " - 3s - loss: 1.0012\n",
      "Epoch 7/50\n",
      " - 3s - loss: 0.9498\n",
      "Epoch 8/50\n",
      " - 3s - loss: 0.9047\n",
      "Epoch 9/50\n",
      " - 3s - loss: 0.8601\n",
      "Epoch 10/50\n",
      " - 3s - loss: 0.8171\n",
      "Epoch 11/50\n",
      " - 3s - loss: 0.7747\n",
      "Epoch 12/50\n",
      " - 3s - loss: 0.7327\n",
      "Epoch 13/50\n",
      " - 2s - loss: 0.6969\n",
      "Epoch 14/50\n",
      " - 2s - loss: 0.6568\n",
      "Epoch 15/50\n",
      " - 3s - loss: 0.6279\n",
      "Epoch 16/50\n",
      " - 3s - loss: 0.5913\n",
      "Epoch 17/50\n",
      " - 2s - loss: 0.5602\n",
      "Epoch 18/50\n",
      " - 2s - loss: 0.5291\n",
      "Epoch 19/50\n",
      " - 2s - loss: 0.5024\n",
      "Epoch 20/50\n",
      " - 2s - loss: 0.4717\n",
      "Epoch 21/50\n",
      " - 3s - loss: 0.4463\n",
      "Epoch 22/50\n",
      " - 3s - loss: 0.4158\n",
      "Epoch 23/50\n",
      " - 4s - loss: 0.3908\n",
      "Epoch 24/50\n",
      " - 3s - loss: 0.3637\n",
      "Epoch 25/50\n",
      " - 3s - loss: 0.3429\n",
      "Epoch 26/50\n",
      " - 3s - loss: 0.3217\n",
      "Epoch 27/50\n",
      " - 3s - loss: 0.2984\n",
      "Epoch 28/50\n",
      " - 3s - loss: 0.2778\n",
      "Epoch 29/50\n",
      " - 3s - loss: 0.2547\n",
      "Epoch 30/50\n",
      " - 3s - loss: 0.2369\n",
      "Epoch 31/50\n",
      " - 4s - loss: 0.2181\n",
      "Epoch 32/50\n",
      " - 3s - loss: 0.2010\n",
      "Epoch 33/50\n",
      " - 3s - loss: 0.1852\n",
      "Epoch 34/50\n",
      " - 3s - loss: 0.1677\n",
      "Epoch 35/50\n",
      " - 2s - loss: 0.1555\n",
      "Epoch 36/50\n",
      " - 2s - loss: 0.1410\n",
      "Epoch 37/50\n",
      " - 3s - loss: 0.1290\n",
      "Epoch 38/50\n",
      " - 2s - loss: 0.1176\n",
      "Epoch 39/50\n",
      " - 3s - loss: 0.1066\n",
      "Epoch 40/50\n",
      " - 2s - loss: 0.0966\n",
      "Epoch 41/50\n",
      " - 3s - loss: 0.0877\n",
      "Epoch 42/50\n",
      " - 3s - loss: 0.0776\n",
      "Epoch 43/50\n",
      " - 3s - loss: 0.0714\n",
      "Epoch 44/50\n",
      " - 2s - loss: 0.0625\n",
      "Epoch 45/50\n",
      " - 3s - loss: 0.0568\n",
      "Epoch 46/50\n",
      " - 2s - loss: 0.0534\n",
      "Epoch 47/50\n",
      " - 2s - loss: 0.0491\n",
      "Epoch 48/50\n",
      " - 2s - loss: 0.0429\n",
      "Epoch 49/50\n",
      " - 2s - loss: 0.0375\n",
      "Epoch 50/50\n",
      " - 3s - loss: 0.0341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x203d94f1908>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensorflow classification\n",
    "\n",
    "model_class = Sequential()\n",
    "model_class.add(Dense(50, input_dim=x_train_lr.shape[1], activation='relu')) # Hidden 1\n",
    "model_class.add(Dense(25, activation='relu')) # Hidden 2\n",
    "model_class.add(Dense(y_train_lr.shape[1], activation='softmax')) # Output\n",
    "\n",
    "model_class.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model_class.fit(x_train_lr,y_train_lr,verbose=2,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1996, 9)\n",
      "[[4.8480987e-21 8.7688440e-11 3.6708113e-07 ... 4.0000780e-11\n",
      "  2.0035622e-11 1.7034164e-19]\n",
      " [0.0000000e+00 4.3768849e-33 1.0997931e-20 ... 9.6302813e-01\n",
      "  3.6949817e-02 2.2013457e-05]\n",
      " [7.5696492e-22 1.4770561e-10 3.0735318e-05 ... 7.0913511e-06\n",
      "  2.4185019e-06 3.8029577e-14]\n",
      " ...\n",
      " [0.0000000e+00 1.8693442e-18 2.8503936e-14 ... 4.6418074e-09\n",
      "  1.4032820e-11 7.6944250e-20]\n",
      " [8.6572583e-28 7.0216779e-12 2.6254143e-06 ... 1.1362669e-02\n",
      "  5.3011975e-03 1.7852780e-11]\n",
      " [0.0000000e+00 6.6005226e-31 1.1835784e-19 ... 9.8131645e-01\n",
      "  1.8683216e-02 3.7645924e-07]]\n"
     ]
    }
   ],
   "source": [
    "pred_class = model_class.predict(x_test_lr)\n",
    "print(\"Shape: {}\".format(pred_class.shape))\n",
    "print(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_stars = np.argmax(pred_class,axis=1)\n",
    "\n",
    "true_stars = np.argmax(y_test_lr,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 2, predicted Stars: 3\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 7, predicted Stars: 6\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 4, predicted Stars: 4\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 2, predicted Stars: 1\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 6, predicted Stars: 6\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 2, predicted Stars: 3\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 5, predicted Stars: 8\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 8, predicted Stars: 7\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5, predicted Stars: 2\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 6, predicted Stars: 8\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],true_stars[i],predict_stars[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4308617234468938\n"
     ]
    }
   ],
   "source": [
    "#accuracy  \n",
    "\n",
    "correct = accuracy_score(true_stars, predict_stars)\n",
    "print(\"Accuracy: {}\".format(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test data for linear regression\n",
    "\n",
    "x_train_tf, x_test_tf, y_train_tf, y_test_tf = train_test_split(x_matrix_final, y_stars_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 9s - loss: 1.7639\n",
      "Epoch 2/50\n",
      " - 3s - loss: 1.2489\n",
      "Epoch 3/50\n",
      " - 3s - loss: 1.0005\n",
      "Epoch 4/50\n",
      " - 4s - loss: 0.8068\n",
      "Epoch 5/50\n",
      " - 4s - loss: 0.6362\n",
      "Epoch 6/50\n",
      " - 4s - loss: 0.4994\n",
      "Epoch 7/50\n",
      " - 5s - loss: 0.3911\n",
      "Epoch 8/50\n",
      " - 4s - loss: 0.3061\n",
      "Epoch 9/50\n",
      " - 5s - loss: 0.2414\n",
      "Epoch 10/50\n",
      " - 4s - loss: 0.1890\n",
      "Epoch 11/50\n",
      " - 3s - loss: 0.1474\n",
      "Epoch 12/50\n",
      " - 3s - loss: 0.1160\n",
      "Epoch 13/50\n",
      " - 4s - loss: 0.0884\n",
      "Epoch 14/50\n",
      " - 3s - loss: 0.0667\n",
      "Epoch 15/50\n",
      " - 4s - loss: 0.0512\n",
      "Epoch 16/50\n",
      " - 4s - loss: 0.0377\n",
      "Epoch 17/50\n",
      " - 4s - loss: 0.0297\n",
      "Epoch 18/50\n",
      " - 3s - loss: 0.0219\n",
      "Epoch 19/50\n",
      " - 4s - loss: 0.0166\n",
      "Epoch 20/50\n",
      " - 3s - loss: 0.0124\n",
      "Epoch 21/50\n",
      " - 3s - loss: 0.0098\n",
      "Epoch 22/50\n",
      " - 3s - loss: 0.0077\n",
      "Epoch 23/50\n",
      " - 4s - loss: 0.0063\n",
      "Epoch 24/50\n",
      " - 3s - loss: 0.0053\n",
      "Epoch 25/50\n",
      " - 4s - loss: 0.0044\n",
      "Epoch 26/50\n",
      " - 4s - loss: 0.0035\n",
      "Epoch 27/50\n",
      " - 3s - loss: 0.0030\n",
      "Epoch 28/50\n",
      " - 3s - loss: 0.0024\n",
      "Epoch 29/50\n",
      " - 4s - loss: 0.0020\n",
      "Epoch 30/50\n",
      " - 3s - loss: 0.0017\n",
      "Epoch 31/50\n",
      " - 3s - loss: 0.0014\n",
      "Epoch 32/50\n",
      " - 4s - loss: 0.0012\n",
      "Epoch 33/50\n",
      " - 4s - loss: 0.0010\n",
      "Epoch 34/50\n",
      " - 3s - loss: 8.3692e-04\n",
      "Epoch 35/50\n",
      " - 3s - loss: 7.2314e-04\n",
      "Epoch 36/50\n",
      " - 4s - loss: 6.1082e-04\n",
      "Epoch 37/50\n",
      " - 3s - loss: 5.1979e-04\n",
      "Epoch 38/50\n",
      " - 3s - loss: 4.4558e-04\n",
      "Epoch 39/50\n",
      " - 4s - loss: 3.7844e-04\n",
      "Epoch 40/50\n",
      " - 4s - loss: 3.2323e-04\n",
      "Epoch 41/50\n",
      " - 3s - loss: 2.7882e-04\n",
      "Epoch 42/50\n",
      " - 5s - loss: 2.3825e-04\n",
      "Epoch 43/50\n",
      " - 4s - loss: 2.0499e-04\n",
      "Epoch 44/50\n",
      " - 4s - loss: 1.7638e-04\n",
      "Epoch 45/50\n",
      " - 4s - loss: 1.5433e-04\n",
      "Epoch 46/50\n",
      " - 4s - loss: 1.2937e-04\n",
      "Epoch 47/50\n",
      " - 4s - loss: 1.1178e-04\n",
      "Epoch 48/50\n",
      " - 4s - loss: 1.2836e-04\n",
      "Epoch 49/50\n",
      " - 4s - loss: 0.0923\n",
      "Epoch 50/50\n",
      " - 4s - loss: 0.1023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20517897dd8>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensorflow classification\n",
    "\n",
    "model_class = Sequential()\n",
    "model_class.add(Dense(50, input_dim=x_train_tf.shape[1], activation='relu')) # Hidden 1\n",
    "model_class.add(Dense(25, activation='relu')) # Hidden 2\n",
    "model_class.add(Dense(y_train_lr.shape[1], activation='softmax')) # Output\n",
    "\n",
    "model_class.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model_class.fit(x_train_tf,y_train_tf,verbose=2,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1996, 9)\n",
      "[[2.5405296e-12 1.2393942e-07 5.0602633e-10 ... 1.8107455e-22\n",
      "  2.6426383e-32 5.0162187e-34]\n",
      " [0.0000000e+00 1.0104799e-32 1.3840434e-30 ... 8.7040478e-01\n",
      "  1.2959516e-01 4.5909987e-09]\n",
      " [4.0285604e-26 2.4749689e-16 2.5602374e-13 ... 2.4799876e-12\n",
      "  2.1567378e-17 1.5830178e-22]\n",
      " ...\n",
      " [1.1329312e-22 5.1598427e-15 4.2198586e-10 ... 5.1856097e-07\n",
      "  6.5324351e-16 8.3942530e-22]\n",
      " [7.1796776e-26 1.9210520e-17 5.3053065e-25 ... 1.0000000e+00\n",
      "  3.6923738e-17 1.1553852e-19]\n",
      " [0.0000000e+00 1.3095930e-35 1.7397419e-33 ... 8.5242641e-07\n",
      "  9.9914658e-01 8.5237162e-04]]\n"
     ]
    }
   ],
   "source": [
    "pred_class = model_class.predict(x_test_tf)\n",
    "print(\"Shape: {}\".format(pred_class.shape))\n",
    "print(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_stars = np.argmax(pred_class,axis=1)\n",
    "\n",
    "true_stars = np.argmax(y_test_tf,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business ID: diaiQrxYFU1V5qxrFnW9fg, Actual Stars: 2, predicted Stars: 3\n",
      "2. Business ID: TDTASGFy_aGp6vy0i23mDA, Actual Stars: 7, predicted Stars: 6\n",
      "3. Business ID: VuKJ2s_JP8weQ54NfsXJXQ, Actual Stars: 4, predicted Stars: 5\n",
      "4. Business ID: aGiBg2WKOpXS5-1DRnBiAQ, Actual Stars: 2, predicted Stars: 2\n",
      "5. Business ID: ZMmgFw2P4LWsFXNn1ZGc1g, Actual Stars: 6, predicted Stars: 6\n",
      "6. Business ID: sEKFq5u8P_s0-2mAZnx0JQ, Actual Stars: 2, predicted Stars: 2\n",
      "7. Business ID: rYziPPEILDXJ_F5uKR--YQ, Actual Stars: 5, predicted Stars: 6\n",
      "8. Business ID: Swm_uMOWNcJDZz5lXWyzKA, Actual Stars: 8, predicted Stars: 8\n",
      "9. Business ID: 6nGnVP7M4qQRiclXxeqXSQ, Actual Stars: 5, predicted Stars: 3\n",
      "10. Business ID: Tc24GX9-ZPr4_SHU0nJZZA, Actual Stars: 6, predicted Stars: 8\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"{}. Business ID: {}, Actual Stars: {}, predicted Stars: {}\".format(i+1,merge_df['business_id'][2000+i],true_stars[i],predict_stars[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3787575150300601\n"
     ]
    }
   ],
   "source": [
    "#accuracy  \n",
    "\n",
    "correct = accuracy_score(true_stars, predict_stars)\n",
    "print(\"Accuracy: {}\".format(correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "from sklearn import metrics\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test data\n",
    "x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x_matrix_minmax, y_stars_regression , test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USe linear regression for regularization\n",
    "model_regularization = Sequential()\n",
    "model_regularization.add(Dense(50, input_dim=x_train_reg.shape[1], activation='relu'))\n",
    "model_regularization.add(Dense(25, activation='relu'))\n",
    "model_regularization.add(Dense(10, \n",
    "                kernel_regularizer=regularizers.l1(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "model_regularization.add(Dense(1)) \n",
    "model_regularization.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 20s - loss: 4.3367 - val_loss: 2.2657\n",
      "Epoch 2/100\n",
      " - 6s - loss: 1.7097 - val_loss: 1.3561\n",
      "Epoch 3/100\n",
      " - 6s - loss: 1.1760 - val_loss: 1.0891\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.9575 - val_loss: 0.9274\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.8107 - val_loss: 0.8123\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.6907 - val_loss: 0.7237\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.5859 - val_loss: 0.6551\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.4999 - val_loss: 0.6038\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.4322 - val_loss: 0.5663\n",
      "Epoch 10/100\n",
      " - 6s - loss: 0.3755 - val_loss: 0.5377\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.3289 - val_loss: 0.5132\n",
      "Epoch 12/100\n",
      " - 6s - loss: 0.2891 - val_loss: 0.4969\n",
      "Epoch 13/100\n",
      " - 5s - loss: 0.2566 - val_loss: 0.4748\n",
      "Epoch 14/100\n",
      " - 6s - loss: 0.2272 - val_loss: 0.4554\n",
      "Epoch 15/100\n",
      " - 6s - loss: 0.2044 - val_loss: 0.4384\n",
      "Epoch 16/100\n",
      " - 6s - loss: 0.1839 - val_loss: 0.4344\n",
      "Epoch 17/100\n",
      " - 6s - loss: 0.1670 - val_loss: 0.4177\n",
      "Epoch 18/100\n",
      " - 6s - loss: 0.1513 - val_loss: 0.4044\n",
      "Epoch 19/100\n",
      " - 6s - loss: 0.1391 - val_loss: 0.4012\n",
      "Epoch 20/100\n",
      " - 6s - loss: 0.1278 - val_loss: 0.3891\n",
      "Epoch 21/100\n",
      " - 5s - loss: 0.1187 - val_loss: 0.3819\n",
      "Epoch 22/100\n",
      " - 7s - loss: 0.1111 - val_loss: 0.3811\n",
      "Epoch 23/100\n",
      " - 7s - loss: 0.1049 - val_loss: 0.3745\n",
      "Epoch 24/100\n",
      " - 6s - loss: 0.0998 - val_loss: 0.3664\n",
      "Epoch 25/100\n",
      " - 6s - loss: 0.0941 - val_loss: 0.3629\n",
      "Epoch 26/100\n",
      " - 6s - loss: 0.0909 - val_loss: 0.3652\n",
      "Epoch 27/100\n",
      " - 5s - loss: 0.0869 - val_loss: 0.3592\n",
      "Epoch 28/100\n",
      " - 6s - loss: 0.0827 - val_loss: 0.3576\n",
      "Epoch 29/100\n",
      " - 5s - loss: 0.0794 - val_loss: 0.3543\n",
      "Epoch 30/100\n",
      " - 5s - loss: 0.0766 - val_loss: 0.3507\n",
      "Epoch 31/100\n",
      " - 5s - loss: 0.0739 - val_loss: 0.3522\n",
      "Epoch 32/100\n",
      " - 5s - loss: 0.0706 - val_loss: 0.3441\n",
      "Epoch 33/100\n",
      " - 5s - loss: 0.0674 - val_loss: 0.3499\n",
      "Epoch 34/100\n",
      " - 5s - loss: 0.0655 - val_loss: 0.3490\n",
      "Epoch 35/100\n",
      " - 5s - loss: 0.0626 - val_loss: 0.3414\n",
      "Epoch 36/100\n",
      " - 5s - loss: 0.0610 - val_loss: 0.3454\n",
      "Epoch 37/100\n",
      " - 5s - loss: 0.0590 - val_loss: 0.3452\n",
      "Epoch 38/100\n",
      " - 5s - loss: 0.0571 - val_loss: 0.3435\n",
      "Epoch 39/100\n",
      " - 5s - loss: 0.0548 - val_loss: 0.3438\n",
      "Epoch 40/100\n",
      " - 5s - loss: 0.0526 - val_loss: 0.3400\n",
      "Epoch 41/100\n",
      " - 5s - loss: 0.0514 - val_loss: 0.3366\n",
      "Epoch 42/100\n",
      " - 5s - loss: 0.0495 - val_loss: 0.3400\n",
      "Epoch 43/100\n",
      " - 5s - loss: 0.0476 - val_loss: 0.3320\n",
      "Epoch 44/100\n",
      " - 5s - loss: 0.0465 - val_loss: 0.3368\n",
      "Epoch 45/100\n",
      " - 5s - loss: 0.0451 - val_loss: 0.3383\n",
      "Epoch 46/100\n",
      " - 5s - loss: 0.0438 - val_loss: 0.3368\n",
      "Epoch 47/100\n",
      " - 5s - loss: 0.0420 - val_loss: 0.3298\n",
      "Epoch 48/100\n",
      " - 5s - loss: 0.0407 - val_loss: 0.3328\n",
      "Epoch 49/100\n",
      " - 5s - loss: 0.0395 - val_loss: 0.3329\n",
      "Epoch 50/100\n",
      " - 5s - loss: 0.0390 - val_loss: 0.3362\n",
      "Epoch 51/100\n",
      " - 5s - loss: 0.0383 - val_loss: 0.3295\n",
      "Epoch 52/100\n",
      " - 5s - loss: 0.0378 - val_loss: 0.3322\n",
      "Epoch 00052: early stopping\n"
     ]
    }
   ],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "model_regularization.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor],verbose=2,epochs=100)\n",
    "\n",
    "pred_regularization = model_regularization.predict(x_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5542775392532349\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_regularization = np.sqrt(metrics.mean_squared_error(pred_regularization,y_test_reg))\n",
    "print(\"Final score (RMSE): {}\".format(score_regularization))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: early stopping\n",
      "Final score (RMSE): 0.49788129329681396\n"
     ]
    }
   ],
   "source": [
    "# Dropout\n",
    "\n",
    "model_dropout = Sequential()\n",
    "model_dropout.add(Dense(50, input_dim=x_train_reg.shape[1]))\n",
    "model_dropout.add(Dropout(0.1))\n",
    "\n",
    "model_dropout.add(Dense(25, activation='relu'))\n",
    "model_dropout.add(Dense(10, activation='relu'))\n",
    "model_dropout.add(Dense(1))\n",
    "\n",
    "model_dropout.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "model_dropout.fit(x_train_reg,y_train_reg,validation_data=(x_test_reg,y_test_reg),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "\n",
    "pred_dropout = model_dropout.predict(x_test_reg)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_dropout = np.sqrt(metrics.mean_squared_error(pred_dropout,y_test_reg))\n",
    "print(\"Final score (RMSE): {}\".format(score_dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 50)                50100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 51,646\n",
      "Trainable params: 51,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking to see if regularization helps with over fitting when using postal code and categories and one hot coded values\n",
    "#train test data\n",
    "x_train_reg_ad, x_test_reg_ad, y_train_reg_ad, y_test_reg_ad = train_test_split(x_matrix_final, y_stars_regression , test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USe linear regression for regularization\n",
    "model_regularization_ad = Sequential()\n",
    "model_regularization_ad.add(Dense(50, input_dim=x_train_reg_ad.shape[1], activation='relu'))\n",
    "model_regularization_ad.add(Dense(25, activation='relu'))\n",
    "model_regularization_ad.add(Dense(10, \n",
    "                kernel_regularizer=regularizers.l1(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "model_regularization_ad.add(Dense(1)) \n",
    "model_regularization_ad.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7981 samples, validate on 1996 samples\n",
      "Epoch 1/100\n",
      " - 18s - loss: 4.4570 - val_loss: 2.4116\n",
      "Epoch 2/100\n",
      " - 6s - loss: 1.8795 - val_loss: 1.6409\n",
      "Epoch 3/100\n",
      " - 5s - loss: 1.3024 - val_loss: 1.3105\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.9978 - val_loss: 1.0954\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.7967 - val_loss: 0.9675\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.6554 - val_loss: 0.8644\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.5439 - val_loss: 0.7992\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.4576 - val_loss: 0.7301\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.3906 - val_loss: 0.6778\n",
      "Epoch 10/100\n",
      " - 6s - loss: 0.3365 - val_loss: 0.6339\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.2923 - val_loss: 0.6078\n",
      "Epoch 12/100\n",
      " - 6s - loss: 0.2562 - val_loss: 0.5776\n",
      "Epoch 13/100\n",
      " - 6s - loss: 0.2272 - val_loss: 0.5579\n",
      "Epoch 14/100\n",
      " - 6s - loss: 0.2018 - val_loss: 0.5334\n",
      "Epoch 15/100\n",
      " - 5s - loss: 0.1801 - val_loss: 0.5166\n",
      "Epoch 16/100\n",
      " - 6s - loss: 0.1625 - val_loss: 0.5018\n",
      "Epoch 17/100\n",
      " - 5s - loss: 0.1473 - val_loss: 0.4803\n",
      "Epoch 18/100\n",
      " - 6s - loss: 0.1350 - val_loss: 0.4686\n",
      "Epoch 19/100\n",
      " - 5s - loss: 0.1238 - val_loss: 0.4651\n",
      "Epoch 20/100\n",
      " - 6s - loss: 0.1150 - val_loss: 0.4515\n",
      "Epoch 21/100\n",
      " - 5s - loss: 0.1084 - val_loss: 0.4386\n",
      "Epoch 22/100\n",
      " - 6s - loss: 0.1023 - val_loss: 0.4339\n",
      "Epoch 23/100\n",
      " - 5s - loss: 0.0972 - val_loss: 0.4268\n",
      "Epoch 24/100\n",
      " - 6s - loss: 0.0928 - val_loss: 0.4339\n",
      "Epoch 25/100\n",
      " - 5s - loss: 0.0893 - val_loss: 0.4216\n",
      "Epoch 26/100\n",
      " - 6s - loss: 0.0852 - val_loss: 0.4152\n",
      "Epoch 27/100\n",
      " - 7s - loss: 0.0809 - val_loss: 0.4106\n",
      "Epoch 28/100\n",
      " - 6s - loss: 0.0782 - val_loss: 0.4088\n",
      "Epoch 29/100\n",
      " - 8s - loss: 0.0757 - val_loss: 0.4043\n",
      "Epoch 30/100\n",
      " - 5s - loss: 0.0725 - val_loss: 0.4071\n",
      "Epoch 31/100\n",
      " - 5s - loss: 0.0707 - val_loss: 0.4172\n",
      "Epoch 32/100\n",
      " - 6s - loss: 0.0681 - val_loss: 0.3952\n",
      "Epoch 33/100\n",
      " - 5s - loss: 0.0652 - val_loss: 0.4010\n",
      "Epoch 34/100\n",
      " - 5s - loss: 0.0633 - val_loss: 0.3929\n",
      "Epoch 35/100\n",
      " - 6s - loss: 0.0613 - val_loss: 0.3983\n",
      "Epoch 36/100\n",
      " - 5s - loss: 0.0590 - val_loss: 0.3869\n",
      "Epoch 37/100\n",
      " - 5s - loss: 0.0553 - val_loss: 0.3927\n",
      "Epoch 38/100\n",
      " - 5s - loss: 0.0530 - val_loss: 0.3869\n",
      "Epoch 39/100\n",
      " - 7s - loss: 0.0513 - val_loss: 0.3883\n",
      "Epoch 40/100\n",
      " - 9s - loss: 0.0501 - val_loss: 0.3859\n",
      "Epoch 41/100\n",
      " - 6s - loss: 0.0498 - val_loss: 0.3799\n",
      "Epoch 42/100\n",
      " - 6s - loss: 0.0486 - val_loss: 0.3832\n",
      "Epoch 43/100\n",
      " - 7s - loss: 0.0458 - val_loss: 0.3872\n",
      "Epoch 44/100\n",
      " - 7s - loss: 0.0437 - val_loss: 0.3785\n",
      "Epoch 45/100\n",
      " - 6s - loss: 0.0421 - val_loss: 0.3788\n",
      "Epoch 46/100\n",
      " - 5s - loss: 0.0411 - val_loss: 0.3802\n",
      "Epoch 47/100\n",
      " - 5s - loss: 0.0408 - val_loss: 0.3790\n",
      "Epoch 48/100\n",
      " - 5s - loss: 0.0392 - val_loss: 0.3803\n",
      "Epoch 49/100\n",
      " - 5s - loss: 0.0377 - val_loss: 0.3752\n",
      "Epoch 50/100\n",
      " - 5s - loss: 0.0375 - val_loss: 0.3755\n",
      "Epoch 51/100\n",
      " - 5s - loss: 0.0369 - val_loss: 0.3821\n",
      "Epoch 52/100\n",
      " - 6s - loss: 0.0355 - val_loss: 0.3739\n",
      "Epoch 53/100\n",
      " - 5s - loss: 0.0341 - val_loss: 0.3712\n",
      "Epoch 54/100\n",
      " - 5s - loss: 0.0337 - val_loss: 0.3764\n",
      "Epoch 55/100\n",
      " - 6s - loss: 0.0332 - val_loss: 0.3707\n",
      "Epoch 56/100\n",
      " - 5s - loss: 0.0318 - val_loss: 0.3743\n",
      "Epoch 57/100\n",
      " - 5s - loss: 0.0305 - val_loss: 0.3709\n",
      "Epoch 58/100\n",
      " - 5s - loss: 0.0297 - val_loss: 0.3750\n",
      "Epoch 00058: early stopping\n"
     ]
    }
   ],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "model_regularization_ad.fit(x_train_reg_ad,y_train_reg_ad,validation_data=(x_test_reg_ad,y_test_reg_ad),callbacks=[monitor],verbose=2,epochs=100)\n",
    "\n",
    "pred_regularization_ad = model_regularization_ad.predict(x_test_reg_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5967134833335876\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_regularization_ad = np.sqrt(metrics.mean_squared_error(pred_regularization_ad,y_test_reg_ad))\n",
    "print(\"Final score (RMSE): {}\".format(score_regularization_ad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009: early stopping\n",
      "Final score (RMSE): 0.6171209812164307\n"
     ]
    }
   ],
   "source": [
    "# Dropout\n",
    "\n",
    "model_dropout_ad = Sequential()\n",
    "model_dropout_ad.add(Dense(50, input_dim=x_train_reg_ad.shape[1]))\n",
    "model_dropout_ad.add(Dropout(0.1))\n",
    "\n",
    "model_dropout_ad.add(Dense(25, activation='relu'))\n",
    "model_dropout_ad.add(Dense(10, activation='relu'))\n",
    "model_dropout_ad.add(Dense(1))\n",
    "\n",
    "model_dropout_ad.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "model_dropout_ad.fit(x_train_reg_ad,y_train_reg_ad,validation_data=(x_test_reg_ad,y_test_reg_ad),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "\n",
    "pred_dropout_ad = model_dropout_ad.predict(x_test_reg_ad)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score_dropout_ad = np.sqrt(metrics.mean_squared_error(pred_dropout_ad,y_test_reg_ad))\n",
    "print(\"Final score (RMSE): {}\".format(score_dropout_ad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_85 (Dense)             (None, 50)                275400    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 276,946\n",
      "Trainable params: 276,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dropout_ad.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
